<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>lvh</title><link>https://www.lvh.io/</link><description>lvh's blog</description><atom:link type="application/rss+xml" href="https://www.lvh.io/rss.xml" rel="self"></atom:link><language>en</language><lastBuildDate>Sat, 04 Jun 2016 06:36:39 GMT</lastBuildDate><generator>https://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Nonce misuse resistance 101</title><link>https://www.lvh.io/posts/nonce-misuse-resistance-101.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This post is an introduction to nonce-misused resistant cryptosystems and why
I think they matter. The first part of this post is about nonce-based
authenticated encryption schemes: how they work, and how they fail. If you're
already familiar with them, you can skip to the section on
&lt;a href="https://www.lvh.io/posts/nonce-misuse-resistance-101.html#proto"&gt;protocol design&lt;/a&gt;. If you're completely new to cryptography, you might
like my free introductory course to cryptography, &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;. In a
future blog post, I'll talk about some nonce-misuse resistant schemes I've
implemented using libsodium.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Many stream ciphers and stream cipher-like constructions such as CTR,
GCM, (X)Salsa20... take a nonce. You can think of it as a pointer that lets
you jump to a particular point in the keystream. This makes these ciphers
"seekable", meaning that you can decrypt a small part of a big ciphertext,
instead of having to decrypt everything up to that point first. (That ends up
being trickier than it seems, because you still want to authenticate that
small chunk of ciphertext, but that's a topic for another time.)&lt;/p&gt;
&lt;p&gt;The critical security property of a nonce is that it's never repeated under
the same key. You can remember this by the mnemonic that a &lt;em&gt;nonce&lt;/em&gt; is a
"number used once". If you were to repeat the nonce, the keystream would also
repeat. That means that an attacker can take the two ciphertexts and XOR them
to compute the XOR of the plaintexts. If &lt;code&gt;C_n&lt;/code&gt; are ciphertexts, &lt;code&gt;P_n&lt;/code&gt;
plaintexts, &lt;code&gt;K_n&lt;/code&gt; keystreams, and &lt;code&gt;^&lt;/code&gt; is bitwise exclusive or:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;C_1 = K_1 ^ P_1
C_2 = K_2 ^ P_2
&lt;/pre&gt;


&lt;p&gt;The attacker just XORs &lt;code&gt;C_1&lt;/code&gt; and &lt;code&gt;C_2&lt;/code&gt; together:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;C_1 ^ C_2 = K_1 ^ P_1 ^ K_2 ^ P_2
&lt;/pre&gt;


&lt;p&gt;Since XOR is commutative (you can rearrange the order), &lt;code&gt;K_1 = K_2&lt;/code&gt;, and
XOR'ing two equal values cancels them out:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;C_1 ^ C_2 = P_1 ^ P_2
&lt;/pre&gt;


&lt;p&gt;That tells an attacker a lot about the plaintext, especially if some of one of
the plaintexts is predictable. If the attacker has access to an encryption
oracle, meaning that they can get encryptions for plaintexts of their
choosing, they can even get perfect decryptions. That is not an unrealistic
scenario. For example, if you're encrypting session cookies that contain the
user name and e-mail, I can register using a name and e-mail address that has
a lot of &lt;code&gt;Z&lt;/code&gt; characters, and then I know that just XORing with &lt;code&gt;Z&lt;/code&gt; will reveal
most of the plaintext. For an idea of the state of the art in attacking
two-time pads (the usual term for two ciphertexts with a reused keystream),
see &lt;a href="https://www.cs.jhu.edu/~jason/papers/mason+al.ccs06.pdf"&gt;Mason06&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="proto"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Protocol design&lt;/h3&gt;
&lt;p&gt;For many on-line protocols like TLS, the explicit nonce provides a convenient
way to securely send many messages under a per-session key. Because the
critical security property for a nonce is that it is never repeated with the
same key, it's safe to use a counter. In protocols where both peers send
messages to each other, you can just have one peer use odd nonces and have the
other use even ones. There are some caveats here: for example, if the nonce
size is sufficiently small, an attacker might try to make that counter
overflow, resulting in a repeated nonce.&lt;/p&gt;
&lt;p&gt;For off-line (or at-rest) protocols, it's a little trickier. You don't have a
live communication channel to negotiate a new ephemeral key over, so you're
stuck with longer-term keys or keys derived from them. If multiple systems are
participating, you need to decide ahead of time which systems own which
nonces. Even then, systems need to keep track of which nonces they've
used. That doesn't work well, especially not in a distributed system where
nodes and connections can fail at any time. This is why some cryptosystems
like &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt; provide an API that doesn't require you to specify
anything besides a key and a message.&lt;/p&gt;
&lt;p&gt;One solution is to use randomized nonces. Since nonces can't repeat, random
nonces should be large: if they're too small, you might randomly select the
same nonce twice, per the birthday bound. That is the only difference between
Salsa20 and XSalsa20: Salsa20 has a 64 bit nonce, whereas XSalsa20 has a 192
bit nonce. That change exists explicitly to make random nonces secure.&lt;/p&gt;
&lt;p&gt;Picking a random nonce and just prepending it to the secretbox ciphertext is
secure, but there are a few problems with this approach. It's not clear to
practitioners that that's a secure construct. Doing this may seem obvious to a
cryptographer, but not to someone who just wants to encrypt a
message. Prepending a nonce doesn't feel much different from e.g. appending a
MAC. A somewhat knowledgeable practitioner knows that there's plenty of ways
to use MACs that are insecure, and they don't immediately see that the
prefix-nonce construction is secure. Not wanting to design your own
cryptosystems is a good reflex which we should be encouraging.&lt;/p&gt;
&lt;p&gt;Random nonces also mean that any system sending messages needs access to
high-quality random number generators while they're sending a message. That's
often, but not always true. Bugs around random number generation, especially
userspace CSPRNGs, &lt;a href="http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/"&gt;keep popping up&lt;/a&gt;. This is often a consequence of
poor programming practice, but it can also be a consequence of
poorly-configured VMs or limitations of embedded hardware.&lt;/p&gt;
&lt;h3&gt;Nonce-misuse resistant systems&lt;/h3&gt;
&lt;p&gt;To recap, not all protocols have the luxury of an obvious nonce choice, and
through circumstances or poor practices, nonces might repeat
anyway. Regardless of how cryptographers feel about how important nonce misuse
is, we can anecdotally and empirically verify that such issues are real and
common. This is true even for systems like TLS where there is an "obvious"
nonce available (&lt;a href="https://eprint.iacr.org/2016/475.pdf"&gt;BÃ¶ck et al, 2016&lt;/a&gt;). It's easy to point fingers, but
it's better to produce cryptosystems that fail gracefully.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://web.cs.ucdavis.edu/~rogaway/papers/keywrap.pdf"&gt;Rogaway and Shrimpton (2006)&lt;/a&gt; defined a new model called nonce-misuse
resistance. Informally, nonce-misuse resistance schemes ensure that a repeated
random nonce doesn't result in plaintext compromise. In the case of a broken
system where the attacker can cause repeated nonces, an attacker will only be
able to discern if a particular message repeated, but they will not be able
to decrypt the message.&lt;/p&gt;
&lt;p&gt;Rogaway and Shrimpton also later developed a mode of operation called SIV
(synthetic IV), which Gueron and Lindell are refined to GCM-SIV, a SIV-like
that takes advantage of fast GCM hardware implementations. Those two authors
are currently working with Adam Langley to standardize the AES-GCM-SIV
construction through CFRG. AEZ and HS1-SIV, two entries in the CAESAR
competition, also feature nonce-misuse resistance. CAESAR is an ongoing
competition, and GCM-SIV is not officially finished yet, so this is clearly
a field that is still evolving.&lt;/p&gt;
&lt;p&gt;There are parallels between nonce-misuse resistance and length extension
attacks. Both address issues that arguably only affected systems that were
doing it wrong to begin with. (Note, however, in the embedded case above, it
might not be a software design flaw but a hardware limitation.) Fortunately,
the SHA-3 competition showed that you can have increased performance and
still be immune to a class of problems. I'm hopeful that CAESAR will consider
nonce-misuse resistance an important property of an authenticated encryption
standard.&lt;/p&gt;
&lt;h3&gt;Repeated messages&lt;/h3&gt;
&lt;p&gt;Repeated messages are suboptimal, and in some protocols they might be
unacceptable. However, they're a fail-safe failure mode for nonce
misuse. You're not choosing to have a repeated ciphertext, you're just getting
a repeated ciphertext instead of a plaintext disclosure (where the attacker
would also know that you repeated a message). In the case of a secure random
nonce, a nonce-misuse resistant scheme is just as secure, at the cost of a
performance hit.&lt;/p&gt;
&lt;p&gt;In a context where attackers can see individual messages to detect repeated
ciphertexts, it makes sense to also consider a model where attackers can
replay messages. If replaying messages (which presumably have side effects) is
a problem, a common approach is to add a validity timestamp. This is a feature
of &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt;, for example. A device that doesn't have access to
sufficient entropy will still typically have access to a reasonably
high-resolution clock, which is still more than good enough to make sure the
synthetic IVs don't repeat either.&lt;/p&gt;
&lt;h3&gt;OK, but how does it work?&lt;/h3&gt;
&lt;p&gt;Being able to trade plaintext disclosure for attackers being able to detect
repeated messages sounds like magic, but it makes sense once you realize how
they work. As demonstrated in the start of this post, nonce re-use normally
allows an attacker to have two keystreams cancel out. That only makes sense if
two &lt;em&gt;distinct&lt;/em&gt; messages are encrypted using the same (key, nonce) pair. NMR
solves this by making the nonce also depend on the message itself. Informally,
it means that a nonce should never repeat for two distinct
messages. Therefore, an attacker can't cancel out the keystreams without
cancelling out the messages themselves as well.&lt;/p&gt;
&lt;p&gt;This model does imply off-line operation, in that the entire message has to be
scanned before the nonce can be computed. For some protocols, that may not be
acceptable, although plenty of protocols work around this assumption by simply
making individual messages sufficiently small.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Aaron Zauner and Kurt Griffiths for proofreading this post.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>crypto</category><category>security</category><guid>https://www.lvh.io/posts/nonce-misuse-resistance-101.html</guid><pubDate>Thu, 19 May 2016 19:25:44 GMT</pubDate></item><item><title>Supersingular isogeny Diffie-Hellman 101</title><link>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Craig Costello, Patrick Longa and Michael Naehrig, three cryptographers at
Microsoft Research, recently published a &lt;a href="https://eprint.iacr.org/2016/413"&gt;paper&lt;/a&gt; on supersingular
isogeny Diffie-Hellman. This paper garnered a lot of interest in the security
community and even made it to the front page of Hacker News. Most of the
discussion around it seemed to be how no one understands isogenies, even
within cryptography-literate communities. This article aims to give you a
high-level understanding of what this cryptosystem is and why it works.&lt;/p&gt;
&lt;p&gt;This post assumes that you already know how Diffie-Hellman works in the
abstract, and that you know elliptic curves are a mathematical construct that
you can use to perform Diffie-Hellman operations, just like you can with the
integers &lt;em&gt;mod p&lt;/em&gt; (that would be "regular" Diffie-Hellman). If that was
gibberish to you and you'd like to know more, check out &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;, my
free introductory book on cryptography. You don't need a math background to
understand those concepts at a high level. The main difference is that Crypto
101 sticks to production cryptography, while this is still experimental.&lt;/p&gt;
&lt;p&gt;It's not surprising that isogeny-based cryptography is so confusing. Up until
recently, it was unambiguously in the realm of research, not even close to
being practically applicable. Its mathematical underpinnings are much more
complex than regular elliptic curves, let alone integers &lt;em&gt;mod p&lt;/em&gt;. It also
looks superficially similar to elliptic curve Diffie-Hellman, which only adds
to the confusion.&lt;/p&gt;
&lt;p&gt;With that, let's begin!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is this paper about?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Supersingular isogeny Diffie-Hellman (SIDH) is one of a handful of
"post-quantum" cryptosystems. Those are cryptosystems that will remain secure
even if the attacker has access to a large quantum computer. This has nothing
to do with quantum cryptography (for example, quantum key distribution)
beyond their shared quantum mechanical underpinning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why should I care about quantum computers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;General quantum computers are not useful as general-purpose computing devices,
but they can solve some problems much faster than classical
computers. Classical computers can emulate quantum computers, but only with
exponential slowdown. A sufficiently large quantum computer could break most
production cryptography, including cryptosystems based on the difficulty of
factoring large numbers (like RSA), taking discrete logs over the integers
&lt;em&gt;mod p&lt;/em&gt; (like regular DH), or taking discrete logs over elliptic curves (like
ECDH and ECDSA). To quantify that, consider the following table:&lt;/p&gt;
&lt;p&gt;&lt;img alt="quantum computer attack cost versus classical" src="https://www.lvh.io/img/post-quantum/quantum-computer-relative-cost.png"&gt;&lt;/p&gt;
&lt;p&gt;In this table, n refers to the modulus size for RSA, and the field size for
ECC. Look at the rightmost column, which represents time taken by the
classical algorithm, and compare it to the "time" columns, which represent how
much a quantum computer would take. As &lt;em&gt;n&lt;/em&gt; increases, the amount of time the
quantum computer would take stays in the same ballpark, whereas, for a
classical computer, it increases (almost) exponentially. Therefore, increasing
n is an effective strategy for keeping up with ever-faster classical
computers, but it is ineffective at increasing the run time for a quantum
computer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aah! Why isn't everyone panicking about this?!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The good news is that these large quantum computers don't exist yet.&lt;/p&gt;
&lt;p&gt;If you look at the qubits column, you'll see that these attacks require large
universal quantum computers. The state of the art in those only has a handful
of qubits. In 2011, IBM successfully factored 143 using a 4-qubit quantum
computer. Scaling the number of qubits up is troublesome. In that light,
larger key sizes may prove effective after all; we simply don't know yet how
hard it is to build quantum computers that big.&lt;/p&gt;
&lt;p&gt;D-wave, a quantum computing company, has produced computers with 128 and 512
qubits and even &amp;gt;1000 qubits. While there is some discussion if D-waves
provide quantum speedup or are even real quantum computers at all; there is no
discussion that they are not &lt;em&gt;universal&lt;/em&gt; quantum computers. Specifically, they
only claim to solve one particular problem called quantum annealing. The 1000
qubit D-Wave 2X cannot factor RSA moduli of ~512 bits or solve discrete logs
on curves of ~120 bits.&lt;/p&gt;
&lt;p&gt;The systems at risk implement asymmetric encryption, signatures, and
Diffie-Hellman key exchanges. That's no accident: all post-quantum
alternatives are asymmetric algorithms. Post-quantum secure symmetric
cryptography is easier: we can just use bigger key sizes, which are still
small enough to be practical and result in fast primitives. Quantum computers
simply halve the security level, so all we need to do to maintain a 128 bit
security level is to use ciphers with 256 bit keys, like Salsa20.&lt;/p&gt;
&lt;p&gt;Quantum computers also have an advantage against SIDH, but both are still
exponential in the field size. The SIDH scheme in the new paper has 192 bits
of security against a classical attacker, but still has 128 bits of security
against a quantum attacker. That's in the same ballpark as most symmetric
cryptography, and better than the 2048-bit RSA certificates that underpin the
security of the Internet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What makes this paper special?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Post-quantum cryptography has been firmly in the realm of academic research
and experiments. This paper makes significant advancements in how practically
applicable SIDH is.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Being future-proof sounds good. If this makes it practical, why don't we
start using it right now?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SIDH is a young cryptosystem in a young field, and hasn't had the same level
of scrutiny as some of the other post-quantum cryptosystems, let alone the
"regular" cryptosystems we use daily. Attacks only get better, they never get
worse. It's possible that SIDH is insecure, and we just don't know how to
break it yet. It does have a good argument for why quantum algorithms wouldn't
be able to crack it (more on that later), but that's a hypothesis, not a
proof.&lt;/p&gt;
&lt;p&gt;The new performance figures from this paper are impressive, but this system is
still much slower than the ones we use today. Key generation and key exchange
take a good 50 million cycles or so each. That's about a thousand times slower
than Curve25519, a curve designed about 10 years ago. Key sizes are also much
larger: SIDH public keys are 751 bytes, whereas Curve25519 keys are only 32
bytes. For on-line protocols like HTTPS operating over TCP, that's a
significant cost.&lt;/p&gt;
&lt;p&gt;Finally, there are issues with implementing SIDH safely. Systems like
Diffie-Hellman over integers &lt;em&gt;mod p&lt;/em&gt; are much less complex than elliptic curve
Diffie-Hellman (ECDH), let alone SIDH. With ECDH and ECC in general, we've
seen new implementation difficulties, especially with early curves. Point
addition formulas would work, unless you were adding a point to itself. You
have to check that input points are on the curve, or leak the secret key
modulo some small order. These are real implementation problems, even though
we know how to solve them.&lt;/p&gt;
&lt;p&gt;This is nothing compared to the difficulties implementing SIDH. Currently,
SIDH security arguments rely on honest peers. A peer that gives you a
pathological input can utterly break the security of the scheme. To make
matters worse, while we understand how to verify inputs for elliptic curve
Diffie-Hellman, we don't have a way to verify inputs for isogeny-based
cryptography at all. We don't have much research to fall back on here
either. This isn't a SIDH-specific problem; post-quantum cryptography isn't
mature enough yet to have implementation issues like these nailed down
yet. (For an example from lattice-based cryptography, see the recent paper by
&lt;a href="https://eprint.iacr.org/2016/415"&gt;Bindel et al&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;I don't want to diminish the importance of this paper in any way!  Just
because it's not something that your browser is going to be doing tomorrow
doesn't mean it's not an impressive accomplishment. It's just a step on the
path that might lead to production crypto one day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, fine. Why is this so different from elliptic curve Diffie-Hellman?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While SIDH and ECDH both use elliptic curves, they're different beasts. SIDH
generates new curves to perform a DH exchange, whereas ECDH uses points on one
fixed curve. These supersingular curves also have different properties from
regular curves. Using a supersingular curve for regular elliptic curve
operations would be horribly insecure. If you have some background in elliptic
curves: supersingular curves have a tiny embedding degree, meaning that
solving the ECDLP over &lt;code&gt;F(p)&lt;/code&gt; can easily be transformed into solving the DLP
over &lt;code&gt;F(p^n)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is that small embedding degree. Most curves have large
embedding degrees, meaning that solving the ECDLP directly is easier than
translating it into a DLP and then solving that.  You generally have to go out
of your way to find a curve with a small embedding degree. That is only done
in specialized systems, like for pairing-based cryptography, or, as in this
case, supersingular isogeny-based Diffie-Hellman.&lt;/p&gt;
&lt;p&gt;Let's recap ECDH. Public keys are points on a curve, and secret keys are
numbers. Alice and Bob agree on the parameters of the exchange ahead of time,
such as the curve &lt;em&gt;E&lt;/em&gt; and a generator point &lt;em&gt;P&lt;/em&gt; on that curve. Alice picks a
secret integer &lt;em&gt;a&lt;/em&gt; and computes her public key &lt;em&gt;aP&lt;/em&gt;. Bob picks a secret
integer &lt;em&gt;b&lt;/em&gt; and computes his public key &lt;em&gt;bP&lt;/em&gt;. Alice and Bob send each other
their public keys, and multiply their secret key by the other peer's public
key. Since &lt;em&gt;abP = baP&lt;/em&gt;, they compute the same secret. Since an attacker has
neither secret key, they can't compute the shared secret.&lt;/p&gt;
&lt;p&gt;SIDH is different. Secret keys are isogenies...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Whoa whoa whoa. What the heck are isogenies?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An isogeny between elliptic curves is a function from one elliptic curve to
another that preserves base points. That means it takes points on one curve
and returns points on the other curve. Every point on the input curve will map
to a point on the output curve; but multiple points may map to the same
point. Formally speaking, the isogeny is surjective. An isogeny is also a
homomorphism. That is, it preserves the structure of the curve. For any two
points P and Q, &lt;code&gt;phi(P + Q) = phi(P) + phi(Q)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We have a bunch of formulas for generating isogenies from a curve and a
point. You might remember that the set of values a function takes is its
"domain", and the set of values it returns is called its "codomain". The
domain of such an isogeny is the curve you give it; its codomain might be the
same curve, or it might be a different one. In general, for SIDH, we care
about the case where it produces a new curve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, so explain how SIDH works again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Roughly speaking, a secret key is an isogeny, and a public key is an elliptic
curve. By "mixing" their isogeny with the peer's public curve, each peer
generates a secret curve. The two peers will generally generate different
curves, but those curves will have the same j-invariant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wait, what's a j-invariant?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The j-invariant is a number you can compute for a particular curve. Perhaps
the best analogy would be the discriminant for quadratic equation you might
remember from high school math; it's a single number that tells you something
interesting about the underlying curve. There are different formulas for
curves in different forms. For example, for a curve in short Weierstrass form
&lt;code&gt;y^2 = x^3 + ax + b&lt;/code&gt;, the j-invariant is:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;j(E) = (1728 * 4a^3)/(4a^3 + 27b^2)
&lt;/pre&gt;


&lt;p&gt;The j-invariant has a few cool properties. For example, while this is the
formula for the short Weierstrass form, the value of j doesn't change if you
put the same curve in a different form. Also, all curves with the same
j-invariant are isomorphic. However, for SIDH you don't really care about
these properties; you just care that the j-invariant is a number you can
compute, and it'll be the same for the two secret curves that are generated by
the DH exchange.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, try explaining SIDH again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The protocol fixes a supersingular curve E and four points on that
curve: P_A, Q_A, P_B, Q_B.&lt;/p&gt;
&lt;p&gt;Alice picks two random integers, m_A and n_A. She takes a linear combination
of those two integers with P_A and Q_A to produce a random point R_A, so:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;R_A = n_A * P_A + m_A * Q_A
&lt;/pre&gt;


&lt;p&gt;That random point defines Alice's secret isogeny through the isogeny formulas
I talked about above. The codomain of that isogeny forms Alice's public
curve. Alice transforms points P_B and Q_B with the isogeny. She sends Bob her
public curve and the two transformed points.&lt;/p&gt;
&lt;p&gt;Bob does the same thing, except with A and B swapped.&lt;/p&gt;
&lt;p&gt;Once Alice gets Bob's public key, she applies m_A and n_A again to the
corresponding transformed points she got from Bob. She generates a new isogeny
phiBA from the resulting point just like she did before to generate her
private key. That isogeny's codomain will be an elliptic curve E_BA.&lt;/p&gt;
&lt;p&gt;When Bob performs his side of the exchange, he'll produce a different isogeny
and a different elliptic curve E_AB; but it will have the same j-invariant as
the curve Alice computed.  That j-invariant is the shared key.&lt;/p&gt;
&lt;p&gt;I've compiled a &lt;a href="https://dl.dropboxusercontent.com/u/38476311/Supersingular%20Isogeny%20Elliptic%20Curve%20Cryptography%20--%20Sage.pdf"&gt;transcript&lt;/a&gt; of a Diffie-Hellman exchange using
Sage so you can see a (toy!) demo in action.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I know a little about elliptic curves. I thought they were always
non-singular. What's a supersingular elliptic curve but a contradiction in
terms?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You're right! Supersingular elliptic curves are somewhat confusingly
named. Supersingular elliptic curves are still elliptic curves, and they are
non-singular just like all other elliptic curves. The "supersingular" refers
to the singular values of the j-invariant. Equivalently, the Hasse invariant
will be 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, why does it matter that the curve is supersingular?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Firstly, computing the isogeny is much easier on supersingular curves than on
ordinary (not supersingular) elliptic curves. Secondly, if the curve is
ordinary, the scheme can be broken in subexponential time by a quantum
attacker.&lt;/p&gt;
&lt;p&gt;Isogeny-based cryptography using ordinary curves was considered as a
post-quantum secure cryptosystem before SIDH. However, Childs et al. showed a
subexponential quantum algorithm in 2010. This paper appeared to have ended
isogeny-based cryptography: it was already slower than other post-quantum
systems, and now it was shown that it wasn't even post-quantum secure.&lt;/p&gt;
&lt;p&gt;Because supersingular curves are rare, they had not previously been considered
for isogeny-based cryptography. However, the paper itself suggested that
supersingular curves might be worth examining, so it ended up pushing research
in a new direction rather than ending it.&lt;/p&gt;
&lt;p&gt;Explaining why the supersingular curve makes the problem quantum-hard is
tricky without being thoroughly familiar with isogenies and quantum
computing. If you're really interested, &lt;a href="https://arxiv.org/pdf/1012.4019v2.pdf"&gt;the Childs paper&lt;/a&gt; explains
how the quantum attack in the ordinary case works. Informally, in the ordinary
case, there is a group action (the &lt;em&gt;isogeny star operator&lt;/em&gt;) of the ideal class
group onto the set of isomorphism classes of isogenous curves with the same
endomorphism ring. That can be shown to be a special case of the abelian group
hidden shift problem, which can be solved quickly on a quantum computer. In
the supersingular case, there is no such group action to exploit. (If you're
trying to solve for this at home; this is why SIDH needs to define the 4
points P_A, P_B, Q_A, Q_B.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I would like to thank Thomas Ptacek for reviewing this blog post and bearing
with me as I struggle through trying to come up with human-readable
explanations for all of this stuff; Sean Devlin for reminding me that Sage is
an excellent educational tool; and Watson Ladd for pointing out a correction
w.r.t the Hasse invariant (the Hasse-Witt matrix is undefined, not
singular.). Finally, I'd like to thank all the people who reviewed drafts of
this post, including (in no particular order) Bryan Geraghty, Shane Wilton,
Sean Devlin, Thomas Ptacek, Tanner Prynn, Glyph Lefkowitz and Chris Wolfe.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>crypto</category><category>security</category><guid>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101.html</guid><pubDate>Sat, 30 Apr 2016 16:00:28 GMT</pubDate></item><item><title>Introducing Teleport</title><link>https://www.lvh.io/posts/introducing-teleport.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm happy to introduce &lt;a href="https://github.com/gravitational/teleport"&gt;Teleport&lt;/a&gt;, a new open source platform for
managing SSH infrastructure. Teleport is built by &lt;a href="http://www.gravitational.com/"&gt;Gravitational&lt;/a&gt;, a Y
Combinator company that ships SaaS on any platform. While I'm not a part of
Gravitational, I have been advising them on the Teleport project.&lt;/p&gt;
&lt;p&gt;Most teams don't have a great authentication story. Some rely on passing
passwords around haphazardly, while others rely on copying everyone's
&lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt; to every new box. More complex homegrown systems quickly
become unwieldy. These methods are problematic both operationally and from a
security perspective: when security and usability are at odds, security tends
to lose out. For a lot of teams, a single compromised key off of a developer
machine spells disaster, on-boarding new team members is painful, and key
rotation doesn't happen.&lt;/p&gt;
&lt;p&gt;In the last few years, strong multi-factor authentication has become the
norm. Tokens are only valid for a brief period of time, use challenge-response
protocols, or both. Teleport helps bring the same level of sophistication to
infrastructure. It helps system administrators leverage the security benefits
of short-lived certificates, while keeping the operational benefits of
decoupling server authentication from user authentication. It lets you run
isolated clusters, so that a compromise of staging credentials doesn't lead to
a compromise in production. It automatically maintains clear audit logs: who
logged in, when and where they logged in, and what they did once they got
there.&lt;/p&gt;
&lt;p&gt;Teleport comes with a beautiful, usable UI, making it easy to visualize
different clusters and the available machines within them. The UI is optional:
many system administrators will prefer to use their existing SSH client, and
Teleport supports that natively.  Because it implements the &lt;code&gt;SSH_AUTH_SOCK&lt;/code&gt;
protocol, integrating your current CLI workflow is a simple matter of setting
a single environment variable.&lt;/p&gt;
&lt;p&gt;As someone with an open-source background, I'm glad to see this software
released and developed out in the open. A decent SSH key management story
should be available to everyone, and that's what Teleport does. I believe
making this technology more accessible is good for everyone, including
commercial vendors. Democratizing a decent DIY story helps turn their product
into the battle-hardened and commercially supported version of industry best
practice; and as such, I hope this helps grow that market. As a principal
engineer at &lt;a href="https://www.rackspace.com/security/"&gt;Rackspace Managed Security&lt;/a&gt;, I'm excited to start working
towards better authentication stories, both internally and for our customers,
with Teleport as the new baseline.&lt;/p&gt;
&lt;p&gt;Releasing early and often is also an important part of open source
culture. That can be at odds with doing due diligence when releasing
security-critical systems like Teleport, especially when those systems have
non-trivial cryptographic components. We feel Teleport is ready to show to the
public now. To make sure we act as responsibly as possible, I've helped the
Teleport team to join forces with a competent independent third-party
auditor. We're not recommending that you bet the farm on Teleport by running
it in production as your only authentication method just yet, but we do think
it's ready for motivated individuals to start experimenting with it.&lt;/p&gt;
&lt;p&gt;Some people might feel that a better SSH story means you're solving the wrong
problem. It seems at odds with the ideas behind immutable infrastructure and
treating servers as &lt;a href="https://blog.engineyard.com/2014/pets-vs-cattle"&gt;cattle, not pets&lt;/a&gt;. I don't think that's
true. Firstly, even with immutable infrastructure, being able to SSH into a
box to debug and monitor is still incredibly important. Being able to rapidly
deploy a bunch of fixed images quickly may be good, but you still have to know
what to fix first. Secondly, existing systems don't always work that way. It
may not be possible, let alone economically rational, to "port" them
effectively. It's easy to think of existing systems as legacy eyesores that
only exist until you can eradicate them, but they do exist, they're typically
here to stay, and they need a real security story, too.&lt;/p&gt;
&lt;p&gt;Teleport is still in its early stages. It's usable today, and I'm convinced it
has a bright future ahead of it. It's written in a beautiful, hackable Go
codebase, and &lt;a href="https://github.com/gravitational/teleport"&gt;available on Github&lt;/a&gt; starting today.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/introducing-teleport.html</guid><pubDate>Sat, 12 Mar 2016 17:35:56 GMT</pubDate></item><item><title>Don't expose the Docker socket (not even to a container)</title><link>https://www.lvh.io/posts/dont-expose-the-docker-socket-not-even-to-a-container.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Docker primarily works as a client that communicates with a daemon
process (&lt;code&gt;dockerd&lt;/code&gt;). Typically that socket is a UNIX domain socket
called &lt;code&gt;/var/run/docker.sock&lt;/code&gt;. That daemon is highly privileged;
effectively having root access. Any process that can write to the
&lt;code&gt;dockerd&lt;/code&gt; socket &lt;em&gt;also&lt;/em&gt; effectively has root access.&lt;/p&gt;
&lt;p&gt;This is no big secret. Docker clearly documents this in a bunch of
places, including the introductory documentation. It's an excellent
reason to use Docker Machine for development purposes, even on
Linux. If your regular user can write to the &lt;code&gt;dockerd&lt;/code&gt; socket, then
every code execution vulnerability comes with a free privilege
escalation.&lt;/p&gt;
&lt;p&gt;The warnings around the Docker socket typically come with a (sometimes
implicit) context of being on the host to begin with. Write access to
the socket as an unprivileged user on the host may mean privileged
access to the host, but there seems to be some confusion about what
happens when you get write access to the socket &lt;em&gt;from a
container&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The two most common misconceptions seem to be that it either doesn't
grant elevated privileges at all, or that it grants you privileged
access within the container (and without a way to break out). This is
false; write access to the Docker socket is root on the host,
regardless on where that write comes from. This is different from
&lt;a href="https://github.com/jpetazzo/dind"&gt;Jerome Pettazoni's &lt;code&gt;dind&lt;/code&gt;&lt;/a&gt;, which gives you Docker-in-Docker;
we're talking about access to the host's Docker socket.&lt;/p&gt;
&lt;p&gt;The process works like this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The Docker container gets a &lt;code&gt;docker&lt;/code&gt; client of its own, pointed at
   the &lt;code&gt;/var/run/docker.sock&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The Docker container launches a new container mounting &lt;code&gt;/&lt;/code&gt; on
   &lt;code&gt;/host&lt;/code&gt;. This is the &lt;em&gt;host&lt;/em&gt; root filesystem, not the first
   container.&lt;/li&gt;
&lt;li&gt;The second container chroots to &lt;code&gt;/host&lt;/code&gt;, and is now effectively
   root on the host. (There are a few differences between this and a
   clean login shell; for example, &lt;code&gt;/proc/self/cgroups&lt;/code&gt; will still show
   Docker cgroups. However, the attacker has all of the permissions
   necessary to work around this.)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This is identical to the process you'd use to escalate from outside of
a container. Write access to the Docker socket is root on the host,
full stop; who's writing, or where they're writing from, doesn't
matter.&lt;/p&gt;
&lt;p&gt;Unfortunately, there are plenty of development teams unaware of this
property. I recently came across one, and ended up making a screencast
to unambiguously demonstrate the flaw in their setup (which involved a
container with write access to the Docker socket).&lt;/p&gt;
&lt;iframe width="560" height="315" src="https://www.youtube.com/embed/CB9Aa6QeRaI" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;This isn't new; it's been a known property of the way Docker works
ever since the (unfortunately trivially cross-site scriptable) REST
API listening on a local TCP port was replaced with the
&lt;code&gt;/var/run/docker.sock&lt;/code&gt; UNIX domain socket.&lt;/p&gt;&lt;/div&gt;</description><category>docker</category><category>security</category><guid>https://www.lvh.io/posts/dont-expose-the-docker-socket-not-even-to-a-container.html</guid><pubDate>Wed, 23 Sep 2015 21:54:24 GMT</pubDate></item><item><title>querySelectorAll from an element probably doesn't do what you think it does</title><link>https://www.lvh.io/posts/queryselectorall-from-an-element-probably-doesnt-do-what-you-think-it-does.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Modern browsers have APIs called &lt;code&gt;querySelector&lt;/code&gt; and &lt;code&gt;querySelectorAll&lt;/code&gt;. They
find one or more elements matching a CSS selector. I'm assuming basic
familiarity with CSS selectors: how you select elements, classes and ids. If
you haven't used them, the Mozilla Developer Network has an excellent
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/Guide/CSS/Getting_started/Selectors"&gt;introduction&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Imagine the following HTML page:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"outside"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"my-id"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"inside"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"lonely"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"outer"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
            &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"inner"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;&lt;code&gt;document.querySelectorAll("div")&lt;/code&gt; returns a &lt;code&gt;NodeList&lt;/code&gt; of all of the &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt;
elements on the page. &lt;code&gt;document.querySelector("div.lonely")&lt;/code&gt; returns that
single lonely div.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;document&lt;/code&gt; supports both &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelector"&gt;&lt;code&gt;querySelector&lt;/code&gt;&lt;/a&gt; and
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/querySelectorAll"&gt;&lt;code&gt;querySelectorAll&lt;/code&gt;&lt;/a&gt;, letting you find elements in the entire
document. Elements themselves also support both &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/querySelector"&gt;&lt;code&gt;querySelector&lt;/code&gt;&lt;/a&gt; and
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/querySelectorAll"&gt;&lt;code&gt;querySelectorAll&lt;/code&gt;&lt;/a&gt;, letting you query for elements that are
descendants of that element. For example, the following expression will find
images that are descendants of &lt;code&gt;#my-id&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"img"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;In the sample HTML page above, it will find &lt;code&gt;&amp;lt;img id="inside"&amp;gt;&lt;/code&gt; but not &lt;code&gt;&amp;lt;img
id="outside"&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With that in mind, what do these two expressions do?&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id div div"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"div div"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You might reasonably expect them to be equivalent. After all, one asks for
&lt;code&gt;div&lt;/code&gt; elements inside &lt;code&gt;div&lt;/code&gt; elements inside &lt;code&gt;#my-id&lt;/code&gt;, and the other asks for
&lt;code&gt;div&lt;/code&gt; elements inside &lt;code&gt;div&lt;/code&gt; elements that are &lt;em&gt;descendants&lt;/em&gt; of
&lt;code&gt;#my-id&lt;/code&gt;. However, when you look at &lt;a href="http://jsbin.com/hineco/edit?html,js,output"&gt;this JSbin&lt;/a&gt;, you'll see that they
produce very different results:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id div div"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;===&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"div div"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;length&lt;/span&gt; &lt;span class="o"&gt;===&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;What is going on here?&lt;/p&gt;
&lt;p&gt;It turns out that &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/querySelectorAll"&gt;&lt;code&gt;element.querySelectorAll&lt;/code&gt;&lt;/a&gt; doesn't match elements
starting from &lt;code&gt;element&lt;/code&gt;. Instead, it matches elements matching the query that
are also descendants of &lt;code&gt;element&lt;/code&gt;. Therefore, we're seeing three &lt;code&gt;div&lt;/code&gt;
elements: &lt;code&gt;div.lonely&lt;/code&gt;, &lt;code&gt;div.outer&lt;/code&gt;, &lt;code&gt;div.inner&lt;/code&gt;. We're seeing them because
they both match the &lt;code&gt;div div&lt;/code&gt; selector and are all descendants of &lt;code&gt;#my-id&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The trick to remembering this is that CSS selectors are absolute. They are not
relative to any particular element, not even the element you're calling
&lt;code&gt;querySelectorAll&lt;/code&gt; on.&lt;/p&gt;
&lt;p&gt;This even works with elements &lt;em&gt;outside&lt;/em&gt; the element you're calling
&lt;code&gt;querySelectorAll&lt;/code&gt; on. For example, this selector:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"div div div"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;... matches &lt;code&gt;div.inner&lt;/code&gt; in this snippet (&lt;a href="http://jsbin.com/woropuc/edit?html,js,output"&gt;JSbin&lt;/a&gt;):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="cp"&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"my-id"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
        &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt; &lt;span class="na"&gt;class&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;"inner"&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
      &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
    &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;div&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;body&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;html&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;I think this API is surprising, and the front-end engineers I've asked seem to
agree with me. This is, however, not a bug. It's how the spec defines it to
work, and browsers consistently implement it that way.
Safari. &lt;a href="http://ejohn.org/blog/thoughts-on-queryselectorall/"&gt;John Resig commented&lt;/a&gt; how he and others felt this behavior
was quite confusing back when the spec came out.&lt;/p&gt;
&lt;p&gt;If you can't easily rewrite the selector to be absolute like we did above,
there are two alternatives: the &lt;code&gt;:scope&lt;/code&gt; CSS pseudo-selector, and
&lt;code&gt;query&lt;/code&gt;/&lt;code&gt;queryAll&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;:scope&lt;/code&gt; pseudo-selector matches against the current scope. The
name comes from the &lt;a href="https://html.spec.whatwg.org/multipage/semantics.html#attr-style-scoped"&gt;CSS scoping&lt;/a&gt;, which limits the scope
of styles to part of the document. The element we're calling
&lt;code&gt;querySelectorAll&lt;/code&gt; on also counts as a scope, so this expression only
matches &lt;code&gt;div.inner&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;querySelector&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"#my-id"&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;querySelectorAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;":scope div div"&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Unfortunately, &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/%3Ascope#Browser_compatibility"&gt;browser support&lt;/a&gt; for scoped CSS and the &lt;code&gt;:scope&lt;/code&gt;
pseudo-selector is extremely limited. Only recent versions of Firefox support
it by default. Blink-based browsers like Chrome and Opera require the
well-hidden experimental features flag to be turned on. Safari has a buggy
implementation. Internet Explorer doesn't support it at all.&lt;/p&gt;
&lt;p&gt;The other alternative is &lt;code&gt;element.query&lt;/code&gt;/&lt;code&gt;queryAll&lt;/code&gt;. These are alternative
methods to &lt;code&gt;querySelector&lt;/code&gt; and &lt;code&gt;querySelectorAll&lt;/code&gt; that exist on DOM parent
nodes. They also take selectors, except these selectors are interpreted
relative to the element being queried from.  Unfortunately, these methods are
even more obscure: they are not referenced on MDN or &lt;code&gt;caniuse.com&lt;/code&gt;, and are
missing from the &lt;a href="http://www.w3.org/TR/dom/#interface-parentnode"&gt;current DOM4 working draft&lt;/a&gt;, dated 18
June 2015. They were still present in &lt;a href="http://www.w3.org/TR/2014/WD-dom-20140204/#interface-parentnode"&gt;an older version&lt;/a&gt;, dated 4
February 2014, as well as in the &lt;a href="https://dom.spec.whatwg.org/#interface-parentnode"&gt;WHATWG Living Document&lt;/a&gt; version
of the spec. They have also been implemented by at least two polyfills:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://webreflection.github.io/dom4/"&gt;Dom4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/barberboy/dom-elements"&gt;dom-elements&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In conclusion, the DOM spec doesn't always necessarily do the most obvious
thing. It's important to know pitfalls like these, because they're difficult
to discover from just the behavior. Fortunately, you can often rewrite your
selector so that it isn't a problem. If you can't, there's always a polyfill
to give you the modern API you want. Alternatively, libraries like jQuery can
also help you get a consistent, friendly interface for querying the DOM.&lt;/p&gt;&lt;/div&gt;</description><category>css</category><category>dom</category><category>webdev</category><guid>https://www.lvh.io/posts/queryselectorall-from-an-element-probably-doesnt-do-what-you-think-it-does.html</guid><pubDate>Fri, 21 Aug 2015 19:11:23 GMT</pubDate></item><item><title>Today's OpenSSL bug (for techies without infosec chops)</title><link>https://www.lvh.io/posts/todays-openssl-bug-for-techies-without-infosec-chops.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;h2&gt;What happened?&lt;/h2&gt;
&lt;p&gt;OpenSSL 1.0.1n+ and 1.0.2b+ had a new feature that allows finding an
alternative certificate chain when the first one fails. The logic in
that feature had a bug in it, such that it didn't properly verify if
the certificates in the alternative chain had the appropriate
permissions; specifically, it didn't check if those certificates are
certificate authorities.&lt;/p&gt;
&lt;p&gt;Specifically, this means that an attacker who has a valid certificate
for any domain, can use that certificate to produce new
certificates. Those normally wouldn't work, but the algorithm for
finding the alternative trust chain doesn't check if the valid
certificate can act as a certificate authority.&lt;/p&gt;
&lt;h2&gt;What's a certificate (chain)?&lt;/h2&gt;
&lt;p&gt;A certificate is a bit like an ID card: it has some information about
you (like your name), and is authenticated by a certificate authority
(in the case of an ID, usually your government).&lt;/p&gt;
&lt;h2&gt;What's a certificate authority?&lt;/h2&gt;
&lt;p&gt;A certificate authority is an entity that's allowed to authenticate
certificates. Your computer typically ships with the identity of those
certificate authorities, so it knows how to recognize certificates
authorized by them.&lt;/p&gt;
&lt;p&gt;In the ID analogy, your computer knows how to recognize photo IDs
issued by e.g. California.&lt;/p&gt;
&lt;p&gt;The issue here is that in some cases, OpenSSL was willing to accept
signatures authenticated by certificates that don't have certificate
authority powers. In the analogy, it would mean that it accepted
CostCo cards as valid ID, too.&lt;/p&gt;
&lt;h2&gt;Why did they say it wouldn't affect most users?&lt;/h2&gt;
&lt;p&gt;This basically means "we're assuming most users are using OpenSSL for
vanilla servers", which is probably true. Most servers do use OpenSSL,
and most clients (browsers) don't.&lt;/p&gt;
&lt;p&gt;The bug affects anyone trying to authenticate their peer. That
includes regular clients, and servers doing client
authentication. Regular servers aren't affected, because they don't
authenticate their peer.&lt;/p&gt;
&lt;p&gt;Servers doing client authentication are fairly rare. The biggest
concern is with clients. While browsers typically don't use OpenSSL, a
lot of API clients do. For those few people affected by the bug and
with clients that use OpenSSL, the bug is catastrophic.&lt;/p&gt;
&lt;h2&gt;What's client authentication?&lt;/h2&gt;
&lt;p&gt;The vast majority of TLS connections only authenticate the
server. When the client opens the connection, the server sends its
certificate. The client checks the certificate chain against the list
of certificate authorities that it knows about. The client is
typically authenticated, but over the protocol spoken inside of TLS
(usually HTTP), not at a TLS level.&lt;/p&gt;
&lt;p&gt;That isn't the only way TLS can work. TLS also supports authenticating
clients with certificates, just like it authenticates servers. This is
called mutually authenticated TLS, because both peers authenticate
each other. At Rackspace Managed Security, we use this for all
communication between internal nodes. We also operate our own
certificate authority to sign all of those certificates.&lt;/p&gt;
&lt;h2&gt;What's TLS?&lt;/h2&gt;
&lt;p&gt;TLS is what SSL has been called for way over a decade. The old name
stuck (particularly in the name "OpenSSL"), but you should probably
stop using it when you're talking about the secure protocol, since all
of the versions of the protocol that were called "SSL" have crippling
security bugs.&lt;/p&gt;
&lt;h2&gt;Why wasn't this found by automated testing?&lt;/h2&gt;
&lt;p&gt;I'm not sure. I wish automated testing this stuff was easier. Since
I'm both a user and a big fan of client authentication, which is a
pretty rare feature, I hope to spend more time in the future creating
easy-to-use automated testing tools for this kind of scenario.&lt;/p&gt;
&lt;h2&gt;How big is the window?&lt;/h2&gt;
&lt;p&gt;1.0.1n and 1.0.2b were both released on 11 Jun 2015. The fixes, 1.0.1p
and 1.0.2d, were released today, on 9 Jul 2015.&lt;/p&gt;
&lt;p&gt;The "good news" is that the bad releases are recent. Most people who
have an affected version will be updating regularly, so the number of
people affected is small.&lt;/p&gt;
&lt;p&gt;The bug affected following platforms (non-exhaustive):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It did not affect stock OS X, because they still ship
  0.9.8. However, the bug does affect a stable version shipped through
  Homebrew (1.0.2c).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.canonical.com/~ubuntu-security/cve/2015/CVE-2015-1793.html"&gt;Ubuntu is mostly not affected&lt;/a&gt;. The only affected version
  is the unreleased 15.10 (Wily). Ubuntu has already released an
  update for it.&lt;/li&gt;
&lt;li&gt;The bug affects stable releases of Fedora. I previously mistakenly
  reported that the contrary, but that information was based on their
  package version numbers, which did not match upstream. Fedora
  backported the faulty logic to their version of 1.0.1k, which was
  available in Fedora 21 and 22. They have since released patches; see
  &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1241544"&gt;this ticket&lt;/a&gt; for details. Thanks to Major Hayden for the
  correction!&lt;/li&gt;
&lt;li&gt;The bug does not affect Debian stable, but it does affect
  &lt;a href="https://security-tracker.debian.org/tracker/CVE-2015-1793s=openssl"&gt;testing and unstable&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The bug affects &lt;a href="https://www.archlinux.org/packages/?sort=-last_update"&gt;ArchLinux testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;In conclusion&lt;/h2&gt;
&lt;p&gt;The bug is disastrous, but affects few people. If you're running
stable versions of your operating system, you're almost certainly
safe.&lt;/p&gt;
&lt;p&gt;The biggest concern is with software developers using OS X. That
audience uses HTTPS APIs frequently, and the clients to connect to
those APIs typically use OpenSSL. OS X comes with 0.9.8zf by default
now, which is a recent revision of an ancient branch. Therefore,
people have a strong motivation to get their OpenSSL from a
third-party source. The most popular source is Homebrew, which up
until earlier this morning shipped 1.0.2c. The bug affects that
version. If you installed OpenSSL through Homebrew, you should go
update right now.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/todays-openssl-bug-for-techies-without-infosec-chops.html</guid><pubDate>Thu, 09 Jul 2015 15:26:58 GMT</pubDate></item><item><title>They do take security seriously</title><link>https://www.lvh.io/posts/they-do-take-security-seriously.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Earlier today, I read an &lt;a href="http://www.troyhunt.com/2015/07/we-take-security-seriously-otherwise.html"&gt;article&lt;/a&gt; about the plethora of
information security breaches in recent history. Its title reads:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âWe take security seriouslyâ, otherwise known as âWe didnât take it
seriously enoughâ&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The article then lists a number of companies informing the public that
they've been breached.&lt;/p&gt;
&lt;p&gt;I think this article doesn't just blame the victims of those attacks,
but subjects them to public ridicule. Neither helps anyone, least of
all end users.&lt;/p&gt;
&lt;p&gt;I'm surprised to hear such comments from Troy Hunt. He's certainly an
accomplished professional with extensive security experience. This is
not the first time people have expressed similar thoughts; the
&lt;a href="https://news.ycombinator.com/item?id=9834099"&gt;HN thread&lt;/a&gt; for that article is rife with them.&lt;/p&gt;
&lt;p&gt;The explicit assumption is that these companies wouldn't have gotten
in trouble if only they had taken security more seriously. In a world
where the information services store is increasingly valuable and
software increasingly complex, breaches are going to happen. The idea
that getting breached is their own darn fault is unrealistic.&lt;/p&gt;
&lt;p&gt;This idea is also counterproductive. Firstly, there's one thing all of
the victims being ostracized have in common: they disclosed the
details of the breach. That is exactly what they should have done;
punishing them creates a perverse incentive for victims to hide
breaches in the future, a decidedly worse end-user outcome.&lt;/p&gt;
&lt;p&gt;Secondly, if any breach is as bad as any other breach, there is no
incentive to proactively mitigate damage from future breaches by
hardening internal systems. Why encrypt records, invest in access
control or keep sensitive information in a separate database with
extensive audit logging? It might materially impact end-user security,
but who cares -- all anyone is going to remember is that you got
popped.&lt;/p&gt;
&lt;p&gt;Finally, there's a subtle PR issue: how can the security industry
build deep relationships with clients when we publicly ridicule them
when the inevitable happens?&lt;/p&gt;
&lt;p&gt;These commentators have presumably not been the victims of a breach
themselves. I have trouble swallowing that anyone who's been through
the terrifying experience of being breached, seeing a breach up close
or even just witnessing a hairy situation being defused could air
those thoughts.&lt;/p&gt;
&lt;p&gt;If you haven't been the victim of an attack, and feel that your
security posture is keeping you from becoming one, consider this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What's your threat model?&lt;/li&gt;
&lt;li&gt;How confident are you in your estimation of the capabilities of
   attackers?&lt;/li&gt;
&lt;li&gt;Would you still be okay if your database became three orders of
   magnitude more valuable? Most personal data's value will scale
   linearly with the number of people affected, so if you're a small
   start-up with growth prospects, you'll either fail to execute, or
   be subject to that scenario.&lt;/li&gt;
&lt;li&gt;Would you still be okay if the attacker has a few 0-days?&lt;/li&gt;
&lt;li&gt;What if the adversary is a nation-state?&lt;/li&gt;
&lt;li&gt;How do you &lt;em&gt;know&lt;/em&gt; you haven't been breached?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That brings me to my final thesis: I contest the claim that all of the
companies in the article didn't take security seriously. It is far
more probable that all of the companies cited in the article have
expended massive efforts to protect themselves, and, in doing so,
foiled many attacks. It's also possible that they haven't; but the
onus there is certainly on the accuser.&lt;/p&gt;
&lt;p&gt;Clearly, that's a weak form of disagreement, since "taking something
seriously" is entirely subjective. However, keep in mind that many
targets &lt;em&gt;actually&lt;/em&gt; haven't taken security seriously, and would not
even have the technical sophistication to detect an attack.&lt;/p&gt;
&lt;p&gt;(By the way, if you too would like to help materially improve people's
security, we're hiring. Contact me at &lt;code&gt;_@lvh.io&lt;/code&gt;.)&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/they-do-take-security-seriously.html</guid><pubDate>Sun, 05 Jul 2015 20:17:18 GMT</pubDate></item><item><title>HTTPS requests with client certificates in Clojure</title><link>https://www.lvh.io/posts/https-requests-with-client-certificates-in-clojure.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;The vast majority of TLS connections only authenticate the
server. When the client opens the connection, the server sends its
certificate. The client checks the certificate against the list of
certificate authorities that it knows about. The client is typically
authenticated, but over the inner HTTP connection, not at a TLS level.&lt;/p&gt;
&lt;p&gt;That isn't the only way TLS can work. TLS also supports authenticating
clients with certificates, just like it authenticates servers. This is
called mutually authenticated TLS, because both peers authenticate
each other. At Rackspace Managed Security, we use this for all
communication between internal nodes. We also operate our own
certificate authority to sign all of those certificates.&lt;/p&gt;
&lt;p&gt;One major library, &lt;a href="https://github.com/http-kit/http-kit"&gt;&lt;code&gt;http-kit&lt;/code&gt;&lt;/a&gt;, makes use of Java's
&lt;code&gt;javax.net.ssl&lt;/code&gt;, notably &lt;code&gt;SSLContext&lt;/code&gt; and &lt;code&gt;SSLEngine&lt;/code&gt;. These Java APIs
are exhaustive, and very... Java. While it's easy to make fun of these
APIs, most other development environments leave you using OpenSSL,
whose APIs are patently misanthropic. While some of these APIs do
leave something to be desired, &lt;a href="https://aphyr.com/"&gt;aphyr&lt;/a&gt; has done a lot of the
hard work of making them more palatable with
&lt;a href="https://github.com/aphyr/less-awful-ssl"&gt;&lt;code&gt;less-awful-ssl&lt;/code&gt;&lt;/a&gt;. That gives you an
&lt;code&gt;SSLContext&lt;/code&gt;. Request methods in &lt;code&gt;http-kit&lt;/code&gt; have an &lt;code&gt;opts&lt;/code&gt; map that
you can pass a &lt;code&gt;:sslengine&lt;/code&gt; object to. Given an &lt;code&gt;SSLContext&lt;/code&gt;, you just
need to do &lt;code&gt;(.createSSLEngine ctx)&lt;/code&gt; to get the engine object you want.&lt;/p&gt;
&lt;p&gt;Another major library, &lt;a href="https://github.com/dakrone/clj-http"&gt;&lt;code&gt;clj-http&lt;/code&gt;&lt;/a&gt;, uses lower-level
APIs. Specifically, it requires [&lt;code&gt;KeyStore&lt;/code&gt;][keystore] instances for
its &lt;code&gt;:key-store&lt;/code&gt; and &lt;code&gt;:trust-store&lt;/code&gt; options. That requires diving deep
into Java's cryptographic APIs, which, as mentioned before, might be
something you want to avoid. While &lt;code&gt;clj-http&lt;/code&gt; is probably the most
popular library, if you want to do fancy TLS tricks, you probably want
to use &lt;code&gt;http-kit&lt;/code&gt; instead for now.&lt;/p&gt;
&lt;p&gt;My favorite HTTP library is &lt;a href="http://aleph.io/"&gt;&lt;code&gt;aleph&lt;/code&gt;&lt;/a&gt; by
&lt;a href="http://ideolalia.com/"&gt;Zach Tellman&lt;/a&gt;.  It uses Netty instead of the usual Java IO
components. Fortunately, Netty's API is at least marginally friendlier
than the one in &lt;code&gt;javax.net.ssl&lt;/code&gt;. Unfortunately, there's no
&lt;code&gt;less-awful-ssl&lt;/code&gt; for Aleph. Plus, since I'm using &lt;a href="https://github.com/ptaoussanis/sente"&gt;&lt;code&gt;sente&lt;/code&gt;&lt;/a&gt; for
asynchronous client-server communication, which doesn't have support
for &lt;code&gt;aleph&lt;/code&gt; yet. So, I'm comfortably stuck with &lt;code&gt;http-kit&lt;/code&gt; for now.&lt;/p&gt;
&lt;p&gt;In conclusion, API design &lt;em&gt;is&lt;/em&gt; UX design. The library that "won" for
us was simply the one that was easiest to use.&lt;/p&gt;
&lt;p&gt;For a deeper dive in how TLS and its building blocks work, you should
watch my talk, &lt;a href="https://www.youtube.com/watch?v=3rmCGsCYJF8"&gt;Crypto 101&lt;/a&gt;, or the matching &lt;a href="https://www.crypto101.io"&gt;book&lt;/a&gt;. It's
free! Oh, and if you're looking for information security positions
(that includes entry-level!) in an inclusive and friendly environment
that puts a heavy emphasis on teaching and personal development, you
should get in touch with me at &lt;code&gt;_@lvh.io&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/https-requests-with-client-certificates-in-clojure.html</guid><pubDate>Thu, 02 Jul 2015 15:53:20 GMT</pubDate></item><item><title>Call for proposal proposals</title><link>https://www.lvh.io/posts/call-for-proposal-proposals.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm excited to announce that I was invited to speak at PyCon
PL. Hence, I'm preparing to freshen up my arsenal of talks for the
coming year. The organizers have very generously given me a lot of
freedom regarding what to talk about.&lt;/p&gt;
&lt;p&gt;I'd like to do more security talks as well as shift focus towards a
more technical audience, going more in-depth and touching on more
advanced topics.&lt;/p&gt;
&lt;h2&gt;Candidates&lt;/h2&gt;
&lt;h3&gt;Object-capability systems&lt;/h3&gt;
&lt;p&gt;Capabilities are a better way of thinking about authorization. A
capability ("cap") gives you the authority to perform some action,
without giving you any other authority. Unlike role-based access
control systems, capability based systems nearly always fail-closed;
if you don't have the capability, you simply don't have enough
information to perform an action. Contrast this with RBAC systems,
where authorization constraints are enforced with pinky swears, and
therefore often subverted.&lt;/p&gt;
&lt;p&gt;I think I can make an interesting case for capability systems to any
technical audience with some professional experience. Just talk about
secret management, and how it's nearly always terrifying! This gives
me an opportunity to talk about &lt;a href="https://github.com/lvh/icecap"&gt;&lt;code&gt;icecap&lt;/code&gt;&lt;/a&gt;
(&lt;a href="https://github.com/lvh/icecap/wiki/Introduction"&gt;docs&lt;/a&gt;) and &lt;a href="https://github.com/lvh/shimmer"&gt;&lt;code&gt;shimmer&lt;/code&gt;&lt;/a&gt; (&lt;a href="https://www.lvh.io/posts/securing-apis-with-shims.html"&gt;blog&lt;/a&gt;,
my favorite pastimes.&lt;/p&gt;
&lt;h3&gt;Putting a backdoor in &lt;code&gt;RDRAND&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;I've &lt;a href="https://www.lvh.io/posts/2013/10/thoughts-on-rdrand-in-linux.html"&gt;blogged about this before&lt;/a&gt; before, but I think I
could turn it into a talk. The short version is that Linux's PRNG
mixes in entropy from the &lt;code&gt;RDRAND&lt;/code&gt; in a way that would allow a
malicious implementation to control the output of the PRNG in ways
that would be indistinguishable to a (motivated) observer.&lt;/p&gt;
&lt;p&gt;As a proof of concept, I'd love to demo the attack, either in software
(for example, with QEMU) or even in hardware with an open core. I
could also go into the research that's been done regarding hiding
stuff on-die. Unfortunately, the naysayers so far have relied on
moving the goalposts continuously, so I'm not sure that would convince
them this is a real issue.&lt;/p&gt;
&lt;h3&gt;Retroreflection&lt;/h3&gt;
&lt;p&gt;An opportunity to get in touch with my languishing inner electrical
engineer! It turns out that when you zap radio waves at most hardware,
the reflection gets modulated based on what it's doing right now. The
concept became known as &lt;a href="https://en.wikipedia.org/wiki/Tempest_%28codename%29"&gt;TEMPEST&lt;/a&gt;, an NSA program. So far,
there's little public research on how feasible it is for your average
motivated hacker. This is essentially &lt;a href="https://en.wikipedia.org/wiki/Van_Eck_phreaking"&gt;van Eck phreaking&lt;/a&gt;,
with 2015 tools. There's probably some interesting data to pick off of
USB HIDs, and undoubtedly a myriad of interesting devices controlled
by low-speed RS-232. Perhaps wireless JTAG debugging?&lt;/p&gt;
&lt;h2&gt;The unfinished draft bin&lt;/h2&gt;
&lt;h3&gt;Underhanded curve selection&lt;/h3&gt;
&lt;p&gt;Another talk in the underhanded cryptography section I've considered
would be about underhanded elliptic curve selection. Unfortunately,
bringing the audience up to speed with the math to get something out
of it would be impossible in one talk slot. People already familiar
with the math are also almost certainly familiar with the argument for
rigid curves.&lt;/p&gt;
&lt;h3&gt;Web app authentication&lt;/h3&gt;
&lt;p&gt;Some folks asked for a tutorial on how to authenticate to web
apps. I'm not sure I can turn that into a great talk. There's a lot of
general stuff that's reasonably obvious, and then there's highly
framework-specific stuff. I don't really see how I can provide a lot
of value for people's time.&lt;/p&gt;
&lt;h2&gt;Feedback&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://twitter.com/dreid"&gt;David Reid&lt;/a&gt; and &lt;a href="https://twitter.com/DLitz"&gt;Dwayne Litzenberger&lt;/a&gt; made similar,
excellent points. They both recommend talking about object-capability
systems. Unlike the other two, it will (hopefully) actually help
people build secure software. Also, the other two will just make
people feel sad. I feel like those points generalize to all attack
talks; are they just not that useful?&lt;/p&gt;&lt;/div&gt;</description><guid>https://www.lvh.io/posts/call-for-proposal-proposals.html</guid><pubDate>Sat, 13 Jun 2015 17:07:13 GMT</pubDate></item><item><title>Everything I've learned about running a financial aid program</title><link>https://www.lvh.io/posts/everything-ive-learned-about-running-a-financial-aid-program.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;For the past two years, I've been running PyCon's financial aid
program. Starting this year, the event coordinator has asked all staff
members to document what they do for PyCon. Firstly, this helps to
objectively recognize the hard work done by our (volunteer) staff, and
to help make sure there is continuity when the time comes to pass the
torch. Since organizers of other conferences have expressed interest
in my opinions for creating their own financial aid programs, I am
posting my notes publicly instead.&lt;/p&gt;
&lt;p&gt;This is a collection of hard-earned opinions, and is very much work in
progress. It's written as if it were a conversation with a
hypothetical financial aid organizer; so, whenever I say "you", I mean
you, the awesome person running financial aid at a conference
somewhere.&lt;/p&gt;
&lt;h2&gt;Basics&lt;/h2&gt;
&lt;p&gt;Financial aid programs are one of the most effective ways a software
foundation can spend their money. Even if you completely ignore the
effect it has on diversity, the number of speakers, sprinters and
other contributors that attended PyCon thanks to the financial aid
program is staggering.&lt;/p&gt;
&lt;h3&gt;Naming your program&lt;/h3&gt;
&lt;p&gt;I inherited the term "Financial Aid". It's a fine term, but some other
conferences have come up with different terms that you may want to
consider, like "opportunity grants" and "diversity grants".&lt;/p&gt;
&lt;h3&gt;Taking care of yourself&lt;/h3&gt;
&lt;p&gt;Running a financial aid program is a lot of work. It scales linearly
with the number of applicants; it's your job to create a process that
keeps the work per applicant small, so that you can make the number of
applicants large. (You'll know you've succeeded when the fixed
overhead dominates, and it wouldn't really matter if you added another
dozen people.)&lt;/p&gt;
&lt;p&gt;It is also an exercise in deferred gratification. Typically, you will
need to start preparing about a year before the conference. The
gratification part only comes at the conference itself. Since you'll
probably be quite busy as an organizer, it may only come after the
conference is over. You probably want to make sure that you have an
excellent social circle and that you're fairly self-motivated.&lt;/p&gt;
&lt;p&gt;As the Financial Aid Chair, I have been on the receiving end of verbal
abuse once. Don't put up with it.&lt;/p&gt;
&lt;h3&gt;Beat the drum&lt;/h3&gt;
&lt;p&gt;Your financial aid program is useless if people don't know about it.&lt;/p&gt;
&lt;p&gt;Some very talented speakers refrain from sending talk proposals
because they don't know if they can afford to attend.&lt;/p&gt;
&lt;h3&gt;Numbers&lt;/h3&gt;
&lt;p&gt;PyCon's financial aid program is quite large. There are a number of
reasons for that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;PyCon's financial aid program has been around for many years, so
  it's quite mature.&lt;/li&gt;
&lt;li&gt;The program can count on support from PyCon leadership and the
  Python Software Foundation.&lt;/li&gt;
&lt;li&gt;Because PyCon US is the largest PyCon in the world, it acts as a
  nexus for people across the globe; therefore, it's important for the
  Python community that as many people as possible have a chance to
  attend.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is just to give you a ballpark idea of our numbers.&lt;/p&gt;
&lt;p&gt;Regardless of what your numbers will be, expect that the primary
bottleneck of your financial aid program will simply be lack of funds.&lt;/p&gt;
&lt;h2&gt;Confusing parts and sad truths&lt;/h2&gt;
&lt;h3&gt;No-shows&lt;/h3&gt;
&lt;p&gt;A lot of people will not show up, and not notify you (or notify you in
the days around the conference). Sometimes, there's good reasons
(illness, emergencies...). Sometimes, the reasons are less
great. Sometimes, you won't know the reason.&lt;/p&gt;
&lt;p&gt;From the perspective of the Financial Aid Chair, no-shows are
terrible. It's a dead grant: money that's been allocated that can't
easily be translated into an extra attendee. Hence, many of the
suggestions I make for running financial aid processes are focused on
minimizing no-shows.&lt;/p&gt;
&lt;h3&gt;Visas and travel&lt;/h3&gt;
&lt;p&gt;Many recipients have to cancel because they are unable to acquire
visas to Canada or the United States. In some cases, the visa process
took several months and simply did not complete in time for the
conference. In others the visas were declined for various reasons.&lt;/p&gt;
&lt;p&gt;Occam's razor tells me that many countries, particularly the United
States, to some extent now Canada, but also Schengen zone countries
are simply actively hostile to foreigners visiting their country.&lt;/p&gt;
&lt;h2&gt;Planning&lt;/h2&gt;
&lt;h3&gt;Stand by your Chair&lt;/h3&gt;
&lt;p&gt;At the end of the day, someone's responsible for making your
conference all it can be. That position is typically called the
Conference Chair. They get help from teams like the Program Committee
and Financial Aid to make that happen. At the end of the day they make
the hard calls, and you have to execute within their guidelines. That
typically includes the budget, but it also includes how you want to
allocate grants. You will almost certainly be resource-constrained, so
there are trade-offs to be made:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Do you want to help newbies, or advanced programmers?&lt;/li&gt;
&lt;li&gt;Do you want to help marginalized groups? Which ones? How much?&lt;/li&gt;
&lt;li&gt;Do you want repeat attendees, or first timers?&lt;/li&gt;
&lt;li&gt;Do you want a few people from all over the globe, or many locals?&lt;/li&gt;
&lt;li&gt;Do you want to benefit people who directly contribute to the
  conference? Which ones (speakers, staff...)? How much?&lt;/li&gt;
&lt;li&gt;Do we care if people are receiving funds from other places? What if
  their employer is paying? What if their employer is also a sponsor?
  Does it make sense for them to give us &lt;em&gt;x&lt;/em&gt; sponsorship fees when
  we're giving them a significant portion of that back in financial
  aid?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Your budget is, unfortunately, zero sum. Every group you benefit means
less for everyone else. Helping everyone is the same as helping
no-one. Everyone wants to help everyone, but it's unlikely you'll get
to do that. Make everyone understands exactly what you want to
accomplish; you don't want to have this argument in the middle of
trying to run a financial aid process.&lt;/p&gt;
&lt;h3&gt;Free or reduced-price tickets&lt;/h3&gt;
&lt;p&gt;For many conferences, the tickets themselves can be quite
expensive. It makes sense to provide them to financial aid recipients
at no (or reduced) charge as part of their grant.&lt;/p&gt;
&lt;p&gt;PyCon previously provided free registration, but now provides
reduced-cost registration. This helps with no-shows, giving
applicants a financial incentive to let you know if they can't attend.&lt;/p&gt;
&lt;p&gt;Make sure that you document clearly that people will be receiving
tickets, at what price they'll be receiving them, and that their spots
are reserved. Common concerns from financial aid applicants:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;"Your conference blog says that you're sold out, and I haven't
  received financial aid yet. Will I be able to attend?"&lt;/li&gt;
&lt;li&gt;"I've already registered to reserve my spot; what do I do now that I
  get financial aid?"&lt;/li&gt;
&lt;li&gt;"I'm a student. Will I still be able to register at the student rate
  if I apply for financial aid?"&lt;/li&gt;
&lt;li&gt;"I applied for a larger amount because I didn't think ticket price
  would be included." (Unfortunately, most people tell you this far
  too late.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As usual, clarity in communication is key here.&lt;/p&gt;
&lt;p&gt;Previous years, PyCon optionally provided free registration for people
who asked. This optional part was somewhat confusing. Whatever you do,
make it part of the default grant application. That also means that
you should probably offer the reduced-price ticket to anyone who
applies for financial aid, even if you can't otherwise give them a
grant. Otherwise, someone who applies for financial aid for whom you
simply don't have enough funds will get punished twice: no financial
aid, and no access to early bird ticket price.&lt;/p&gt;
&lt;h3&gt;Housing&lt;/h3&gt;
&lt;p&gt;Housing, in the context of financial aid, means that you pay for a
bunch of hotel rooms for various dates at your conference, and then
put financial aid recipients in them. To save costs, you want to pair
them up, and you want to utilize the rooms maximally.&lt;/p&gt;
&lt;p&gt;Some people think that it's a good idea to organize housing as part of
your travel grants. Those people are mistaken. Housing is a terrible
idea all round:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It doesn't scale, up or down. If you're small, you can't negotiate a
  worthwhile hotel block contract. If you're big, the system crashes
  under its /O(NÂ²)/ weight (see below).&lt;/li&gt;
&lt;li&gt;It's not good for the financial aid recipients. While there are many
  nice things to be said about conference hotels, they are typically
  not economical. When we still organized housing, many financial aid
  recipients opted out: they could get significantly more bang for
  their buck otherwise.&lt;/li&gt;
&lt;li&gt;It's not good for the conference. People leave, people join, people
  change dates, people have preferences (or hard constraints) about
  who they'll stay with... Doing this for any nontrivial number of
  people is a logistic nightmare; doing it for trivial number of
  people isn't worth it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Having humans solve the allocation problem produces inefficiencies at
larger scales (i.e. humans typically come up with fairly suboptimal
solutions). It's a pretty tricky problem to solve even with computers
(believe me, I've &lt;a href="https://www.lvh.io/posts/2014/03/optimization-problems-and-pycon-financial-aid.html"&gt;tried&lt;/a&gt; &lt;a href="http://www.lvh.io/posts/2014/03/optimal-hotel-room-pairing.html"&gt;extensively&lt;/a&gt;), but computers
will never solve the logistic issues caused by human factors.&lt;/p&gt;
&lt;p&gt;PyCon used to manage housing for financial aid recipients. Getting rid
of this was the single best decision I've ever made for the financial
aid process.&lt;/p&gt;
&lt;p&gt;It worked out quite well for the attendees too. Providing simple tools
(i.e. the equivalent of a classifieds section) is more than ample to
help people find great groups to room-share with. This &lt;em&gt;increased&lt;/em&gt;
opportunities for roomsharing, because it made it much less of a
hassle to mix-and-match between financial aid recipients and other
attendees.&lt;/p&gt;
&lt;p&gt;Plenty of FA people stayed in large AirBnBs or the like in groups of 6
or more, and ended up getting fantastic deals that allowed them to
stay an extra few days to attend other events like sprints and
tutorials.&lt;/p&gt;
&lt;h2&gt;Before the conference: from applications to allocation&lt;/h2&gt;
&lt;h3&gt;Applications&lt;/h3&gt;
&lt;p&gt;Keep it simple. Use a form generator (Google Forms or Wufoo or
something) for data collection. All of the processing was done with
simple Python scripts, most of it in an IPython/Jupyter notebook. This
enables you to create well-documented processes, which helps
everyone. CSV files are your best friend.&lt;/p&gt;
&lt;p&gt;Make as many fields on the application form as possible directly
translatable to something in your allocation process. Multiple choice
and boolean values are your friend; the review process will make sure
the applications are accurate. Have free-form fields for documenting
things, but only use them in the review process. For example, you can
have a multiple choice field for Python expertise ranging from
beginner to expert, and then have a free-form field for applicants'
portfolios.&lt;/p&gt;
&lt;p&gt;Names are weird. There are lots of falsehoods programmers believe
about names &lt;a href="http://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/"&gt;(link)&lt;/a&gt;. You probably want to ask for a legal
name; it's quite likely that you need to keep the legal name around
for your records. Ask a lawyer and/or an accountant for
details. However, you probably want to ask for an (optional) preferred
name as well, which you should always use when communicating with
them. There's a bunch of reasons those might be different, and people
may have excellent reasons for not using their legal names. For
example, a legal name might give someone away as being
transgender. Sometimes, you want to do that just for your /own/
convenience. People will put all sorts of stuff down as their "name",
but full legal names are quite consistent. This can be useful to match
up records from different sources, such as your registration database.&lt;/p&gt;
&lt;p&gt;Speaking of gender, asking for people's gender is also tricky. Make
sure you have at least a cursory understanding of how gender works
before you ask. Always have a "decline to answer" button, which is
distinct from "other/nonbinary". If all you really want to know is
whether someone qualifies for earmarked funds, just ask the specific
question you want to know; e.g. "Apply for a PyLadies grant (people
who self-identify as women only, please)".&lt;/p&gt;
&lt;p&gt;As usual in programming, state is the bane of your existence. Keep it
in one place whenever possible. A (Google Drive) spreadsheet works
just fine. Your scripts should operate on data extracted from them
(again, CSV works fine), but not store any state. This is trickier
than it sounds, but the alternative is that you'll probably end up
destroying some data.&lt;/p&gt;
&lt;h3&gt;Review&lt;/h3&gt;
&lt;p&gt;Reviews are easy to do in parallel, so get help from volunteers if
needed. Establish clear guidelines for what your discrete values
(e.g. Python experience) mean; not everyone agrees on what "expert"
means.&lt;/p&gt;
&lt;h3&gt;Allocation&lt;/h3&gt;
&lt;p&gt;I've &lt;a href="https://www.lvh.io/posts/2014/03/optimization-problems-and-pycon-financial-aid.html"&gt;written about allocation before&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;PyCon allocates approximately 15% over budget; i.e. the budget that we
allocate is 1.15x the actual grant budget. This does not include aid
in the form of e.g. reduced ticket prices; remember to account for
those separately!&lt;/p&gt;
&lt;p&gt;PyCon's no-show rate is somewhere between 10% and 20%, but it's very
hard to predict if the factors that contribute to that will affect
your conference equally.&lt;/p&gt;
&lt;p&gt;As mentioned in that previous blog post, you don't always want to
allocate the full grant asked for. People will still be able to attend
with partial grants but typically wouldn't with an empty
grant. Therefore it typically makes sense to reduce everyone's grant
slightly if that allows you to provide more grants.&lt;/p&gt;
&lt;p&gt;We ended up going with a fairly simple "flood fill" algorithm. An
applicant's score maps to a fraction of the budget:&lt;/p&gt;
&lt;p&gt;$$f_i = \frac{s_i}{\sum_j s_j}$$&lt;/p&gt;
&lt;p&gt;Where \(f_i\) is the fraction of the budget you're willing to assign
to applicant \(i\), \(s_i\) is an applicant's score.&lt;/p&gt;
&lt;p&gt;If \(f_i \ge q \cdot r_i\) (where \(q\) is the fraction of the
grant you're willing to allocate and \(r_i\) is what the applicant
requested, you grant them \(q \cdot r_i\); otherwise, grant them 0.&lt;/p&gt;
&lt;p&gt;Some applicants will be below this fraction, some will be above. They
could be below this fraction because they have a very high score
(e.g. they are a speaker), or because they're "low hanging fruit" and
not asking for very much money.&lt;/p&gt;
&lt;p&gt;That means that if you run the algorithm again, the fractions will be
bigger; the people that received allocations in the previous round
were allocated less than what would've been their "fair share". Rinse,
repeat until you're out of money.&lt;/p&gt;
&lt;h2&gt;Communications&lt;/h2&gt;
&lt;p&gt;Have a central website where people can see their current status and
updates, both specific to the applicant and generic to the entire
process. Training people to expect information there will drastically
reduce the number of repetitive questions you get to answer by e-mail,
which will contribute enormously to your happiness. Therefore, if
people ask questions that are answered there; answer, be kind, but
point out where they could have gotten that information from.&lt;/p&gt;
&lt;p&gt;Most of the things you will have to say will be generic points about
the process. Nonetheless, I have spent huge amounts of time answering
individual questions about that generic process, which got get quite
tedious. Hence, even a static page that doesn't show any information
specific to the applicant, but just explaining the process in detail
is extremely valuable.&lt;/p&gt;
&lt;p&gt;Being up-front about how your process works is also great for
prospective applicants who wouldn't feel comfortable asking. This also
attracts speakers to submit talk proposals; many speakers would not
propose a talk because they know they can't afford to come without
financial aid. Therefore, it's important to communicate clearly if you
intend to support speakers, both through your financial aid
communication and your call for papers.&lt;/p&gt;
&lt;p&gt;Once that fails, send e-mail. Once you're over a dozen or so
recipients, use &lt;a href="http://www.mailgun.com/"&gt;Mailgun&lt;/a&gt;. Emails
particularly automated from your personal email account is a good way
to get stuck in spam filters.&lt;/p&gt;
&lt;h2&gt;Disbursement (giving out money)&lt;/h2&gt;
&lt;p&gt;First off, talk to your treasurer. Possibly talk to a lawyer,
too. It's quite possible, particularly if you're in the United States,
that giving out a bunch of money as a non-profit comes with some
fairly complex strings attached. For example, you probably have
certain standards in terms of what records you have to keep.&lt;/p&gt;
&lt;p&gt;As a European, I found it somewhat comical to still see checks in
active use, but hey; it works. For many parts of the world (apparently
not the United States, though) wire transfers are how you send money
to people. PayPal seems to work better for larger, established
organizations that use it often. There is less of a problem with the
accounts or funds being frozen. It does actively restrict (or, perhaps
more accurately, enforces restrictions on) sending funds to certain
countries, including Brazil and India.&lt;/p&gt;
&lt;p&gt;Cash works, but is hard to scale. With PyCon's budget of well over
$100,000.00, managing cash is clearly less than ideal.&lt;/p&gt;
&lt;p&gt;At the end of the day, be pragmatic. Do whatever your recipients can
accept. Be sure to ask ahead of time, as your financial aid programs
may prove to be successful in bringing people in from very different
countries, with very different cultures and very different means
available to them for accepting your grant. This is the case for
PyCon, but I consider that a superb problem to have.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I'd like to thank the following people in no particular order:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ewa Jodlowska, for managing PyCon and being the love of my life&lt;/li&gt;
&lt;li&gt;Van Lindberg, for continuously inspiring me to serve&lt;/li&gt;
&lt;li&gt;Diana Clarke, for Charing PyCon US in Montreal&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>mathjax</category><category>pycon</category><guid>https://www.lvh.io/posts/everything-ive-learned-about-running-a-financial-aid-program.html</guid><pubDate>Sun, 26 Apr 2015 04:08:36 GMT</pubDate></item></channel></rss>