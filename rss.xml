<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>lvh</title><link>https://www.lvh.io/</link><description>lvh's blog</description><atom:link href="https://www.lvh.io/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 30 Oct 2019 14:32:46 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How (not) to sign a JSON object</title><link>https://www.lvh.io/posts/how-not-to-sign-a-json-object/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Last year we did a blog post on interservice auth. This post is mostly about authenticating consumers to an API. That’s a related but subtly different problem: you can probably impose more requirements on your internal users than your customers. The idea is the same though: you’re trying to differentiate between a legitimate user and an attacker, usually by getting the legitimate user to prove that they know a credential that the attacker doesn’t.&lt;/p&gt;
&lt;h2&gt;You don’t really want a signature&lt;/h2&gt;
&lt;p&gt;When cryptography engineers say "signature" they tend to mean something asymmetric, like RSA or ECDSA. Developers reach for asymmetric tools too often. There are a lot of ways to screw them up. By comparison, symmetric “signing” (MACs) are easy to use and hard to screw up. HMAC is bulletproof and ubiquitous.&lt;/p&gt;
&lt;p&gt;Unless you have a good reason why you need an (asymmetric) signature, you want a MAC. If you really do want a signature, check out our Cryptographic Right Answers post to make that as safe as possible. For the rest of this blog post, "signing" means symmetrically, and in practice that means HMAC.&lt;/p&gt;
&lt;h2&gt;How to sign a JSON object&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Serialize however you want.&lt;/li&gt;
&lt;li&gt;HMAC. With SHA256? Sure, whatever. We did &lt;a href="https://latacora.singles/2018/04/03/cryptographic-right-answers.html"&gt;a blog post&lt;/a&gt; on that too.&lt;/li&gt;
&lt;li&gt;Concatenate the tag with the message, maybe with a comma in between for easy parsing or something.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Wait, isn’t that basically a HS256 JWT?&lt;/h2&gt;
&lt;p&gt;Shut up. Anyway, no, because you need to parse a header to read the JWT, so you inherit all of the problems that stem from that.&lt;/p&gt;
&lt;h2&gt;How &lt;em&gt;not&lt;/em&gt; to sign a JSON object, if you can help it&lt;/h2&gt;
&lt;p&gt;Someone asked how to sign a JSON object "in-band": where the tag is part of the object you’re signing itself. That's a niche use case, but it happens. You have a JSON object that a bunch of intermediate systems want to read and it’s important  none of them mess with its contents. You can't just send &lt;code&gt;tag || json&lt;/code&gt;: that may be the cryptographically right answer, but now it's not a JSON object anymore so third party services and middleboxes will barf. You also can't get them to reliably pass the tag around as metadata (via a HTTP header or something). You need to put the key &lt;em&gt;on the JSON object&lt;/em&gt;, somehow, to "transparently" sign it. Anyone who cares about validating the signature can, and anyone who cares that the JSON object has a particular structure doesn't break (because the blob is still JSON and it still has the data it's supposed to have in all the familiar places).&lt;/p&gt;
&lt;p&gt;This problem sort-of reminds me of format-preserving encryption. I don’t mean that in a nice way, because there’s no nice way to mean that. Format-preserving encryption means you encrypt a credit card number and the result still sorta looks like a credit card number. It’s terrible and you only do it because you have to. Same with in-band JSON signing.&lt;/p&gt;
&lt;p&gt;As stated, in-band JSON signing means modifying a JSON object (e.g. removing the HMAC tag) and validating that it’s the same thing that was signed. You do that by computing the HMAC again and validating the result. Unfortunately there are infinitely many equal JSON objects with distinct byte-level representations (for some useful definition of equality, like Python’s builtin ==).&lt;/p&gt;
&lt;p&gt;Some of those differences are trivial, while others are fiendishly complicated. You can add as many spaces as you want between some parts of the grammar, like after the colon and before the value in an object. You can reorder the keys in an object. You can escape a character using a Unicode escape sequence (\u2603) instead of using the UTF-8 representation. "UTF-8" may be a serialization format for Unicode, but it’s not a canonicalization technique. If a character has multiple diacritics, they might occur in different orders. Some characters can be written as a base character plus a diacritic, but there’s also an equivalent single character. You can’t always know what the “right” character out of context: is this the symbol for the unit of resistance (U+2126 OHM SIGN) or a Greek capital letter Omega (U+03A9)? Don’t even get me started on the different ways you can write the same floating point number!&lt;/p&gt;
&lt;p&gt;Three approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Canonicalize the JSON.&lt;/li&gt;
&lt;li&gt;Add the tag and the exact string you signed to the object, validate the signature and then validate that the JSON object is the same as the one you got.&lt;/li&gt;
&lt;li&gt;Create an alternative format with an easier canonicalization than JSON.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Canonicalization&lt;/h3&gt;
&lt;p&gt;Canonicalization means taking an object and producing a unique representation for it. Two objects that mean the same thing ("are equal") but are expressed differently canonicalize to the same representation.&lt;/p&gt;
&lt;p&gt;Canonicalization is a quagnet, which is a term of art in vulnerability research meaning quagmire and vulnerability magnet. You can tell it’s bad just by how hard it is to type ‘canonicalization’.&lt;/p&gt;
&lt;p&gt;My favorite canonicalization bug in recent memory is probably Kelby Ludwig’s SAML bug. Hold onto your butts, because this bug broke basically every SAML implementation under the sun in a masterful stroke. It used NameIds (SAML-speak for "the entity this assertion is about") that look like this:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;NameId&amp;gt;&lt;/span&gt;barney@latacora.com&lt;span class="c"&gt;&amp;lt;!----&amp;gt;&lt;/span&gt;.evil.com&lt;span class="nt"&gt;&amp;lt;/NameId&amp;gt;&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The common canonicalization strategy ("exc-c14n") will remove comments, so that side sees “barney@latacora.com.evil.com”. The common parsing strategy (“yolo”) disagrees, and sees a text node, a comment, and another text node. Since everyone is expecting a NameId to have one text node, you grab the first one. But that says barney@latacora.com, which isn’t what the IdP signed or your XML-DSIG library validated.&lt;/p&gt;
&lt;p&gt;Not to worry: we said we were doing JSON, and JSON is not XML. It’s simpler! Right? There are at least two specs here: Canonical JSON (from OLPC) and an IETF draft (https://tools.ietf.org/id/draft-rundgren-json-canonicalization-scheme-05.html). They work? Probably? But they’re not fun to implement.&lt;/p&gt;
&lt;h3&gt;Include the exact thing you’re signing&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as "to validate a signature I need an exact byte representation of what to sign" and canonicalization is just the default mechanism for getting to an exact byte representation, you could also just attach a specific byte serialization to the object with a tag for it.&lt;/p&gt;
&lt;p&gt;You validate the tag matches the specific serialization, and then you validate that the specific serialization matches the outside object with the tag and specific serialization removed. The upside is that you don’t need to worry about canonicalization; the downside is your messages are about twice the size that they need to be. You can maybe make that a little better with compression, since the repeated data is likely to compress well.&lt;/p&gt;
&lt;h3&gt;The regex bait and switch trick&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as being about already having a perfectly fine serialization to compute a tag over, but the JSON parser/serializer roundtrip screwing it up after you compute the tag, you might try to do something to the serialized format that doesn't know it's JSON. This is a variant of the previous approach: you're just not adding a &lt;em&gt;second&lt;/em&gt; serialization to compute the tag over.&lt;/p&gt;
&lt;p&gt;The clever trick here is to add a field of the appropriate size for your tag with a well-known fake value, then HMAC, then swap the value. For example, if you know the tag is HMAC-SHA256, your tag size is 256 bits aka 32 bytes aka 64 hex chars. You add a unique key (something like &lt;code&gt;__hmac_tag&lt;/code&gt;) with a value of 64 well-known bytes, e.g. 64 ASCII zero bytes. Serialize the object and compute its HMAC. If you document some subset of JSON serialization (e.g. where CRLFs can occur or where extra spaces can occur), you know that the string &lt;code&gt;"__hmac_tag": “000...”&lt;/code&gt; will occur in the serialized byte stream. Now, you can use string replacement to shiv in the real HMAC value. Upon receipt, the decoder finds the tag, reads the HMAC value, replaces it with zeroes, computes the expected tag and compares against the previously read value.&lt;/p&gt;
&lt;p&gt;Because there’s no JSON roundtripping, the parser can’t mess up the JSON object’s specific serialization. The key needs to be unique because of course the string replacement or regular expression doesn’t know how to parse JSON.&lt;/p&gt;
&lt;p&gt;This feels weirdly gross? But at the same time probably less annoying than canonicalization. And it doesn't work if any of the middleboxes modiy the JSON through a parse/re-serialize cycle.&lt;/p&gt;
&lt;h3&gt;An alternative format&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as "canonicalization is hard because JSON is more complex than what I really want to sign", you might think the answer is to reformat the data you want to sign in a format where canonicalization is easy or even automatic.  AWS Signatures do this: there’s a serialization format that’s far less flexible than JSON where you put some key parameters, and then you HMAC that. (There’s an interesting part to it where it also incorporates the hash of the exact message you’re signing -- but we’ll get to that later.)&lt;/p&gt;
&lt;p&gt;This is particularly attractive if there’s a fixed set of simple values you have to sign, or more generally if the thing you’re signing has a predictable format.&lt;/p&gt;
&lt;h2&gt;Request signing in practice&lt;/h2&gt;
&lt;p&gt;Let’s apply this model to a case study of request signing has worked through the years in some popular services. These are not examples of how to do it well, but rather cautionary tales.&lt;/p&gt;
&lt;p&gt;First off, AWS. AWS requires you to sign API requests. The current spec is "v4", which tells you that there is probably at least one interesting version that preceded it.&lt;/p&gt;
&lt;h3&gt;AWS Signing v1&lt;/h3&gt;
&lt;p&gt;Let’s say an AWS operation CreateWidget takes attribute Name which can be any ASCII string. It also takes an attribute Unsafe, which is false by default and the attacker wishes were true. V1 concatenates the key-value pairs you’re signing, so something like Operation=CreateWidget&amp;amp;Name=iddqd became OperationCreateWidgetNameiddqd. You then signed the resulting string using HMAC.&lt;/p&gt;
&lt;p&gt;The problem with this is if I can get you to sign messages for creating widgets with arbitrary names, I can get you to sign operations for arbitrary CreateWidget requests: I just put all the extra keys and values I want in the value you’re signing for me. For example, the request signature for creating a widget named &lt;code&gt;iddqdUnsafetrue&lt;/code&gt; is exactly the same as a request signature for creating a widget named &lt;code&gt;iddqd&lt;/code&gt; with Unsafe equal to true: OperationCreateWidgetNameiddqdUnsafetrue.&lt;/p&gt;
&lt;h3&gt;AWS Signing V2&lt;/h3&gt;
&lt;p&gt;Security-wise: fine.&lt;/p&gt;
&lt;p&gt;Implementation-wise: it’s limited to query-style requests (query parameters for GET, x-www-form-urlencoded for POST bodies) and didn’t support other methods, let alone non-HTTP requests. Sorting request parameters is a burden for big enough requests. Nothing for chunked requests either.&lt;/p&gt;
&lt;p&gt;(Some context: even though most AWS SDKs present you with a uniform interface, there are several different protocol styles in use within AWS. For example, EC2 and S3 are their own thing, some protocols use Query Requests (basically query params in GET queries and POST formencoded bodies), others use REST+JSON, some use REST+XML… There’s even some SOAP! But I think that’s on its way out.)&lt;/p&gt;
&lt;h3&gt;AWS Signing V3&lt;/h3&gt;
&lt;p&gt;AWS doesn’t seem to like V3 very much. The &lt;a href="https://docs.aws.amazon.com/general/latest/gr/sigv4_changes.html"&gt;"what’s new in v4 document"&lt;/a&gt; all but disavows it’s existence, and no live services appear to implement it. It had some annoying problems like distinguishing between signed and unsigned headers (leaving the service to figure it out) and devolving to effectively a bearer token when used over TLS (which is great, as long as it actually gets used over TLS).&lt;/p&gt;
&lt;p&gt;Given how AWS scrubbed it away, it’s hard to say anything with confidence. I’ve found implementations, but that’s not good enough: an implementation may only use a portion of the spec while the badness can be hiding in the rest.&lt;/p&gt;
&lt;h3&gt;AWS Signing V4&lt;/h3&gt;
&lt;p&gt;Security-wise: fine.&lt;/p&gt;
&lt;p&gt;Addressed some problems noted in V2; for example: just signs the raw body bytes and doesn’t care about parameter ordering. This is pretty close to the original recommendation: don’t do inline signing at all, just sign the exact message you’re sending and put a MAC tag on the outside. A traditional objection is that several equivalent requests would have a different representation, e.g. the same arguments but in a different order. It just turns out that in most cases that doesn’t matter, and API auth is one of those cases.&lt;/p&gt;
&lt;p&gt;Also note that all of these schemes are really outside signing, but they’re still interesting because they had a lot of the problems you see on an inline signing scheme (they were just mostly unforced errors).&lt;/p&gt;
&lt;h3&gt;AWS Signing V0&lt;/h3&gt;
&lt;p&gt;For completeness. It is even harder to find than V3: you have to spelunk some SDKs for it. I hear it might have been HMAC(k, service || operation || timestamp), so it didn’t really sign much of the request.&lt;/p&gt;
&lt;h3&gt;Flickr’s API signing&lt;/h3&gt;
&lt;p&gt;One commonality of the AWS vulnerabilities is that none of them attacked the primitive. All of them used HMAC and HMAC has always been safe. Flickr had exactly the same bug as AWS V1 signing, but also used a bad MAC. The tag you sent was MD5(secret + your_concatenated_key_value_pairs). We’ll leave the details of extension attacks for a different time, but the punchline is that if you know the value of H(secret + message) and don’t know s, you get to compute H(secret + message + glue + message2), where glue is some binary nonsense and message2 is an arbitrary attacker controlled string.&lt;/p&gt;
&lt;p&gt;A typical protocol where this gets exploited looks somewhat like query parameters. The simplest implementation will just loop over every key-value pair and assign the value into an associative array. So if you have user=lvh&amp;amp;role=user, I might be able to extend that to a valid signature for user=lvh&amp;amp;role=userSOMEBINARYGARBAGE&amp;amp;role=admin.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Just go ahead and always enforce TLS for your APIs.&lt;/li&gt;
&lt;li&gt;Maybe you don’t need request signing? A bearer token header is fine, or HMAC(k, timestamp) if you’re feeling fancy, or mTLS if you really care.&lt;/li&gt;
&lt;li&gt;Canonicalization is fiendishly difficult.&lt;/li&gt;
&lt;li&gt;Add a signature on the outside of the request body, make sure the request body is complete, and don’t worry about "signing what is said versus what is meant" -- it’s OK to sign the exact byte sequence.&lt;/li&gt;
&lt;li&gt;The corollary here is that it’s way harder to do request signing for a REST API (where stuff like headers and paths and methods matter) than it is to do signing for an RPC-like API.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/how-not-to-sign-a-json-object/</guid><pubDate>Thu, 25 Jul 2019 01:56:06 GMT</pubDate></item><item><title>Analyzing a simple encryption scheme using GitHub SSH keys</title><link>https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;(This is an introductory level analysis of a scheme involving RSA. If you're already comfortable with Bleichenbacher oracles you should skip it.)&lt;/p&gt;
&lt;p&gt;Someone pointed me at the following suggestion on the Internet for encrypting secrets to people based on their GitHub SSH keys. I like the idea of making it easier for people to leverage key material and tools they already have.  The encryption instructions are:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;"my secret"&lt;/span&gt; &amp;gt; message.txt
curl -q github.com/&lt;span class="nv"&gt;$USER&lt;/span&gt;.keys &lt;span class="p"&gt;|&lt;/span&gt; head -n &lt;span class="m"&gt;1&lt;/span&gt; &amp;gt; recipient.pub
ssh-keygen -e -m pkcs8 -f recipient.pub &amp;gt; recipient.pem
openssl rsautl -encrypt -pubin -inkey recipient.pem -ssl &lt;span class="se"&gt;\&lt;/span&gt;
    -in message.txt -out encrypted.txt
&lt;/pre&gt;


&lt;p&gt;Anything using an openssl command line tool makes me a little uncomfortable. Let's poke at it a little.&lt;/p&gt;
&lt;p&gt;We'll assume that that first key is really an RSA key and we don't have to worry about EdDSA or ECDSA (or heaven forbid, DSA). You're encrypting a password for someone. The straightforward threat model is an attacker who has the public key and ciphertext (but no plaintext) and wants to decrypt the ciphertext.&lt;/p&gt;
&lt;p&gt;There are a few ways you can try to attack RSA schemes. You could attack the underlying math: maybe the keys were generated with insufficient entropy (e.g. &lt;a href="https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/%5Bcve.mitre.org/cgi-bin/c...%5D(http:/cve.mitre.org/cgi-bin/cvename.cgi?name=cve-2008-0166)"&gt;the Debian weak SSH keys problem&lt;/a&gt;) or bogus prime generation (e.g. &lt;a href="https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/%5Bcve.mitre.org/cgi-bin/c...%5D(https:/cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2017-15361)"&gt;ROCA&lt;/a&gt;). In either case, you can generate the private key from the public key. These keys off of GitHub are likely OpenSSH-generated SSH keys generated on developer laptops and hence unlikely to have that sort of problem. It's also not specific to this scheme. (A real attacker would still check.)&lt;/p&gt;
&lt;p&gt;Other attacks depend on the type of RSA padding used. The thing that sticks out about that &lt;code&gt;openssl rsautl -encrypt&lt;/code&gt; is the &lt;code&gt;-ssl&lt;/code&gt; flag. The man page claims:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;-pkcs, -oaep, -ssl, -raw&lt;/p&gt;
&lt;p&gt;the padding to use: PKCS#1 v1.5 (the default), PKCS#1 OAEP, special padding used in SSL v2
   backwards compatible handshakes, or no padding, respectively.  For signatures, only -pkcs
   and -raw can be used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;iA! iA! I forgot that SSLv2 has its own weird padding variant: I remembered it as PKCSv15 from the last time I looked (DROWN). After some source diving (thanks pbsd!) I figured out that backwards-compatible SSLv2 padding is like PKCS1v15, but the first 8 bytes of the random padding are &lt;code&gt;0x03&lt;/code&gt; (&lt;a href="https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/%5Bgithub.com/openssl/o...%5D(https:/github.com/openssl/openssl/blob/1212818eb07add297fe562eba80ac46a9893781e/crypto/rsa/rsa_pk1.c#L117-L152)"&gt;PKCS1v15 code&lt;/a&gt;, &lt;a href="https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/%5Bgithub.com/openssl/o...%5D(https:/github.com/openssl/openssl/blob/1212818eb07add297fe562eba80ac46a9893781e/crypto/rsa/rsa_ssl.c#L16-L53)"&gt;SSLv2 code&lt;/a&gt;). That's weird, but OK: let's just say it's weird PKCSv15 and move on.&lt;/p&gt;
&lt;p&gt;PKCS1v15 and its SSLv2 variant are both vulnerable to Bleichenbacher's oracle attack. That attack relies on being able to mess with a ciphertext and learn from how it fails decryption via an error message or a timing side channel. That doesn't work here: this model is "offline": the attacker gets a ciphertext and a public key, but they don't get to talk to anything that knows how to decrypt.  Hence, they don't get to try to get it to decrypt maliciously modified ciphertexts either.&lt;/p&gt;
&lt;p&gt;There are lots of ways unpadded ("textbook") RSA is unsafe, but one of them is that it's deterministic. If &lt;em&gt;c = m&lt;sup&gt;e&lt;/sup&gt; mod N&lt;/em&gt; and an attacker is given a &lt;em&gt;c&lt;/em&gt; and they can guess a bunch of &lt;em&gt;m&lt;/em&gt;, they know &lt;em&gt;which&lt;/em&gt; &lt;em&gt;m&lt;/em&gt; produced a particular &lt;em&gt;c&lt;/em&gt;, and so decrypted the ciphertext. That sounds like a weird model at first, since the attacker comes up with &lt;em&gt;m&lt;/em&gt; and just "confirms" it's the right one. It would work here regardless: passwords are often low-entropy and can be enumerated, that's the premise of modern password cracking.&lt;/p&gt;
&lt;p&gt;But that's raw RSA, not PKCS1v15 padding, which is &lt;code&gt;EB = 00 || BT || PS || 00 || D&lt;/code&gt; (see &lt;a href="https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/%5Btools.ietf.org/html/rfc2...%5D(https:/tools.ietf.org/html/rfc2313)"&gt;RFC&lt;/a&gt;), where BT is the block type (here 02 for public key encryption). D is the data you're encrypting. PS is the  "padding string", which is a little confusing because the entire operation is padding. It's randomly generated when you're doing an RSA encryption operation. If you call the maximum size we can run through RSA k (the modulus size), the maximum length for PS is k - D - 3 (one for each null byte and one for the BT byte). The spec insists (and OpenSSL correctly enforces) this to be at least 8 bytes, or 64 bits of entropy. You can do about 50k/s public key operations on my dinky virtualized and heavily power throttled laptop. 64 bits is a bunch but not infinity. That's still not a very satisfactory result.&lt;/p&gt;
&lt;p&gt;But wait--it's &lt;em&gt;not&lt;/em&gt; PKCS1V15, it's that weird SSLv2 padding which sets the first 8 bytes of the padding string to 0x03 bytes. If the padding string is just 8 bytes long, that means the padding string is entirely determined. We can verify that by trying to encrypt a message of the appropriate size. For a 2048 bit RSA key, that's 2048 // 8 == 256 bytes worth of modulus, 3 bytes worth of header bytes and 8 bytes worth of padding, so a 256 - 8 - 3 == 245 byte message. You can go check that any 245 message encrypts to the same ciphertext every time. There's no lower bound on the amount of entropy in the ciphertext. A 244 byte message will encrypt to one of 256 ciphertexts: one for each possible pseudorandom padding value.&lt;/p&gt;
&lt;p&gt;Practically, is this still fine? Probably, but only within narrow parameters. If the message you're encrypting is very close to 245 bytes and has plenty of structure known to the attacker, it isn't. If I can get you to generate a lot of these (say, a CI system automating the same scheme), it won't be. It's the kind of crypto that makes me vaguely uncomfortable but you'll probably get away with because there's no justice in the world.&lt;/p&gt;
&lt;p&gt;There's a straightforward way to improve this. Remember how I said &lt;code&gt;-ssl&lt;/code&gt; was weird? Not specifying anything would've resulted in the better-still-not-great PKCS1v15 padding. If you are going to specify a padding strategy, specify &lt;code&gt;-oaep&lt;/code&gt;. OAEP is the good RSA encryption padding. By default, OpenSSL uses SHA1 with it (for both the message digest and in MGF1), which is fine for this purpose. That gives you 160 bits of randomness, which ought to be plenty.&lt;/p&gt;
&lt;p&gt;This is why most schemes use RSA to encrypt a symmetric key.&lt;/p&gt;
&lt;p&gt;Future blog posts: how to fix this, creative scenarios in which we mess with those parameters so it breaks, and how to do the same with ECDSA/EdDSA keys. For the latter: I asked a smart person and the "obvious" thing to them was not the thing I'd have done. For EdDSA, my first choice would be to convert the public key from Ed25519 to X25519 and then use NaCl box. They'd use the EdDSA key directly. So, if you're interested, we'll could do a post on that. And then we'd probably talk about why you use NIST P-256 for both signatures and ECDH, but different curve formats in djb country: Ed25519 for signatures and X25519 for ECDH. Oh, and we should do some entropy estimation. People often know how to do that for passwords, but for this threat model we also need to do that for English prose.&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><guid>https://www.lvh.io/posts/analyzing-a-simple-encryption-scheme-using-github-ssh-keys/</guid><pubDate>Sun, 30 Sep 2018 19:54:00 GMT</pubDate></item><item><title>The default OpenSSH key encryption is worse than plaintext</title><link>https://www.lvh.io/posts/the-default-openssh-key-encryption-is-worse-than-plaintext/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;The eslint-scope npm package got compromised recently, stealing npm credentials from your home directory. We started running tabletop exercises: what else would you smash-and-grab, and how can we mitigate that risk?&lt;/p&gt;
&lt;p&gt;Most people have an RSA SSH key laying around. That SSH key has all sorts of privileges: typically logging into prod and GitHub access. Unlike an npm credential, an SSH key is encrypted, so perhaps it’s safe even if it leaks? Let’s find out!&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;user&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="nv"&gt;work&lt;/span&gt; &lt;span class="nv"&gt;/tmp&lt;/span&gt; &lt;span class="nv"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;ssh-keygen&lt;/span&gt;
&lt;span class="nv"&gt;Generating&lt;/span&gt; &lt;span class="nv"&gt;public/private&lt;/span&gt; &lt;span class="nv"&gt;rsa&lt;/span&gt; &lt;span class="nb"&gt;key &lt;/span&gt;&lt;span class="nv"&gt;pair.&lt;/span&gt;
&lt;span class="nv"&gt;Enter&lt;/span&gt; &lt;span class="nv"&gt;file&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;which&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;save&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nb"&gt;key &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;/home/user/.ssh/id_rsa&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="nv"&gt;mykey&lt;/span&gt;
&lt;span class="nv"&gt;...&lt;/span&gt;
&lt;span class="nv"&gt;user&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="nv"&gt;work&lt;/span&gt; &lt;span class="nv"&gt;/tmp&lt;/span&gt; &lt;span class="nv"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;head&lt;/span&gt; &lt;span class="nv"&gt;-n&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="nv"&gt;mykey&lt;/span&gt;  
&lt;span class="nv"&gt;-----BEGIN&lt;/span&gt; &lt;span class="nv"&gt;RSA&lt;/span&gt; &lt;span class="nv"&gt;PRIVATE&lt;/span&gt; &lt;span class="nv"&gt;KEY-----&lt;/span&gt;
&lt;span class="nv"&gt;Proc-Type&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;,&lt;span class="nv"&gt;ENCRYPTED&lt;/span&gt;
&lt;span class="nv"&gt;DEK-Info&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="nv"&gt;AES-128-CBC&lt;/span&gt;,&lt;span class="nv"&gt;CB973D5520E952B8D5A6B86716C6223F&lt;/span&gt;

&lt;span class="nv"&gt;+5ZVNE65kl8kwZ808e4+Y7Pr8IFstgoArpZJ/bkOs7rB9eAfYrx2CLBqLATk1RT/&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You can tell it’s encrypted because it says so right there. It also doesn’t start with &lt;code&gt;MII&lt;/code&gt; -- the base64 DER clue that an RSA key follows. And AES! That’s good, right? CBC with ostensibly a random IV, even! No MAC, but without something like a padding oracle to try modified ciphertexts on, so that might be OK?&lt;/p&gt;
&lt;p&gt;It’s tricky to find out what this DEK-Info stuff means. Searching the openssh-portable repo for the string DEK-Info only shows sample keys. The punchline is that the AES key is just MD5(password || IV[:8]). That’s not good at all: password storage best practice holds that passwords are bad (low entropy) and in order to turn them into cryptographic key material you need an expensive function like Argon2. MD5 is very cheap to compute. The only thing this design has going for it is that the salt goes after the password, so you can’t just compute the intermediate state of MD5(IV[8:]) and try passwords from there. That’s faint praise, especially in a world where I can rent a machine that tries billions of MD5 calls per second. There just aren’t that many passwords.&lt;/p&gt;
&lt;p&gt;You might ask yourself how OpenSSH ended up with this. The sad answer is the OpenSSL command line tool had it as a default, and now we’re stuck with it.&lt;/p&gt;
&lt;p&gt;That’s a fair argument to say that standard password-encrypted keys are about as good as plaintext: the encryption is ineffective. But I made a stronger statement: it’s &lt;em&gt;worse&lt;/em&gt;. The argument there is simple: an SSH key password is unlikely to be managed by a password manager: instead it’s something you remember. If you remember it, you probably reused it somewhere. Perhaps it’s even your device password. This leaked key provides an oracle: if I guess the password correctly (and that’s feasible because the KDF is bad), I know I guessed correctly because I can check against your public key.&lt;/p&gt;
&lt;p&gt;There’s nothing wrong with the RSA key pair itself: it’s just the symmetric encryption of the private key. You can’t mount this attack from just a public key.&lt;/p&gt;
&lt;p&gt;How do you fix this? OpenSSH has a new key format that you should use. “New” means 2013. This format uses bcrypt_pbkdf, which is essentially bcrypt with fixed difficulty, operated in a PBKDF2 construction. Conveniently, you always get the new format when generating Ed25519 keys, because the old SSH key format doesn’t support newer key types. That’s a weird argument: you don’t really need your key format to define how Ed25519 serialization works since Ed25519 itself already defines how serialization works. But if that’s how we get good KDFs, that’s not the pedantic hill I want to die on. Hence, one answer is ssh-keygen -t ed25519. If, for compatibility reasons, you need to stick to RSA, you can use ssh-keygen -o. That will produce the new format, even for old key types. You can upgrade existing keys with ssh-keygen -p -o -f PRIVATEKEY. If your keys live on a Yubikey or a smart card, you don't have this problem either.&lt;/p&gt;
&lt;p&gt;We want to provide a better answer to this. On the one hand, aws-vault has shown the way by moving credentials off disk and into keychains. Another parallel approach is to move development into partitioned environments. Finally, most startups should consider not having long-held SSH keys, instead using temporary credentials issued by an SSH CA, ideally gated on SSO. Unfortunately this doesn't work for GitHub.&lt;/p&gt;
&lt;p&gt;PS: It’s hard to find an authoritative source, but from my memory: the versioned parameter in the PEM-like OpenSSH private key format only affect the encryption method. That doesn’t matter in the slightest: it’s the KDF that’s broken. That’s an argument against piecemeal negotiating parts of protocols, I’m sure. We’ll get you a blog post on that later.&lt;/p&gt;
&lt;p&gt;The full key is available here, just in case you feel like running john the ripper on something today: &lt;a href="https://gist.github.com/lvh/c532c8fd46115d2857f40a433a2416fd"&gt;gist.github.com/lvh/c532c...&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/the-default-openssh-key-encryption-is-worse-than-plaintext/</guid><pubDate>Sat, 04 Aug 2018 02:00:18 GMT</pubDate></item><item><title>Factoring the Noise protocol matrix</title><link>https://www.lvh.io/posts/factoring-the-noise-protocol-matrix/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;style&gt;
    .matrix {
        position: relative;
        margin: auto;
        margin-bottom: 2em;
    }
    .matrix:before, .matrix:after {
        content: "";
        position: absolute;
        top: 0;
        border: 3px solid #000;
        width: 20px;
        height: 100%;
    }
    .matrix:before {
        left: -10px;
        border-right: 0;
    }
    .matrix:after {
        right: -10px;
        border-left: 0;
    }
    .matrix td {
        vertical-align: middle;
        min-width: 100px;
        margin-bottom: 10px;
    }
    .matrix td p {
        vertical-align: middle;
        text-align: center;
        margin: auto;
    }
&lt;/style&gt;

&lt;p&gt;The Noise protocol is one of the best things to happen to encrypted protocol
design. &lt;a href="https://www.wireguard.com"&gt;WireGuard&lt;/a&gt; inherits its elegance from Noise.
Noise is a cryptography engineer's darling spec. It's important not to get
blindsided while fawning over it and to pay attention to where implementers run
into trouble. Someone raised a concern I had run into before: Noise has a
matrix.&lt;/p&gt;
&lt;table class="matrix" style="width:100%"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;N(rs):&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN:&lt;br&gt;  → e&lt;br&gt;  ← e, ee&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN:&lt;br&gt; → s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ...&lt;br&gt; → e&lt;br&gt; ← e, ee, se&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN:&lt;br&gt;  → e&lt;br&gt;  ← e, ee&lt;br&gt;  → s, se&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, s&lt;br&gt;  ← e, ee, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;K(s, rs):&lt;br&gt;  → s&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, ss&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK:&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;br&gt;  ← e, ee&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  …&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, es, ss&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← e, ee, se&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK:&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;br&gt;  ← e, ee&lt;br&gt;  → s, se&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, s, ss&lt;br&gt;  ← e, ee, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;X(s, rs):&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, s, ss&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX:&lt;br&gt;  → e&lt;br&gt;  ← e, ee, s, es&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX:&lt;br&gt;  → s&lt;br&gt;  ...&lt;br&gt;  → e&lt;br&gt;  ← e, ee, se, s, es&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX:&lt;br&gt;  → e&lt;br&gt;  ← e, ee, s, es&lt;br&gt;  → s, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt; IX:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← e, ee, se, s, es&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To a cryptography engineer, this matrix is beautiful. These eldritch runes
describe a grammar: the number of ways you can meaningfully compose the phrases
that can make up a Noise handshake into a proper protocol. The rest of the
document describes what the trade-offs between them are: whether the protocol is
one-way or interactive, whether you get resistance against key-compromise
impersonation, what sort of privacy guarantees you get, et cetera.
(Key-compromise impersonation means that if I steal your key, I can impersonate
anyone to you.)&lt;/p&gt;
&lt;p&gt;To the layperson implementer, the matrix is terrifying. They hadn't thought
about key-compromise impersonation or the distinction between known-key,
hidden-key and exposed-key protocols or even forward secrecy. They're going to
fall back to something else: something probably less secure but at least
unambiguous on what to do. As Noise matures into a repository for protocol
templates with wider requirements, this gets worse, not better. The most recent
revision of the Noise protocol adds 23 new "deferred" variants. It's unlikely
these will be the last additions.&lt;/p&gt;
&lt;p&gt;Which Noise variant should that layperson use? Depends on the application of
course, but we can make some reasonable assumptions for most apps. Ignoring
variants, we have:&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;N&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;K&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;X&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Firstly, let's assume you need bidirectional communication, meaning
initiator and responder can send messages to each other as opposed to
just initiator to responder. That gets rid of the first column of the
matrix.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The other protocols are defined by two letters. From the spec:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The first character refers to the initiator's static key:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N = No static key for initiator&lt;/li&gt;
&lt;li&gt;K = Static key for initiator Known to responder&lt;/li&gt;
&lt;li&gt;X = Static key for initiator Xmitted ("transmitted") to responder&lt;/li&gt;
&lt;li&gt;I = Static key for initiator Immediately transmitted to responder, despite reduced or absent identity hiding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second character refers to the responder's static key:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N = No static key for responder&lt;/li&gt;
&lt;li&gt;K = Static key for responder Known to initiator&lt;/li&gt;
&lt;li&gt;X = Static key for responder Xmitted ("transmitted") to initiator&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;NN provides confidentiality against a passive attacker but neither party
has any idea who you're talking to because no static (long-term) keys
are involved. For most applications none of the *N suites make a ton of
sense: they imply the initiator does not care who they're connecting to.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For most applications the client (initiator) ought to have a fixed
static key so we have a convenient cryptographic identity for clients
over time. So really, if you wanted something with an N in it, you'd
know.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The responder usually doesn't know what the key is for any initiator that
happens to show up. This mostly makes sense if you have one central initiator
that reaches out to a lot of responders: something like an MDM or sensor data
collection perhaps. In practice, you often end up doing egress from those
devices anyway for reasons that have nothing to do with Noise. So, K* is out.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These remaining suites generally trade privacy (how easily can you
identify participants) for latency (how many round trips are needed).&lt;/p&gt;
&lt;p&gt;IX doesn't provide privacy for the initiator at all, but that's the side you
usually care about. It still has the roundtrip downside, making it a niche
variant. XX and XK require an extra round trip before they send over the
initiator's static key. Flip side: they have the strongest possible
privacy protection for the initiator, whose identity is only sent to the
responder after they've been authenticated and forward secrecy has been
established.&lt;/p&gt;
&lt;p&gt;IK provides a reasonable tradeoff: no extra round trip and the
initiator's key is encrypted to the responder's static key. That means
that the initiator's key is only disclosed if the responder's key is
compromised. You probably don't care about that. It does require the
initiator to know the static key of the responder ahead of time but
that's probably true anyway: you want to check that key against a
trusted value. You can also try private keys for the responder offline
but that doesn't matter unless you gratuitously messed up key
generation. In conclusion, you probably want IK.&lt;/p&gt;
&lt;p&gt;This breakdown only works if you're writing a client-server application
that plausibly might've used mTLS instead. WireGuard, for example, is
built on Noise_IK. The other variants aren't pointless: they're just
good at different things. If you care more about protecting your
initiator's privacy than you do about handshake latency, you want
Noise_XK. If you're doing a peer-to-peer IoT system where device
privacy matters, you might end up with Noise_XX. (It's no accident
that IK, XK and XX are in the last set of protocols standing.)&lt;/p&gt;
&lt;h3&gt;Protocol variants&lt;/h3&gt;
&lt;p&gt;Ignore deferred variants for now. If you needed them you'd
know. PSK is an interesting quantum computer hedge. We'll talk more about
quantum key exchanges in a different post, but briefly: a shared PSK among
several participants protects against a passive adversary that records
everything and acquires a quantum computer some time in the future, while
retaining the convenient key distribution of public keys.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;It's incredible how much has happened in the last few years
to make protocols safer, between secure protocol templates like Noise,
new proof systems like Tamarin, and ubiquitous libraries of safer
primitives like libsodium. So far, the right answer for a safe transport
has almost always been TLS, perhaps mutually authenticated. That's not
going to change right away, but if you control both sides of the network
and you need properties hard to get out of TLS, Noise is definitely The
Right Answer. Just don't stare at the eldritch rune matrix too long. You
probably want Noise_IK. Or, you know, ask your security person :)&lt;/p&gt;
&lt;p&gt;Thanks to Katriel Cohn-Gordon for reviewing this blog post.&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/factoring-the-noise-protocol-matrix/</guid><pubDate>Wed, 18 Jul 2018 17:59:00 GMT</pubDate></item><item><title>Smaller Clojure Docker builds with multi-stage builds</title><link>https://www.lvh.io/posts/smaller-clojure-docker-builds-with-multi-stage-builds/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;A common pattern in Docker is to use a separate build environment from the
runtime environment. Many platforms have different requirements when you're
generating a runnable artifact than when you're running it.&lt;/p&gt;
&lt;p&gt;In languages like Go, Rust or C, where the most common implementations produce
native binaries, the resulting artifact may require nothing from the environment
at all, or perhaps as little as a C standard library. Even in languages like
Python that don't typically have a build step, you might indirectly use code
that still requires compilation. Common examples include OpenSSL with
pyca/cryptography or NETLIB and other numerical libraries with numpy/scipy.&lt;/p&gt;
&lt;p&gt;In Clojure, you can easily build "uberjars" with both lein and boot. These are
jars (the standard JVM deployable artifact) that come with all dependencies
prepackaged, requiring nothing beyond what's in the Java standard library
(rt.jar). While this still requires a JRE to run, that is still much smaller
than the full development environment.&lt;/p&gt;
&lt;p&gt;There are a few advantages to separating environments. It all boils down to them
not having anything in them they don't need. That has clear performance
advantages, although Docker has historically mitigated this problem with layered
pulls. It can have security benefits as well: you can't have bugs in software
you don't ship. Even software that isn't directly used in the build process can
be affected: some build environments will contain plenty of software that is
never used that would normally carry over into your production environments.&lt;/p&gt;
&lt;p&gt;Historically, most users of Docker haven't bothered. Even if there are
advantages, they aren't worth the hassle of having separate Docker environments
and ferrying data between them. While different ways of effectively sharing data
between containers have been available for years, people who wanted a shared
build step have mostly had to write their own tooling. For example,
my &lt;a href="https://github.com/lvh/icecap/blob/master/utils/build-libsodium-package.sh"&gt;icecap&lt;/a&gt; project has a batch file with an embedded Dockerfile that builds
libsodium debs.&lt;/p&gt;
&lt;p&gt;The upcoming release of Docker will add support for a new feature called
multi-stage builds, where this pattern is much simpler. Dockerfiles themselves
know about your precursor environments now, and future containers have full
access to previous containers for copying build artifacts around. This
requires Docker 17.05 or newer.&lt;/p&gt;
&lt;p&gt;Here's an example Dockerfile that builds an uberjar from a standard lein-based
app, and puts it in a new JRE image:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;clojure&lt;/span&gt; &lt;span class="k"&gt;AS&lt;/span&gt; &lt;span class="n"&gt;build&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;env&lt;/span&gt;
&lt;span class="n"&gt;WORKDIR&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;myapp&lt;/span&gt;
&lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="n"&gt;project&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;clj&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;myapp&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
&lt;span class="n"&gt;RUN&lt;/span&gt; &lt;span class="n"&gt;lein&lt;/span&gt; &lt;span class="n"&gt;deps&lt;/span&gt;
&lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;myapp&lt;/span&gt;
&lt;span class="n"&gt;RUN&lt;/span&gt; &lt;span class="n"&gt;mv&lt;/span&gt; &lt;span class="ss"&gt;"$(lein uberjar | sed -n 's/^Created \(.*standalone\.jar\)/\1/p')"&lt;/span&gt; &lt;span class="n"&gt;myapp&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;standalone&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;jar&lt;/span&gt;

&lt;span class="k"&gt;FROM&lt;/span&gt; &lt;span class="n"&gt;openjdk&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;8&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;jre&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;alpine&lt;/span&gt;
&lt;span class="n"&gt;WORKDIR&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;myapp&lt;/span&gt;
&lt;span class="k"&gt;COPY&lt;/span&gt; &lt;span class="c1"&gt;--from=build-env /usr/src/myapp/myapp-standalone.jar /myapp/myapp.jar&lt;/span&gt;
&lt;span class="n"&gt;ENTRYPOINT&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="ss"&gt;"java"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"-jar"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;"/myapp/myapp.jar"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;This captures the uberjar name from the &lt;code&gt;lein uberjar&lt;/code&gt; output. If your uberjar
name doesn't end in &lt;code&gt;.standalone.jar&lt;/code&gt;, that won't work. You can change the name
of the uberjar with the &lt;code&gt;:uberjar-name&lt;/code&gt; setting in &lt;code&gt;project.clj&lt;/code&gt;. If you set it
to &lt;code&gt;myapp-standalone.jar&lt;/code&gt;, you don't need the gnarly &lt;code&gt;sed&lt;/code&gt; expression anymore at
all, and can just call &lt;code&gt;lein uberjar&lt;/code&gt;. (Thanks to Łukasz Korecki for the
suggestion!)&lt;/p&gt;
&lt;p&gt;The full clojure base image is a whopping 629MB (according to &lt;code&gt;docker images&lt;/code&gt;),
whereas &lt;code&gt;openjdk:8-jre-alpine&lt;/code&gt; clocks in at 81.4MB. That's a little bit of an
unfair comparison: &lt;code&gt;clojure&lt;/code&gt; also has an alpine-based image. However, this still
illustrates the savings compared to the most commonly used Docker image.&lt;/p&gt;
&lt;p&gt;There are still good reasons for not using multi-stage builds. In the icecap
example above, the entire point is to use Docker as a build system to produce
a deb artifact &lt;em&gt;outside of Docker&lt;/em&gt;. However, that's a pretty exotic use case:
for most people this will hopefully make smaller Docker images an easy
reality.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edited:&lt;/em&gt; The original blog post said that the Docker version to support this
feature was in beta at time of writing. That was/is correct, but it's since
been released, so I updated the post.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Edited:&lt;/em&gt;* Łukasz Korecki pointed out that &lt;code&gt;project.clj&lt;/code&gt; has an &lt;code&gt;:uberjar-name&lt;/code&gt;
parameter which can be used to avoid the gnarly &lt;code&gt;sed&lt;/code&gt; expression. Thanks Łukasz!&lt;/p&gt;&lt;/div&gt;</description><category>clojure</category><category>docker</category><guid>https://www.lvh.io/posts/smaller-clojure-docker-builds-with-multi-stage-builds/</guid><pubDate>Fri, 16 Jun 2017 17:12:46 GMT</pubDate></item><item><title>2016 rMBP caveats</title><link>https://www.lvh.io/posts/2016-rmbp-caveats/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;I bought the 2016 15" retina MacBook Pro as soon as it became available. I've
had it for a week now, and there have been some issues you might want to be
aware of if you'd like to get one.&lt;/p&gt;
&lt;p&gt;(There are a bunch of links to Amazon in this article. They're not affiliate
links.)&lt;/p&gt;
&lt;h2&gt;System Integrity Protection is often disabled&lt;/h2&gt;
&lt;p&gt;I noticed &lt;a href="https://twitter.com/schwa/status/799160866209828864"&gt;via Twitter&lt;/a&gt; that some people were reporting that &lt;a href="https://en.wikipedia.org/wiki/System_Integrity_Protection"&gt;System Integrity
Protection (SIP)&lt;/a&gt; was disabled by default on their Macs. SIP is a mechanism via
which macOS protects critical system files from being overwritten.&lt;/p&gt;
&lt;p&gt;You can check if SIP is enabled on your system by running &lt;code&gt;csrutil status&lt;/code&gt; in a
terminal. Sure enough, SIP was disabled for both me and my wife's new rMBPs. To
enable SIP, boot into the recovery mode (hold ⌘-R when booting), open a
terminal, type &lt;code&gt;csrutil enable&lt;/code&gt; and reboot.&lt;/p&gt;
&lt;p&gt;Perhaps unrelatedly, different out-of-the-box rMBPs appear to have different
builds of OS X Sierra 10.12.1.&lt;/p&gt;
&lt;h2&gt;Thunderbolt 2 dongle doesn't work with external screens&lt;/h2&gt;
&lt;p&gt;I have a Dell 27" 4k montior (P2715Q). I used it with my previous-generation
rMBP with a DisplayPort-to-mDP2 cable to connect it to its Thunderbolt 2 port.
When buying my laptop, it suggested I get a Thunderbolt 3 to Thunderbolt 2
dongle. I was expecting to get a Thunderbolt 2 port like the one on my previous
Mac. When I plugged it in to my monitor, it told me that there was a cable
plugged in, but no signal coming from the computer.&lt;/p&gt;
&lt;p&gt;My understanding was that the Thunderbolt spec implies PCIe lanes and other
protocols over the same port. Specifically, Thunderbolt 2 means 4 PCI Express
2.0 lanes with DisplayPort 1.2; at a cursory glance, &lt;a href="https://en.wikipedia.org/wiki/Thunderbolt_(interface)"&gt;Wikipedia agrees&lt;/a&gt;.
(Thunderbolt 3 adds HDMI 2.0 and USB 3.1 gen 2.)&lt;/p&gt;
&lt;p&gt;I spent about an hour and a half on the phone with AppleCare folks. The Apple
support people were very friendly. (I'm guessing their instructions tell them to
never, under any circumstances, interrupt a customer. It was a little weird.) I
was redirected a few times. They had a variety of suggestions, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Changing my monitor to MST mode, which shouldn't be necessary for DisplayPort
  1.2-supporting devices, and did nothing but make my monitor not work with my old
  rMBP either. Fortunately I was able to recover via HDMI to my old laptop.&lt;/li&gt;
&lt;li&gt;Buying the Apple Digital AV Adapter instead. That adapter used HDMI instead of
  mDP2. That's a significant downgrade; my use of DisplayPort was intentional,
  because DisplayPort 1.2 is the only way I can power the 4K display at 60Hz.
  (The new adapter does not support HDMI 2.0, which is necessary for 4K@60Hz.)&lt;/li&gt;
&lt;li&gt;Buying a third-party DisplayPort adapter or dock. This is precarious at best.
  Most existing devices &lt;a href="https://9to5mac.com/2016/11/03/2016-macbook-pro-thunderbolt-compatibility-issues/"&gt;don't work with the new rMBP&lt;/a&gt;, because they
  use a previous-generation TI chip. There are plenty of docks that wont work,
  by &lt;a href="https://www.amazon.com/StarTech-com-Thunderbolt-Dual-4K-Docking-Station"&gt;StarTech&lt;/a&gt;, &lt;a href="https://www.amazon.com/Dell-Dock-WD15-Adapter-Type-C"&gt;Dell&lt;/a&gt;, &lt;a href="https://www.amazon.com/Kensington-Delivery-DisplayPort-Microphone-K38231WW"&gt;Kensington&lt;/a&gt;
  and &lt;a href="https://www.amazon.com/Plugable-Display-Docking-Charging-Delivery"&gt;Plugable&lt;/a&gt;. I found one Dock by &lt;a href="https://www.amazon.com/CalDigit-USB-C-Docking-Station-DisplayPort"&gt;CalDigit&lt;/a&gt; that will
  ostensibly work with the new rMBP, but doesn't supply enough power to charge
  it.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Eventually, we found &lt;a href="https://support.apple.com/en-us/HT207266"&gt;a KB article&lt;/a&gt; that spells out that the Thunderbolt
dongle doesn't work for DisplayPort displays:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Thunderbolt 3 (USB-C) to Thunderbolt 2 Adapter doesn't support connections to these devices:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Apple DisplayPort display&lt;/li&gt;
&lt;li&gt;DisplayPort devices or accessories, such as Mini DisplayPort to HDMI or Mini DisplayPort to VGA adapters&lt;/li&gt;
&lt;li&gt;4K Mini DisplayPort displays that don’t have Thunderbolt&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;I'm a little vindicated by the &lt;a href="http://www.apple.com/shop/reviews/MMEL2AM/A/thunderbolt-3-usb-c-to-thunderbolt-2-adapter"&gt;Mac Store&lt;/a&gt; review page for the dongle;
apparently I wasn't the only person to expect that. (I was unable to see the
reviews before my purchase, because I purchased it with my Mac, which doesn't
show reviews. Also, the product was brand new at the time, and didn't have these
reviews yet.)&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.belkin.com/us/p/P-F4U095/"&gt;Belkin&lt;/a&gt; and &lt;a href="https://9to5mac.com/2016/11/03/owc-announces-thunderbolt-3-dock-adds-13-ports-of-legacy-io-to-the-new-macbook-pros-over-a-single-cable/"&gt;OWC&lt;/a&gt; will be shipping docks that allegedly work with
the new rMBP, but Belkin's is currently unavailable with no ship date mentioned,
and OWC claims February 2017.&lt;/p&gt;
&lt;h2&gt;WiFi failing with USB-C devices plugged in&lt;/h2&gt;
&lt;p&gt;Just as I was going to start writing this post, I noticed that I wasn't able
to sync my blog repository from GitHub:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;Get&lt;/span&gt; &lt;span class="nv"&gt;https&lt;/span&gt;:&lt;span class="o"&gt;//&lt;/span&gt;&lt;span class="nv"&gt;api&lt;/span&gt;.&lt;span class="nv"&gt;github&lt;/span&gt;.&lt;span class="nv"&gt;com&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;repos&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;lvh&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nv"&gt;lvh&lt;/span&gt;.&lt;span class="nv"&gt;github&lt;/span&gt;.&lt;span class="nv"&gt;io&lt;/span&gt;: &lt;span class="nv"&gt;dial&lt;/span&gt; &lt;span class="nv"&gt;tcp&lt;/span&gt; &lt;span class="mi"&gt;192&lt;/span&gt;.&lt;span class="mi"&gt;30&lt;/span&gt;.&lt;span class="mi"&gt;253&lt;/span&gt;.&lt;span class="mi"&gt;116&lt;/span&gt;:&lt;span class="mi"&gt;443&lt;/span&gt;: &lt;span class="k"&gt;connect&lt;/span&gt;: &lt;span class="nv"&gt;network&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;unreachable&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;It didn't click at first what was going on. I restarted my router, connected to
different networks, tried a different machine -- all telling me it was this
laptop that was misbehaving. I started trying everything, and realized I had
recently plugged in my WD backup drive from which I was copying over an SSH key.
It's a USB 3.0 drive that I'm connecting via an AUKEY USB 3 to USB-C converter.
I removed the drive, and my WiFi starts working again. Plugging it back in does
not instantly, but eventually, break WiFi again.&lt;/p&gt;
&lt;p&gt;After searching, I was able &lt;a href="https://www.youtube.com/watch?v=NYVjIjBMx6o"&gt;to find someone with the same problem&lt;/a&gt;.
It is unclear to me if this issue is related to the first-gen TI chip issue
mentioned above. In that video, the authors are also using a USB 3.0 to USB-C
plug, albeit a different one from mine. I don't have a reference USB-C machine
that isn't a new 2016 rMBP to test with. However, this seems plausible, because
the USB 3.0 dongle I purchased from Apple ostensibly works fine.&lt;/p&gt;
&lt;p&gt;This does not seem like a reasonable failure mode.&lt;/p&gt;
&lt;h2&gt;The escape key, and the new keyboard&lt;/h2&gt;
&lt;p&gt;I spend most of my day in Emacs. I'm perfectly happy with the new keyboard. I've
also used the regular MacBook butterfly keyboard, and the new version is
significantly better. I've never had a problem with not having an escape key;
every app where I would've cared to press it had an escape key drawn on the new
Touch Bar. However, not having tactile feedback for the escape key is annoying.
When I was setting up my box and quickly editing a file in vim, I successfully
pressed Escape to exit insert mode -- but I ended up pressing it five times
because I thought I didn't hit it. Apparently the visual feedback vim gives me
that I've exited insert mode is not, actually, what my brain relies on. I'll let
you know if I get used to it.&lt;/p&gt;
&lt;h2&gt;Charging&lt;/h2&gt;
&lt;p&gt;I'll miss the safety of Magsafe, but being able to plug in your charger on
either side is an unexpected nice benefit.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I was ready to accept a transition period of dongles; I bought into it,
literally and figuratively. However, most of the dongles don't actually work,
and that sucks. So, maybe wait for the refresh, or at least until the
high-quality docks are available.&lt;/p&gt;&lt;/div&gt;</description><guid>https://www.lvh.io/posts/2016-rmbp-caveats/</guid><pubDate>Tue, 22 Nov 2016 15:49:16 GMT</pubDate></item><item><title>Crypto APIs and JVM byte types</title><link>https://www.lvh.io/posts/crypto-apis-and-jvm-byte-types/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;In a previous post, I talked about &lt;a href="https://www.lvh.io/posts/tradeoffs-in-cryptographic-api-design.html"&gt;crypto API tradeoffs&lt;/a&gt;. In this
post, I'll go into a specific API design case in &lt;a href="https://github.com/lvh/caesium"&gt;&lt;code&gt;caesium&lt;/code&gt;&lt;/a&gt;, my
cryptographic library for Clojure, a language that runs on the Java Virtual
Machine.&lt;/p&gt;
&lt;h3&gt;JVM byte types&lt;/h3&gt;
&lt;p&gt;The JVM has several standard byte types. For one-shot cryptographic APIs, the
two most relevant ones are byte arrays (also known as &lt;code&gt;byte[]&lt;/code&gt;) and
&lt;code&gt;java.nio.ByteBuffer&lt;/code&gt;.  Unfortunately, they have different pros and cons, so
there is no unambiguously superior choice.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ByteBuffer&lt;/code&gt; can produce slices of byte arrays and other byte buffers with
zero-copy semantics. This makes a useful tool when want to place an encrypted
message in a pre-allocated binary format. One example of this is my
&lt;a href="https://github.com/lvh/caesium/blob/master/src/caesium/magicnonce/secretbox.clj"&gt;experimental NMR suite&lt;/a&gt;. Another use case is generating more than
one key out of a single call to a key derivation function. The call produces
one (long) output, and &lt;code&gt;ByteBuffer&lt;/code&gt; lets you slice it into different keys.&lt;/p&gt;
&lt;p&gt;Byte arrays are easily serializable, but &lt;code&gt;ByteBuffer&lt;/code&gt; is not. Even if you
teach your serialization library about &lt;code&gt;ByteBuffer&lt;/code&gt;, this usually results in
extra copying during serialization.&lt;/p&gt;
&lt;p&gt;Byte arrays are constant length, and that length is stored with the array, so
it's cheap to access. Figuring out how much to read from a &lt;code&gt;ByteBuffer&lt;/code&gt;
requires a (trivial) amount of math by calling &lt;code&gt;remaining&lt;/code&gt;. This is because
the &lt;code&gt;ByteBuffer&lt;/code&gt; is a view, and it can be looking at a different part of the
underlying memory at different times. For a byte array, this is all fixed: a
byte array's starting and stopping points remain constant. Computing the
remaining length of a &lt;code&gt;ByteBuffer&lt;/code&gt; may not always be constant time, although
it probably is. Even if it isn't, it's probably not in a way that is relevant
to the security of the scheme (in &lt;code&gt;caesium&lt;/code&gt;, only cryptographic hashes,
detached signatures and detached MACs don't publicly specify the message
length).&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ByteBuffer&lt;/code&gt; has a public API for allocating &lt;em&gt;direct&lt;/em&gt; buffers. This means they
are not managed by the JVM. Therefore they won't be copied around by the
garbage collector, and memory pinning is free. "Memory pinning" means that you
notify the JVM that some external C code is using this object, so it should
not be moved around or garbage collected until that code is done using that
buffer. You can't pass "regular" (non-direct) buffers to C code. When you do
that, the buffer is first copied under the hood. Directly allocated buffers
let you securely manage the entire lifecycle of the buffer. For example, they
can be securely zeroed out after use. Directly allocated &lt;code&gt;ByteBuffer&lt;/code&gt;
instances might have underlying arrays; this is explicitly unspecified.
Therefore, going back to an array &lt;em&gt;might&lt;/em&gt; be zero-copy. In my experiments,
these byte buffers never have underlying arrays, so copying is always
required. I have not yet done further research to determine if this generally
the case. In addition to &lt;code&gt;ByteBuffer&lt;/code&gt;, the&lt;code&gt;sun.misc.Unsafe&lt;/code&gt; class does have
options for allocating memory directly, but it's pretty clear that use of that
class is strongly discouraged. Outside of the JDK, the &lt;code&gt;Pointer&lt;/code&gt; API in
&lt;code&gt;jnr-ffi&lt;/code&gt; works identically to &lt;code&gt;ByteBuffer&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Design decisions&lt;/h3&gt;
&lt;p&gt;As a brief recap from my previous post, it's important that we design an API
that makes common things easy and hard things possible while remaining secure
and performant. For the cryptographic APIs in &lt;code&gt;caesium&lt;/code&gt;, there are a number of
variables to consider:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Are the return types and arguments &lt;code&gt;ByteBuffer&lt;/code&gt; instances, byte arrays
   (&lt;code&gt;[B&lt;/code&gt;), &lt;code&gt;Pointer&lt;/code&gt; instances, or something else?&lt;/li&gt;
&lt;li&gt;Is the return type fixed per exposed function, or is the return
   type based on the input types, like Clojure's &lt;a href="https://clojure.github.io/clojure/clojure.core-api.html#clojure.core/empty"&gt;&lt;code&gt;empty&lt;/code&gt;&lt;/a&gt;?&lt;/li&gt;
&lt;li&gt;Are the APIs "C style" (which passes in the output buffer as an argument)
   or "functional style" (which allocates the output buffer for you)?&lt;/li&gt;
&lt;li&gt;Does the implementation convert to the appropriate type (which might
   involve copying), does it use reflection to find the appropriate type, does
   it explicitly dispatch on argument types, or does it assume you give
   it some specific types?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Many of these choices are orthogonal, meaning we can choose them
independently. With dozens of exposed functions, half a dozen or so arguments
per function with 2-4 argument types each, two function styles, four argument
conversion styles, and two ways of picking the return type, this easily turns
into a combinatorial explosion of many thousands of exposed functions.&lt;/p&gt;
&lt;p&gt;All of these choices pose trade-offs. We've already discussed the differences
between the different byte types, so I won't repeat them here. Having the
function manage the output buffer for you is the most convenient option, but
it also precludes using direct byte buffers effectively. Type conversion is
most convenient, but type dispatch is faster, and statically resolvable
dispatching to the right implementation is faster still. The correct return
value depends on context. Trying to divine what the user really wanted is
tricky, and, as we discussed before, the differences between those types are
significant.&lt;/p&gt;
&lt;p&gt;The functions exposed in caesium live on the inside of a bigger system, in the
same sense that IO libraries like &lt;a href="https://twistedmatrix.com/"&gt;Twisted&lt;/a&gt; and &lt;a href="https://github.com/ztellman/manifold"&gt;manifold&lt;/a&gt;
live on the edges. Something gives you some bytes, you perform some
cryptographic operations on them, and then the resulting bytes go somewhere
else. This is important, because it reduces the number of contexts in which
people end up with particular types.&lt;/p&gt;
&lt;h3&gt;Implementing the API&lt;/h3&gt;
&lt;p&gt;One easy decision is that the underlying binding should support every
permutation, regardless of what the API exposes. This would most likely
involve annoying code generation in a regular Java/jnr-ffi project, but
caesium is written in Clojure. The information on how to bind libsodium is a
Clojure data structure that gets compiled into an interface, which is what
jnr-ffi consumes. This makes it easy to expose every permutation, since it's
just some code that operates on a value. You can see this at work in the
&lt;a href="https://github.com/lvh/caesium/blob/master/src/caesium/binding.clj#L13"&gt;&lt;code&gt;caesium.binding&lt;/code&gt; namespace&lt;/a&gt;. As a consequence, an expert
implementer (who knows exactly which underlying function they want to call
with no "smart" APIs or performance overhead) can always just drop down to the
binding layer.&lt;/p&gt;
&lt;p&gt;Another easy call is that all APIs should raise exceptions, instead of
returning success codes. Success codes make sense for a C API, because there's
no reasonable exception mechanism available. However, problems like failed
decryption should definitely just raise exceptions.&lt;/p&gt;
&lt;p&gt;It gets tricky when we compare APIs that take an output buffer versus APIs
that build the output buffer for you. The latter are clearly the easiest to
use, but the former are necessary for explicit buffer life cycle
management. You can also easily build the managed version from the unmanaged
version, but you can't do the converse. As a consequence, we should expose
both.&lt;/p&gt;
&lt;p&gt;Having to expose both has the downside that we haven't put a dent in that
combinatorial explosion of APIs yet. Let's consider the cases in which someone
might have a byte buffer:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They're using them as a slice of memory, where the underlying memory could
   be another byte buffer (direct or indirect) or a byte array -- usually a
   byte array wrapping a byte buffer.&lt;/li&gt;
&lt;li&gt;They're managing their own (presumably direct) output buffers.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the former case, the byte buffers primarily act as inputs. In the latter,
they exclusively act as outputs. Because both byte buffers and byte arrays can
act as inputs, any API should be flexible in what it accepts. However, this
asymmetry in how the types are used, and how they can be converted, has
consequences for APIs where the caller manages the output buffer versus APIs
that manage it for you.&lt;/p&gt;
&lt;p&gt;When the API that manages the output buffer for you, the most reasonable
return type is a byte array. There is no difference between byte arrays
created by the API and those created by the caller, and there's no reasonable
way to reuse them. If you do really need a byte buffer for some reason,
wrapping that output array is simple and cheap. Conversely, APIs where the
caller manages the output buffer should use output byte buffers. Callers who
are managing their own byte buffer need to call an API that supports that, and
there's nothing to be gained from managing your own byte arrays (only direct
byte buffers). This is fine for internal use within &lt;code&gt;caesium&lt;/code&gt; — the byte array
producing API can just wrap it in a byte buffer view.&lt;/p&gt;
&lt;p&gt;This means we've reduced the surface significantly: APIs with caller-managed
buffers output to &lt;code&gt;ByteBuffer&lt;/code&gt;, and APIs that manage it themselves return byte
arrays. This takes care of the output types, but not the input types.&lt;/p&gt;
&lt;p&gt;Keys, salts, nonces, messages et cetera will usually be byte arrays, since
they're typically just read directly from a file or made on the spot. However
rare, there can be good reasons for having any of these as byte buffers. For
example, a key might have been generated from a different key using a key
derivation function; a nonce might be synthetically generated (as with
deterministic or nonce-misuse resistant schemes); either might be randomly
generated but just into a pre-existing buffer.&lt;/p&gt;
&lt;p&gt;The easiest way for this to work by default is reflection. That mostly works,
until it doesn't. Firstly, reflecting can be brittle. For example, if all of
your byte sequence types are known but a buffer length isn't, Clojure's
reflection will fail to find the appropriate method, even if it is
unambiguous. Secondly, unannotated Clojure fns always take boxed objects, not
primitives, which is what we want for calling into C. Annotating is imperfect,
too, because it moves the onus of producing a primitive to the caller. These
aren't really criticisms of Clojure. At this point we're well into weird edge
case territory which this system wasn't designed for.&lt;/p&gt;
&lt;p&gt;We can't do static dispatch for the public API, because we've established that
we should be flexible in our input types. We can work around the unknown type
problems with reflection using explicitly annotated call sites. That means
we're dispatching on types, which comes with its own set of issues. In the
next blog post, I'll go into more detail on how that works, with a bunch of
benchmarks. Stay tuned!&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><guid>https://www.lvh.io/posts/crypto-apis-and-jvm-byte-types/</guid><pubDate>Mon, 11 Jul 2016 21:00:00 GMT</pubDate></item><item><title>Tradeoffs in cryptographic API design</title><link>https://www.lvh.io/posts/tradeoffs-in-cryptographic-api-design/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Producing cryptographic software is a difficult and specialized endeavor. One
of the pitfalls is that getting it wrong looks exactly like getting it
right. Much like a latent memory corruption bug or a broken distributed
consensus algorithm, a piece of cryptographic software can appear to be
functioning perfectly, while being subtly broken in a way that only comes to
light years later. As the adage goes, attacks never get worse; they only get
better. Implementation concerns like timing attacks can be fiendishly
complicated to solve, involving problems like division instructions on modern
Intel CPUs taking a variable number of cycles depending on the size of the
input. Implementation concerns aren't the only problem; just designing the
APIs themselves is a complex task as well.&lt;/p&gt;
&lt;p&gt;Like all API design, cryptographic API design is a user experience
exercise. It doesn't matter how strong or fast your cryptographic software is
if no one uses it. The people who end up with ECB mode didn't end up with it
because they understood what that meant. They got stuck with it because it was
the default and it didn't require thinking about scary parameters like IVs,
nonces, salts and tweaks. Even if someone ended up with CTR or CBC, these APIs
are still precarious; they'll still be vulnerable to issues like nonce
reuse, fixed IV, key-as-IV, unauthenticated encryption...&lt;/p&gt;
&lt;p&gt;User experience design always means deep consideration of who your users
are. A particular API might be necessary for a cryptographic engineer to build
new protocols, but that API is probably not a reasonable default encryption
API. An explicit-nonce encryption scheme is great for a record layer protocol
between two peers like TLS, but it's awful for someone trying to encrypt a
session cookie. We can't keep complaining about people getting it wrong when
we keep giving them no chances at getting it right. This is why I'm building
educational material like &lt;a href="https://www.crypto101.io/"&gt;Crypto 101&lt;/a&gt; and why I care about
cryptography like &lt;a href="https://www.lvh.io/posts/nonce-misuse-resistance-101.html"&gt;nonce-misuse resistance&lt;/a&gt; that's easier to use
correctly.  (The blog post on my new nonce-misuse resistant schemes for
libsodium is coming soon, I promise!)&lt;/p&gt;
&lt;p&gt;Before you can make your API easy to use, first you have to worry about
getting it to work at all.&lt;/p&gt;
&lt;p&gt;An underlying cryptographic library might expose an unfortunate API. It might
be unwieldy because of historical reasons, backwards compatibility, language
limitations, or even simple oversight. Regardless of why the API is the way it
is, even minute changes to it—a nicer type, an implied parameter—might have
subtle but catastrophic consequences for the security of the final
product. Figuring out if an arbitrary-length integer in your programming
language is interchangeable with other representations, like the
implementation in your crypto library or a &lt;code&gt;char *&lt;/code&gt;, has many complex
facets. It doesn't just have to be true under some conditions; ideally, it's
true for every platform your users will run your software on, in perpetuity.&lt;/p&gt;
&lt;p&gt;There might be an easy workaround to an annoying API. C APIs often take a
&lt;code&gt;char *&lt;/code&gt; together with a length parameter, because C doesn't have a standard
way of passing a byte sequence together with its length. Most higher level
languages, including Java and Python, have byte sequence types that know their
own length. Therefore, you can specify the &lt;code&gt;char *&lt;/code&gt; and its associated length
in a single parameter on the high-level side. That's just the moral equivalent
of building a small C struct that holds both. (Whether or not you can trust C
compilers to get anything right at all is a point of contention.)&lt;/p&gt;
&lt;p&gt;These problems compound when you are binding libraries in languages and
environments with wildly different semantics. For example, your runtime might
have a relocating garbage collector.  Pointers in C and objects in CPython
stay put, but objects move around all the time in environments like the JVM
(HotSpot) or PyPy. That implies copying to or from a buffer whenever you call
C code, unless the underlying virtual machine supports "memory pinning":
forcing the object to stay put for the duration of the call.&lt;/p&gt;
&lt;p&gt;Programmers normally operate in a drastically simplified model of the
world. We praise programming designs for their ability to separate concerns,
so that programmers can deal with one problem at a time. The modern CPU your
code runs on is always an intricate beast, but you don't worry about cache
lines when you're writing a Python program. Only a fraction of programmers
ever has to worry about them at all. Those that do typically only do so after
the program already works so they can still focus on one part of the problem.&lt;/p&gt;
&lt;p&gt;When designing cryptographic software, these simplified models we normally
program in don't generally work.  A cryptographic engineer often needs to
worry about concerns all the way up and down the stack simultaneously: from
application layer concerns, to runtime semantics like the
&lt;a href="https://docs.oracle.com/javase/specs/jls/se8/html/index.html"&gt;Java Language Specification&lt;/a&gt;, to FFI semantics and the C ABI on all
relevant platforms, to the underlying CPU, to the mathematical underpinnings
themselves. The engineer has to manage all of those, often while being
hamstrung by flawed designs like TLS' MAC-then-pad-then-encrypt mess.&lt;/p&gt;
&lt;p&gt;In future blog posts, I'll go into more detail about particular cryptographic
API design concerns, starting with JVM byte types. If you're interested, you
should &lt;a href="https://twitter.com/lvh"&gt;follow me on Twitter&lt;/a&gt; or &lt;a href="https://www.lvh.io/rss.xml"&gt;subscribe to my blog's feed&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Footnote:&lt;/em&gt; I'm happy to note that &lt;a href="https://bitbucket.org/cffi/cffi/commits/61e03368485cb78471f701adbfd1bde69a6eaa31"&gt;cffi&lt;/a&gt; now also has
support for memory pinning since PyPy will support it in the upcoming
5.2 release, although that means I'll no longer be able to make
&lt;a href="https://github.com/reaperhulk"&gt;Paul Kehrer of PyCA fame&lt;/a&gt; jealous with the pinning support in
&lt;a href="https://github.com/lvh/caesium"&gt;caesium&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><guid>https://www.lvh.io/posts/tradeoffs-in-cryptographic-api-design/</guid><pubDate>Sat, 18 Jun 2016 20:45:35 GMT</pubDate></item><item><title>Nonce misuse resistance 101</title><link>https://www.lvh.io/posts/nonce-misuse-resistance-101/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This post is an introduction to nonce-misused resistant cryptosystems and why
I think they matter. The first part of this post is about nonce-based
authenticated encryption schemes: how they work, and how they fail. If you're
already familiar with them, you can skip to the section on
&lt;a href="https://www.lvh.io/posts/nonce-misuse-resistance-101/#proto"&gt;protocol design&lt;/a&gt;. If you're completely new to cryptography, you might
like my free introductory course to cryptography, &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;. In a
future blog post, I'll talk about some nonce-misuse resistant schemes I've
implemented using libsodium.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Many stream ciphers and stream cipher-like constructions such as CTR,
GCM, (X)Salsa20... take a nonce. You can think of it as a pointer that lets
you jump to a particular point in the keystream. This makes these ciphers
"seekable", meaning that you can decrypt a small part of a big ciphertext,
instead of having to decrypt everything up to that point first. (That ends up
being trickier than it seems, because you still want to authenticate that
small chunk of ciphertext, but that's a topic for another time.)&lt;/p&gt;
&lt;p&gt;The critical security property of a nonce is that it's never repeated under
the same key. You can remember this by the mnemonic that a &lt;em&gt;nonce&lt;/em&gt; is a
"number used once". If you were to repeat the nonce, the keystream would also
repeat. That means that an attacker can take the two ciphertexts and XOR them
to compute the XOR of the plaintexts. If &lt;code&gt;C_n&lt;/code&gt; are ciphertexts, &lt;code&gt;P_n&lt;/code&gt;
plaintexts, &lt;code&gt;K_n&lt;/code&gt; keystreams, and &lt;code&gt;^&lt;/code&gt; is bitwise exclusive or:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt;
&lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_2&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The attacker just XORs &lt;code&gt;C_1&lt;/code&gt; and &lt;code&gt;C_2&lt;/code&gt; together:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;K_2&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Since XOR is commutative (you can rearrange the order), &lt;code&gt;K_1 = K_2&lt;/code&gt;, and
XOR'ing two equal values cancels them out:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;That tells an attacker a lot about the plaintext, especially if some of one of
the plaintexts is predictable. If the attacker has access to an encryption
oracle, meaning that they can get encryptions for plaintexts of their
choosing, they can even get perfect decryptions. That is not an unrealistic
scenario. For example, if you're encrypting session cookies that contain the
user name and e-mail, I can register using a name and e-mail address that has
a lot of &lt;code&gt;Z&lt;/code&gt; characters, and then I know that just XORing with &lt;code&gt;Z&lt;/code&gt; will reveal
most of the plaintext. For an idea of the state of the art in attacking
two-time pads (the usual term for two ciphertexts with a reused keystream),
see &lt;a href="https://www.cs.jhu.edu/~jason/papers/mason+al.ccs06.pdf"&gt;Mason06&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="proto"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Protocol design&lt;/h3&gt;
&lt;p&gt;For many on-line protocols like TLS, the explicit nonce provides a convenient
way to securely send many messages under a per-session key. Because the
critical security property for a nonce is that it is never repeated with the
same key, it's safe to use a counter. In protocols where both peers send
messages to each other, you can just have one peer use odd nonces and have the
other use even ones. There are some caveats here: for example, if the nonce
size is sufficiently small, an attacker might try to make that counter
overflow, resulting in a repeated nonce.&lt;/p&gt;
&lt;p&gt;For off-line (or at-rest) protocols, it's a little trickier. You don't have a
live communication channel to negotiate a new ephemeral key over, so you're
stuck with longer-term keys or keys derived from them. If multiple systems are
participating, you need to decide ahead of time which systems own which
nonces. Even then, systems need to keep track of which nonces they've
used. That doesn't work well, especially not in a distributed system where
nodes and connections can fail at any time. This is why some cryptosystems
like &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt; provide an API that doesn't require you to specify
anything besides a key and a message.&lt;/p&gt;
&lt;p&gt;One solution is to use randomized nonces. Since nonces can't repeat, random
nonces should be large: if they're too small, you might randomly select the
same nonce twice, per the birthday bound. That is the only difference between
Salsa20 and XSalsa20: Salsa20 has a 64 bit nonce, whereas XSalsa20 has a 192
bit nonce. That change exists explicitly to make random nonces secure.&lt;/p&gt;
&lt;p&gt;Picking a random nonce and just prepending it to the secretbox ciphertext is
secure, but there are a few problems with this approach. It's not clear to
practitioners that that's a secure construct. Doing this may seem obvious to a
cryptographer, but not to someone who just wants to encrypt a
message. Prepending a nonce doesn't feel much different from e.g. appending a
MAC. A somewhat knowledgeable practitioner knows that there's plenty of ways
to use MACs that are insecure, and they don't immediately see that the
prefix-nonce construction is secure. Not wanting to design your own
cryptosystems is a good reflex which we should be encouraging.&lt;/p&gt;
&lt;p&gt;Random nonces also mean that any system sending messages needs access to
high-quality random number generators while they're sending a message. That's
often, but not always true. Bugs around random number generation, especially
userspace CSPRNGs, &lt;a href="http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/"&gt;keep popping up&lt;/a&gt;. This is often a consequence of
poor programming practice, but it can also be a consequence of
poorly-configured VMs or limitations of embedded hardware.&lt;/p&gt;
&lt;h3&gt;Nonce-misuse resistant systems&lt;/h3&gt;
&lt;p&gt;To recap, not all protocols have the luxury of an obvious nonce choice, and
through circumstances or poor practices, nonces might repeat
anyway. Regardless of how cryptographers feel about how important nonce misuse
is, we can anecdotally and empirically verify that such issues are real and
common. This is true even for systems like TLS where there is an "obvious"
nonce available (&lt;a href="https://eprint.iacr.org/2016/475.pdf"&gt;Böck et al, 2016&lt;/a&gt;). It's easy to point fingers, but
it's better to produce cryptosystems that fail gracefully.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://web.cs.ucdavis.edu/~rogaway/papers/keywrap.pdf"&gt;Rogaway and Shrimpton (2006)&lt;/a&gt; defined a new model called nonce-misuse
resistance. Informally, nonce-misuse resistance schemes ensure that a repeated
random nonce doesn't result in plaintext compromise. In the case of a broken
system where the attacker can cause repeated nonces, an attacker will only be
able to discern if a particular message repeated, but they will not be able
to decrypt the message.&lt;/p&gt;
&lt;p&gt;Rogaway and Shrimpton also later developed a mode of operation called SIV
(synthetic IV), which Gueron and Lindell are refined to GCM-SIV, a SIV-like
that takes advantage of fast GCM hardware implementations. Those two authors
are currently working with Adam Langley to standardize the AES-GCM-SIV
construction through CFRG. AEZ and HS1-SIV, two entries in the CAESAR
competition, also feature nonce-misuse resistance. CAESAR is an ongoing
competition, and GCM-SIV is not officially finished yet, so this is clearly
a field that is still evolving.&lt;/p&gt;
&lt;p&gt;There are parallels between nonce-misuse resistance and length extension
attacks. Both address issues that arguably only affected systems that were
doing it wrong to begin with. (Note, however, in the embedded case above, it
might not be a software design flaw but a hardware limitation.) Fortunately,
the SHA-3 competition showed that you can have increased performance and
still be immune to a class of problems. I'm hopeful that CAESAR will consider
nonce-misuse resistance an important property of an authenticated encryption
standard.&lt;/p&gt;
&lt;h3&gt;Repeated messages&lt;/h3&gt;
&lt;p&gt;Repeated messages are suboptimal, and in some protocols they might be
unacceptable. However, they're a fail-safe failure mode for nonce
misuse. You're not choosing to have a repeated ciphertext, you're just getting
a repeated ciphertext instead of a plaintext disclosure (where the attacker
would also know that you repeated a message). In the case of a secure random
nonce, a nonce-misuse resistant scheme is just as secure, at the cost of a
performance hit.&lt;/p&gt;
&lt;p&gt;In a context where attackers can see individual messages to detect repeated
ciphertexts, it makes sense to also consider a model where attackers can
replay messages. If replaying messages (which presumably have side effects) is
a problem, a common approach is to add a validity timestamp. This is a feature
of &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt;, for example. A device that doesn't have access to
sufficient entropy will still typically have access to a reasonably
high-resolution clock, which is still more than good enough to make sure the
synthetic IVs don't repeat either.&lt;/p&gt;
&lt;h3&gt;OK, but how does it work?&lt;/h3&gt;
&lt;p&gt;Being able to trade plaintext disclosure for attackers being able to detect
repeated messages sounds like magic, but it makes sense once you realize how
they work. As demonstrated in the start of this post, nonce re-use normally
allows an attacker to have two keystreams cancel out. That only makes sense if
two &lt;em&gt;distinct&lt;/em&gt; messages are encrypted using the same (key, nonce) pair. NMR
solves this by making the nonce also depend on the message itself. Informally,
it means that a nonce should never repeat for two distinct
messages. Therefore, an attacker can't cancel out the keystreams without
cancelling out the messages themselves as well.&lt;/p&gt;
&lt;p&gt;This model does imply off-line operation, in that the entire message has to be
scanned before the nonce can be computed. For some protocols, that may not be
acceptable, although plenty of protocols work around this assumption by simply
making individual messages sufficiently small.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Aaron Zauner and Kurt Griffiths for proofreading this post.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/nonce-misuse-resistance-101/</guid><pubDate>Thu, 19 May 2016 19:25:44 GMT</pubDate></item><item><title>Supersingular isogeny Diffie-Hellman 101</title><link>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Craig Costello, Patrick Longa and Michael Naehrig, three cryptographers at
Microsoft Research, recently published a &lt;a href="https://eprint.iacr.org/2016/413"&gt;paper&lt;/a&gt; on supersingular
isogeny Diffie-Hellman. This paper garnered a lot of interest in the security
community and even made it to the front page of Hacker News. Most of the
discussion around it seemed to be how no one understands isogenies, even
within cryptography-literate communities. This article aims to give you a
high-level understanding of what this cryptosystem is and why it works.&lt;/p&gt;
&lt;p&gt;This post assumes that you already know how Diffie-Hellman works in the
abstract, and that you know elliptic curves are a mathematical construct that
you can use to perform Diffie-Hellman operations, just like you can with the
integers &lt;em&gt;mod p&lt;/em&gt; (that would be "regular" Diffie-Hellman). If that was
gibberish to you and you'd like to know more, check out &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;, my
free introductory book on cryptography. You don't need a math background to
understand those concepts at a high level. The main difference is that Crypto
101 sticks to production cryptography, while this is still experimental.&lt;/p&gt;
&lt;p&gt;It's not surprising that isogeny-based cryptography is so confusing. Up until
recently, it was unambiguously in the realm of research, not even close to
being practically applicable. Its mathematical underpinnings are much more
complex than regular elliptic curves, let alone integers &lt;em&gt;mod p&lt;/em&gt;. It also
looks superficially similar to elliptic curve Diffie-Hellman, which only adds
to the confusion.&lt;/p&gt;
&lt;p&gt;With that, let's begin!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is this paper about?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Supersingular isogeny Diffie-Hellman (SIDH) is one of a handful of
"post-quantum" cryptosystems. Those are cryptosystems that will remain secure
even if the attacker has access to a large quantum computer. This has nothing
to do with quantum cryptography (for example, quantum key distribution)
beyond their shared quantum mechanical underpinning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why should I care about quantum computers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;General quantum computers are not useful as general-purpose computing devices,
but they can solve some problems much faster than classical
computers. Classical computers can emulate quantum computers, but only with
exponential slowdown. A sufficiently large quantum computer could break most
production cryptography, including cryptosystems based on the difficulty of
factoring large numbers (like RSA), taking discrete logs over the integers
&lt;em&gt;mod p&lt;/em&gt; (like regular DH), or taking discrete logs over elliptic curves (like
ECDH and ECDSA). To quantify that, consider the following table:&lt;/p&gt;
&lt;p&gt;&lt;img alt="quantum computer attack cost versus classical" src="https://www.lvh.io/img/post-quantum/quantum-computer-relative-cost.png"&gt;&lt;/p&gt;
&lt;p&gt;In this table, n refers to the modulus size for RSA, and the field size for
ECC. Look at the rightmost column, which represents time taken by the
classical algorithm, and compare it to the "time" columns, which represent how
much a quantum computer would take. As &lt;em&gt;n&lt;/em&gt; increases, the amount of time the
quantum computer would take stays in the same ballpark, whereas, for a
classical computer, it increases (almost) exponentially. Therefore, increasing
n is an effective strategy for keeping up with ever-faster classical
computers, but it is ineffective at increasing the run time for a quantum
computer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aah! Why isn't everyone panicking about this?!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The good news is that these large quantum computers don't exist yet.&lt;/p&gt;
&lt;p&gt;If you look at the qubits column, you'll see that these attacks require large
universal quantum computers. The state of the art in those only has a handful
of qubits. In 2011, IBM successfully factored 143 using a 4-qubit quantum
computer. Scaling the number of qubits up is troublesome. In that light,
larger key sizes may prove effective after all; we simply don't know yet how
hard it is to build quantum computers that big.&lt;/p&gt;
&lt;p&gt;D-wave, a quantum computing company, has produced computers with 128 and 512
qubits and even &amp;gt;1000 qubits. While there is some discussion if D-waves
provide quantum speedup or are even real quantum computers at all; there is no
discussion that they are not &lt;em&gt;universal&lt;/em&gt; quantum computers. Specifically, they
only claim to solve one particular problem called quantum annealing. The 1000
qubit D-Wave 2X cannot factor RSA moduli of ~512 bits or solve discrete logs
on curves of ~120 bits.&lt;/p&gt;
&lt;p&gt;The systems at risk implement asymmetric encryption, signatures, and
Diffie-Hellman key exchanges. That's no accident: all post-quantum
alternatives are asymmetric algorithms. Post-quantum secure symmetric
cryptography is easier: we can just use bigger key sizes, which are still
small enough to be practical and result in fast primitives. Quantum computers
simply halve the security level, so all we need to do to maintain a 128 bit
security level is to use ciphers with 256 bit keys, like Salsa20.&lt;/p&gt;
&lt;p&gt;Quantum computers also have an advantage against SIDH, but both are still
exponential in the field size. The SIDH scheme in the new paper has 192 bits
of security against a classical attacker, but still has 128 bits of security
against a quantum attacker. That's in the same ballpark as most symmetric
cryptography, and better than the 2048-bit RSA certificates that underpin the
security of the Internet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What makes this paper special?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Post-quantum cryptography has been firmly in the realm of academic research
and experiments. This paper makes significant advancements in how practically
applicable SIDH is.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Being future-proof sounds good. If this makes it practical, why don't we
start using it right now?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SIDH is a young cryptosystem in a young field, and hasn't had the same level
of scrutiny as some of the other post-quantum cryptosystems, let alone the
"regular" cryptosystems we use daily. Attacks only get better, they never get
worse. It's possible that SIDH is insecure, and we just don't know how to
break it yet. It does have a good argument for why quantum algorithms wouldn't
be able to crack it (more on that later), but that's a hypothesis, not a
proof.&lt;/p&gt;
&lt;p&gt;The new performance figures from this paper are impressive, but this system is
still much slower than the ones we use today. Key generation and key exchange
take a good 50 million cycles or so each. That's about a thousand times slower
than Curve25519, a curve designed about 10 years ago. Key sizes are also much
larger: SIDH public keys are 751 bytes, whereas Curve25519 keys are only 32
bytes. For on-line protocols like HTTPS operating over TCP, that's a
significant cost.&lt;/p&gt;
&lt;p&gt;Finally, there are issues with implementing SIDH safely. Systems like
Diffie-Hellman over integers &lt;em&gt;mod p&lt;/em&gt; are much less complex than elliptic curve
Diffie-Hellman (ECDH), let alone SIDH. With ECDH and ECC in general, we've
seen new implementation difficulties, especially with early curves. Point
addition formulas would work, unless you were adding a point to itself. You
have to check that input points are on the curve, or leak the secret key
modulo some small order. These are real implementation problems, even though
we know how to solve them.&lt;/p&gt;
&lt;p&gt;This is nothing compared to the difficulties implementing SIDH. Currently,
SIDH security arguments rely on honest peers. A peer that gives you a
pathological input can utterly break the security of the scheme. To make
matters worse, while we understand how to verify inputs for elliptic curve
Diffie-Hellman, we don't have a way to verify inputs for isogeny-based
cryptography at all. We don't have much research to fall back on here
either. This isn't a SIDH-specific problem; post-quantum cryptography isn't
mature enough yet to have implementation issues like these nailed down
yet. (For an example from lattice-based cryptography, see the recent paper by
&lt;a href="https://eprint.iacr.org/2016/415"&gt;Bindel et al&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;I don't want to diminish the importance of this paper in any way!  Just
because it's not something that your browser is going to be doing tomorrow
doesn't mean it's not an impressive accomplishment. It's just a step on the
path that might lead to production crypto one day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, fine. Why is this so different from elliptic curve Diffie-Hellman?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While SIDH and ECDH both use elliptic curves, they're different beasts. SIDH
generates new curves to perform a DH exchange, whereas ECDH uses points on one
fixed curve. These supersingular curves also have different properties from
regular curves. Using a supersingular curve for regular elliptic curve
operations would be horribly insecure. If you have some background in elliptic
curves: supersingular curves have a tiny embedding degree, meaning that
solving the ECDLP over &lt;code&gt;F(p)&lt;/code&gt; can easily be transformed into solving the DLP
over &lt;code&gt;F(p^n)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is that small embedding degree. Most curves have large
embedding degrees, meaning that solving the ECDLP directly is easier than
translating it into a DLP and then solving that.  You generally have to go out
of your way to find a curve with a small embedding degree. That is only done
in specialized systems, like for pairing-based cryptography, or, as in this
case, supersingular isogeny-based Diffie-Hellman.&lt;/p&gt;
&lt;p&gt;Let's recap ECDH. Public keys are points on a curve, and secret keys are
numbers. Alice and Bob agree on the parameters of the exchange ahead of time,
such as the curve &lt;em&gt;E&lt;/em&gt; and a generator point &lt;em&gt;P&lt;/em&gt; on that curve. Alice picks a
secret integer &lt;em&gt;a&lt;/em&gt; and computes her public key &lt;em&gt;aP&lt;/em&gt;. Bob picks a secret
integer &lt;em&gt;b&lt;/em&gt; and computes his public key &lt;em&gt;bP&lt;/em&gt;. Alice and Bob send each other
their public keys, and multiply their secret key by the other peer's public
key. Since &lt;em&gt;abP = baP&lt;/em&gt;, they compute the same secret. Since an attacker has
neither secret key, they can't compute the shared secret.&lt;/p&gt;
&lt;p&gt;SIDH is different. Secret keys are isogenies...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Whoa whoa whoa. What the heck are isogenies?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An isogeny between elliptic curves is a function from one elliptic curve to
another that preserves base points. That means it takes points on one curve
and returns points on the other curve. Every point on the input curve will map
to a point on the output curve; but multiple points may map to the same
point. Formally speaking, the isogeny is surjective. An isogeny is also a
homomorphism. That is, it preserves the structure of the curve. For any two
points P and Q, &lt;code&gt;phi(P + Q) = phi(P) + phi(Q)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We have a bunch of formulas for generating isogenies from a curve and a
point. You might remember that the set of values a function takes is its
"domain", and the set of values it returns is called its "codomain". The
domain of such an isogeny is the curve you give it; its codomain might be the
same curve, or it might be a different one. In general, for SIDH, we care
about the case where it produces a new curve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, so explain how SIDH works again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Roughly speaking, a secret key is an isogeny, and a public key is an elliptic
curve. By "mixing" their isogeny with the peer's public curve, each peer
generates a secret curve. The two peers will generally generate different
curves, but those curves will have the same j-invariant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wait, what's a j-invariant?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The j-invariant is a number you can compute for a particular curve. Perhaps
the best analogy would be the discriminant for quadratic equation you might
remember from high school math; it's a single number that tells you something
interesting about the underlying curve. There are different formulas for
curves in different forms. For example, for a curve in short Weierstrass form
&lt;code&gt;y^2 = x^3 + ax + b&lt;/code&gt;, the j-invariant is:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1728&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The j-invariant has a few cool properties. For example, while this is the
formula for the short Weierstrass form, the value of j doesn't change if you
put the same curve in a different form. Also, all curves with the same
j-invariant are isomorphic. However, for SIDH you don't really care about
these properties; you just care that the j-invariant is a number you can
compute, and it'll be the same for the two secret curves that are generated by
the DH exchange.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, try explaining SIDH again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The protocol fixes a supersingular curve E and four points on that
curve: P_A, Q_A, P_B, Q_B.&lt;/p&gt;
&lt;p&gt;Alice picks two random integers, m_A and n_A. She takes a linear combination
of those two integers with P_A and Q_A to produce a random point R_A, so:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;R_A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n_A&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P_A&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;m_A&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Q_A&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;That random point defines Alice's secret isogeny through the isogeny formulas
I talked about above. The codomain of that isogeny forms Alice's public
curve. Alice transforms points P_B and Q_B with the isogeny. She sends Bob her
public curve and the two transformed points.&lt;/p&gt;
&lt;p&gt;Bob does the same thing, except with A and B swapped.&lt;/p&gt;
&lt;p&gt;Once Alice gets Bob's public key, she applies m_A and n_A again to the
corresponding transformed points she got from Bob. She generates a new isogeny
phiBA from the resulting point just like she did before to generate her
private key. That isogeny's codomain will be an elliptic curve E_BA.&lt;/p&gt;
&lt;p&gt;When Bob performs his side of the exchange, he'll produce a different isogeny
and a different elliptic curve E_AB; but it will have the same j-invariant as
the curve Alice computed.  That j-invariant is the shared key.&lt;/p&gt;
&lt;p&gt;I've compiled a &lt;a href="https://www.lvh.io/sage/Supersingular%20Isogeny%20Elliptic%20Curve%20Cryptography%20--%20Sage.pdf"&gt;transcript&lt;/a&gt; of a Diffie-Hellman exchange using
Sage so you can see a (toy!) demo in action.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I know a little about elliptic curves. I thought they were always
non-singular. What's a supersingular elliptic curve but a contradiction in
terms?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You're right! Supersingular elliptic curves are somewhat confusingly
named. Supersingular elliptic curves are still elliptic curves, and they are
non-singular just like all other elliptic curves. The "supersingular" refers
to the singular values of the j-invariant. Equivalently, the Hasse invariant
will be 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, why does it matter that the curve is supersingular?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Firstly, computing the isogeny is much easier on supersingular curves than on
ordinary (not supersingular) elliptic curves. Secondly, if the curve is
ordinary, the scheme can be broken in subexponential time by a quantum
attacker.&lt;/p&gt;
&lt;p&gt;Isogeny-based cryptography using ordinary curves was considered as a
post-quantum secure cryptosystem before SIDH. However, Childs et al. showed a
subexponential quantum algorithm in 2010. This paper appeared to have ended
isogeny-based cryptography: it was already slower than other post-quantum
systems, and now it was shown that it wasn't even post-quantum secure.&lt;/p&gt;
&lt;p&gt;Because supersingular curves are rare, they had not previously been considered
for isogeny-based cryptography. However, the paper itself suggested that
supersingular curves might be worth examining, so it ended up pushing research
in a new direction rather than ending it.&lt;/p&gt;
&lt;p&gt;Explaining why the supersingular curve makes the problem quantum-hard is
tricky without being thoroughly familiar with isogenies and quantum
computing. If you're really interested, &lt;a href="https://arxiv.org/pdf/1012.4019v2.pdf"&gt;the Childs paper&lt;/a&gt; explains
how the quantum attack in the ordinary case works. Informally, in the ordinary
case, there is a group action (the &lt;em&gt;isogeny star operator&lt;/em&gt;) of the ideal class
group onto the set of isomorphism classes of isogenous curves with the same
endomorphism ring. That can be shown to be a special case of the abelian group
hidden shift problem, which can be solved quickly on a quantum computer. In
the supersingular case, there is no such group action to exploit. (If you're
trying to solve for this at home; this is why SIDH needs to define the 4
points P_A, P_B, Q_A, Q_B.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I would like to thank Thomas Ptacek for reviewing this blog post and bearing
with me as I struggle through trying to come up with human-readable
explanations for all of this stuff; Sean Devlin for reminding me that Sage is
an excellent educational tool; and Watson Ladd for pointing out a correction
w.r.t the Hasse invariant (the Hasse-Witt matrix is undefined, not
singular.). Finally, I'd like to thank all the people who reviewed drafts of
this post, including (in no particular order) Bryan Geraghty, Shane Wilton,
Sean Devlin, Thomas Ptacek, Tanner Prynn, Glyph Lefkowitz and Chris Wolfe.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101/</guid><pubDate>Sat, 30 Apr 2016 16:00:28 GMT</pubDate></item></channel></rss>