<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>lvh (mathjax)</title><link>http://www.lvh.io/</link><description></description><atom:link href="http://www.lvh.io/categories/mathjax.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Tue, 30 Dec 2014 13:52:19 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>hypercathexis dev notes part 1</title><link>http://www.lvh.io/posts/hypercathexis-dev-notes-part-1.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;blockquote class="epigraph"&gt;
hy·per·ca·thex·is, n, pl hy·per·ca·thex·es \-kə-ˈthek-səs, -ka-\:
excessive concentration of desire upon a particular object&lt;/blockquote&gt;
&lt;p&gt;I'm considering renaming the project to its plural, hypercathexes,
because then it can be about a hyper cat in a bunch of hexes.&lt;/p&gt;
&lt;p&gt;The only real constraints I started with was that I wanted a
simultaneous turn-based space game on a hex grid.&lt;/p&gt;
&lt;p&gt;Amit Patel from &lt;a class="reference external" href="http://www.redblobgames.com"&gt;Red Blob Games&lt;/a&gt; has basically the awesomest page
about &lt;a class="reference external" href="http://www.redblobgames.com/grids/hexagons/"&gt;hex grids&lt;/a&gt;, and a ton of awesome pages about many other areas
of game development. I think it's a fantastic resource for programmers
like myself who don't do game dev as a day job, but just want to make
a little game on the side.&lt;/p&gt;
&lt;p&gt;Simultaneous turn-based means that all players plan their moves
simultaneously, and they are then also executed simultaneously. This
has an interesting scaling effect. On the one hand, it clearly scales
better to many players, because players "play" simultaneously. On the
other hand, you start getting interesting problems. For example, clock
synchronization. Does the entire world advance with the same tick-tock
pattern? What happens when a player does &lt;em&gt;not&lt;/em&gt; make a move within the
allotted time? If you allow different clocks in the world, does time
advance faster if both players submit a move, or do you always wait
until the maximum timeout?&lt;/p&gt;
&lt;p&gt;I wanted an excuse to play with &lt;a class="reference external" href="https://github.com/swannodette/om"&gt;Om&lt;/a&gt; and found &lt;a class="reference external" href="https://github.com/plexus/chestnut"&gt;Chestnut&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The &lt;a class="reference external" href="https://github.com/lvh/hypercathexis/tree/d454da2b1d8c1cf491fc3cd7dba83ee1b2bd4c76"&gt;first version&lt;/a&gt; had a working hex grid, but displayed it using
offset coordinates. I wanted to work using axial coordinates as much
as possible, because it makes a lot of math so much easier. Axial
coordinates work together with the "grain" of the hex map:&lt;/p&gt;
&lt;object data="http://www.lvh.io/img/AxialBaseVectors.svg" type="image/svg+xml"&gt;
axial base vectors&lt;/object&gt;
&lt;p&gt;Second thing I did was move from individual &lt;tt class="docutils literal"&gt;&amp;lt;img&amp;gt;&lt;/tt&gt; tags produced by
Om to a single &lt;tt class="docutils literal"&gt;&amp;lt;svg&amp;gt;&lt;/tt&gt; with hexes (&lt;tt class="docutils literal"&gt;&amp;lt;polygon&amp;gt;&lt;/tt&gt;) inside it. This
fixed a number of annoying placement issues with CSS. CSS really wants
to position things based on bounding box, not midpoints. That's great
for web pages, not so much for my hex grid. I ran into a number of
annoying issues where certain hex borders would be wider than others.
Browsers aren't made to draw hex grids based on left/right offsets, I
guess...&lt;/p&gt;
&lt;p&gt;I started by expressing distances in the SVG in terms of the hex
width, which would become my unit. The height would then be
\(\sqrt{3}/2\). Then, I realized that I could make my life easier by
expressing all x coordinates in terms of a single hex width, and all y
coordinates in terms of a single hex height; then I could just scale
differently across x and y at the end.&lt;/p&gt;
&lt;img alt="Simple SVG hex grid" src="http://www.lvh.io/img/BasicSVGHexGrid.png"&gt;
&lt;p&gt;Developing in Firefox was mostly painless, but I discovered many
discrepancies once trying it in Chrome. Things that should be the same
aren't, particularly when it comes to transforms. For example, Chrome
would occasionally literally do the inverse of the scaling it was
supposed to:&lt;/p&gt;
&lt;img alt="Differences in scaling behavior across browsers" src="http://www.lvh.io/img/HexGridCrossBrowserScalingIssues.png"&gt;
&lt;p&gt;I guess trying to implement things in browsers was a mistake.&lt;/p&gt;&lt;/div&gt;</description><category>game</category><category>hex</category><category>hypercathexis</category><category>mathjax</category><category>svg</category><guid>http://www.lvh.io/posts/hypercathexis-dev-notes-part-1.html</guid><pubDate>Sat, 18 Oct 2014 13:55:15 GMT</pubDate></item><item><title>More on financial aid grant optimization</title><link>http://www.lvh.io/posts/2014/04/more-on-financial-aid-grant-optimization.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;In &lt;a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"&gt;a previous post&lt;/a&gt;, I talked about ways to optimize PyCon
financial aid grants. This is a follow-up on those efforts. Quick
recap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;There is a fixed budget \(b\) available for grants, between 100k
  and 200k USD.&lt;/li&gt;
&lt;li&gt;There are a number of people (approximately 300) requesting various
  amounts \(r_i\) (approximately between 100 USD and 2000 USD) of
  financial aid, and receive a grant \(g_i\) so that \(0 \le g_i
  \le r_i\).&lt;/li&gt;
&lt;li&gt;Financial aid applicants can be assigned scores \(s_i\), a
  relative value describing how much we'd like to have them at PyCon.&lt;/li&gt;
&lt;li&gt;PyCon wants to optimize the total expected value of scores. That
  means getting as many people as possible to come, weighted by score.&lt;/li&gt;
&lt;li&gt;We've conjectured that we can estimate the probability \(p_i\)
  that someone attends as either \(g_i/r_i\), or \((g_i/r_i)^2\).
  The former prefers to spread the budget across a larger number of
  smaller grants, whereas the latter prefers to focus the budget into
  a smaller number of larger grants.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If any of that doesn't make sense, you should read
&lt;a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"&gt;the previous blog post&lt;/a&gt; for more details.&lt;/p&gt;
&lt;p&gt;In short, we're trying to solve the optimization problem:&lt;/p&gt;
&lt;p&gt;$$\max \sum E[S_i] = \sum s_i \cdot p_i$$&lt;/p&gt;
&lt;p&gt;Since most optimization texts appear to prefer minimization,
alternatively:&lt;/p&gt;
&lt;p&gt;$$\min - \sum s_i \cdot p_i$$&lt;/p&gt;
&lt;p&gt;Subject to a budget constraint and an individual grant constraint:&lt;/p&gt;
&lt;p&gt;$$\sum g_i \le b$$&lt;/p&gt;
&lt;p&gt;$$0 \le g_i \le r_i$$&lt;/p&gt;
&lt;p&gt;The greater-than-zero constraint for individual grants is fairly
important, otherwise the algorithm might casually give you answers
like:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;k = 1: [ 10.  20. -20.  30.  50.  10.  50.], sum: 150.0
&lt;/pre&gt;


&lt;p&gt;That list in the middle are the per-person grants. Notice how the
algorithm feels that the third person really ought to pony up some
cash so that some of the other people can go to PyCon ;-)&lt;/p&gt;
&lt;h3&gt;Squared problems&lt;/h3&gt;
&lt;p&gt;In the &lt;a href="http://www.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"&gt;previous blog post&lt;/a&gt; I ran into issues using a very
generic constraint solver. I ended that post saying that I would try
to remeedy that by applying a more specific solver that takes
advantage of a particular structure of the problem.&lt;/p&gt;
&lt;p&gt;When you set \(p_i = g_i/r_i\), this turns into a linear programming
problem, since \(r_i\) is a constant. When you set \(p_i =
\left(g_i/r_i\right)^2\), it turns into a quadratic programming
problem. Turns out there's two things I missed about the quadratic
problem:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The resulting problem is not convex. That means it's (probably)
  difficult to solve.&lt;/li&gt;
&lt;li&gt;The estimated probability that someone will attend falls off sharply
  as soon as they don't receive the full amount they requested. At 50%
  of the requested grant, the estimated probability of attending is
  only 25%; at 90%, it's 81%. This is the opposite of what we want.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Fixing the model&lt;/h3&gt;
&lt;p&gt;That doesn't mean we should put the \((g_i/r_i)^k\) out to pasture:
it just means that I didn't pick the \(k\) I really wanted.
Specifically, if I were to pick \(k=1/2\), I'd get:&lt;/p&gt;
&lt;p&gt;$$p_i = \left(\frac{g_i}{r_i}\right)^{1/2} = \sqrt{\frac{g_i}{r_i}}$$&lt;/p&gt;
&lt;p&gt;In general, if  \(k = 1/n\):&lt;/p&gt;
&lt;p&gt;$$p_i = \left(\frac{g_i}{r_i}\right)^{1/n} = \sqrt[n]{\frac{g_i}{r_i}}$$&lt;/p&gt;
&lt;p&gt;That problem &lt;em&gt;is&lt;/em&gt; convex, but it isn't linear, quadratic, or some
other easy specific problem. It's just constrained multivariate convex
optimization. That's okay, there are still a couple of applicable
optimization algorithms.&lt;/p&gt;
&lt;p&gt;Some of these algorithms require the derivative of the goal function
with respect to a particular grant size \(g_j\) at a particular
point. In case we don't have the real derivative, we can still provide
a numerical approximation. In our case, we don't really need to
approximate, since the derivatives are fairly easy to compute
analytically:&lt;/p&gt;
&lt;p&gt;$$\frac{\partial}{\partial g_j} \sum_i s_i \cdot
\sqrt[n]{\frac{g_i}{r_i}} = \frac{s_j \cdot {g_j}^{\frac{1}{n} -
1}}{\sqrt[n]{r_j} \cdot n}$$&lt;/p&gt;
&lt;h3&gt;Finding a solution with Python&lt;/h3&gt;
&lt;p&gt;There are a few Python packages that contain optimization algorithms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SciPy&lt;/li&gt;
&lt;li&gt;cvxopt&lt;/li&gt;
&lt;li&gt;pyopt&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Someone originally pointed me towards cvxopt. While I'm sure it's
excellent software, I already knew SciPy, so I went with that.&lt;/p&gt;
&lt;p&gt;SciPy's optimization module provides the following algorithms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;fmin_l_bfgs_b&lt;/code&gt; - Zhu, Byrd, and Nocedal's constrained optimizer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fmin_tnc&lt;/code&gt; - Truncated Newton code&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fmin_cobyla&lt;/code&gt; - Constrained optimization by linear approximation&lt;/li&gt;
&lt;li&gt;&lt;code&gt;fmin_slsqp&lt;/code&gt; - Minimization using sequential least-squares programming&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nnls&lt;/code&gt; - Linear least-squares problem with non-negativity constraint&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first two are not applicable because they only appear to support
bounds on individual variables. I also need a constraint over the
&lt;em&gt;sum&lt;/em&gt; of variables for the budget:  \(\sum g_i \le b\). The last one
isn't applicable because this isn't a linear least-squares problem.
That leaves &lt;code&gt;cobyla&lt;/code&gt; and &lt;code&gt;slsqp&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Experimenting with linear approximation (COBYLA)&lt;/h3&gt;
&lt;p&gt;Making COBYLA work ended up being pretty easy. The only non-trivial
part is expressing all your constraints as expressions greater than or
equal to zero.&lt;/p&gt;
&lt;p&gt;I've uploaded my IPython notebook
(&lt;a href="http://nbviewer.ipython.org/gist/lvh/10107818"&gt;viewer&lt;/a&gt;,
&lt;a href="https://gist.github.com/lvh/10107818"&gt;gist&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;This produced the following results:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;scores: [1 1 1 2 3 5 5]
requested: [10 20 30 30 50 10 50] total: 200, budget: 150
k = 1/0.5: [ 10.  20.  30.  30.  50.  10.   0.], sum: 150.0
k = 1/1: [ 10.  -0.   0.  30.  50.  10.  50.], sum: 150.0
k = 1/2: [ 10.  10.   7.  27.  36.  10.  50.], sum: 150.0
k = 1/3: [ 10.  11.   9.  25.  35.  10.  50.], sum: 150.0
k = 1/5: [ 10.  11.  10.  24.  35.  10.  50.], sum: 150.0
k = 1/10: [ 10.  11.  11.  23.  35.  10.  50.], sum: 150.0
k = 1/100: [ 10.  11.  11.  23.  34.  10.  50.], sum: 150.0
&lt;/pre&gt;


&lt;p&gt;Some takeaways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;As predicted, as \(1/k\) increases, the optimization gradually
  starts spreading the budget out more evenly; preferring to give many
  partial grants rather than a few large ones.&lt;/li&gt;
&lt;li&gt;This effect is mostly only pronounced for \(1/k = 2, 3\); after
  that, increasing \(1/k\) doesn't make much of a difference
  anymore. This is what I'd expect when I visualize the \(p_i\)
  functions in my head, but I haven't ruled out numerical instability.&lt;/li&gt;
&lt;li&gt;Even at high \(1/k\), the two high scorers get their full grant
  amount. That's quite understandable for the one that's only asking
  for 10, but even the one asking for a large grant gets it
  unconditionally. This probably means that tweaking the scoring
  functions is going to be very important.&lt;/li&gt;
&lt;li&gt;The linear version is apparently already quite brutal: the person
  with score 3 requesting 50 simply gets it entirely, leaving no
  budget left over for the people with score 1.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Since I'm so pleased with these results, I'm skipping &lt;code&gt;slsqp&lt;/code&gt; until I
feel like it. Next up, I'll try to compare the COBYLA results above
with the results of the greedy algorithm under various fitness
metrics.&lt;/p&gt;&lt;/div&gt;</description><category>mathjax</category><category>pycon</category><guid>http://www.lvh.io/posts/2014/04/more-on-financial-aid-grant-optimization.html</guid><pubDate>Mon, 07 Apr 2014 03:34:00 GMT</pubDate></item><item><title>Optimal hotel room pairing</title><link>http://www.lvh.io/posts/2014/03/optimal-hotel-room-pairing.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;The greedy hotel pairing algorithm from my &lt;a href="http://blog.lvh.io/blog/2014/03/10/optimization-problems-and-pycon-financial-aid/"&gt;previous post&lt;/a&gt;
gives good solutions. If you make some fairly reasonable-sounding
assumptions about the problem, &lt;em&gt;very&lt;/em&gt; good solutions. At any rate
nicer than forcing a human to drudge through it; both in terms of
person-hours spent and quality of the solutions.&lt;/p&gt;
&lt;p&gt;However, it turns out I was wrong about them being &lt;em&gt;optimal&lt;/em&gt;
solutions. There's no guarantee they would be, and in fact a good
chance that they won't.&lt;/p&gt;
&lt;h3&gt;Finding optimal solutions&lt;/h3&gt;
&lt;p&gt;The good news is that there is a way to find the optimal solution.
This problem can be modeled as a &lt;a href="https://en.wikipedia.org/wiki/Matching_%28graph_theory%29"&gt;graph matching problem&lt;/a&gt;;
what we're trying to find is a weighted maximal matching.&lt;/p&gt;
&lt;p&gt;This is really easy if the graph is bipartite, but in our case we're
actually dealing with two &lt;a href="https://en.wikipedia.org/wiki/Complete_graph"&gt;complete graphs&lt;/a&gt;: we try to pair
people with similar gender. Within that compatible group, anyone can
theoretically pair with anyone.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://upload.wikimedia.org/wikipedia/commons/8/86/10-simplex_graph.svg"&gt;&lt;/p&gt;
&lt;p&gt;People interested in additional reading might be interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://theory.stanford.edu/~jvondrak/CS369P-files/lec6.pdf"&gt;Notes from a Stanford course by Jan Vondrak&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www-sop.inria.fr/members/Frederic.Havet/Cours/matching.pdf"&gt;Notes from an Inria course by Frederic Havet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Picking an algorithm&lt;/h3&gt;
&lt;p&gt;There are several feasible algorithms for this.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/Blossom_algorithm"&gt;Edmonds' blossom algorithm&lt;/a&gt;, the first polynomial-time
  algorithm with running time \(O(V^4)\) or \(O(V^2\cdot E)\)&lt;/li&gt;
&lt;li&gt;Gabow's 1973 PhD thesis, an \(O(V^3)\) algorithm&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dl.acm.org/citation.cfm?id=1382663"&gt;An \(O(\sqrt{V} \cdot E)\)) improvement&lt;/a&gt; by Micali (yes,
  &lt;a href="https://en.wikipedia.org/wiki/Silvio_Micali"&gt;&lt;em&gt;that&lt;/em&gt; Micali&lt;/a&gt;) and Vazirani&lt;/li&gt;
&lt;li&gt;Another improvement by Gabow, \(O(V(E + \log{V}))\)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The current state of the art in computerized algorithms appears to be
&lt;a href="http://pub.ist.ac.at/~vnk/papers/blossom5.pdf"&gt;Blossom V&lt;/a&gt; by Vladimir Kolmogorov. This algorithm finds
&lt;em&gt;perfect&lt;/em&gt; matchings (i.e. all nodes are included), which may be
impossible for us, e.g. because of an odd number of pairs.&lt;/p&gt;
&lt;h3&gt;Issues&lt;/h3&gt;
&lt;p&gt;One issue with this approach is that it becomes pretty much impossible
to adapt this to rooms for more than two people. In order to support
that case my previous greedy algorithm remains the best thing I've
found.&lt;/p&gt;
&lt;p&gt;I was unable to find an implementation of this in Java or Clojure.
Fortunately, there is a Python library called &lt;a href="http://networkx.lanl.gov"&gt;NetworkX&lt;/a&gt;
that does have &lt;a href="http://networkx.lanl.gov/reference/generated/networkx.algorithms.matching.max_weight_matching.html"&gt;an implementation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have not yet turned this into a fully functional program, because:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;it's too late to apply it for this year&lt;/li&gt;
&lt;li&gt;there's a good chance we won't be doing this again for next year&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Credits&lt;/h3&gt;
&lt;p&gt;I'd like to thank Tor Myklebust (&lt;code&gt;tmyklebu&lt;/code&gt; on Freenode) for pointing
out I was wrong, and shoving me in the direction of the answers.&lt;/p&gt;
&lt;p&gt;In this blog post I used several freely available graph illustrations
from Wikipedia. The complete graph illustrations were made by
&lt;a href="https://commons.wikimedia.org/wiki/User:Koko90"&gt;koko90&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>mathjax</category><category>pycon</category><guid>http://www.lvh.io/posts/2014/03/optimal-hotel-room-pairing.html</guid><pubDate>Tue, 18 Mar 2014 20:05:00 GMT</pubDate></item><item><title>Optimization problems and PyCon financial aid</title><link>http://www.lvh.io/posts/2014/03/optimization-problems-and-pycon-financial-aid.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;This year, I have partly taken on some new responsibilities in
organizing PyCon. Specifically, I've done some work on financial aid.
(Next year, I will be taking on the position of financial aid chair.)
There have been some challenges that I've thrown some code at. Some of
it stuck.&lt;/p&gt;
&lt;p&gt;I'm very much interested in your comments, thoughts, alternative
approaches, et cetera. Hit me up on
&lt;a href="https://twitter.com/lvh"&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Hotel room allocation&lt;/h3&gt;
&lt;p&gt;The first issue I solved was one of hotel room allocation. We provide
the financial aid applicants with hotel rooms. To keep costs down, we
pair people up, two by two.&lt;/p&gt;
&lt;p&gt;We want to pair people so that we have to book a minimal number of
days. If there's days on the start of the room booking where only one
person is booking the room, we have to pay for the rest.&lt;/p&gt;
&lt;h4&gt;A greedy algorithm&lt;/h4&gt;
&lt;p&gt;I start out with generating every possible pairing. Assuming we have
300 financial aid applicants, that's:&lt;/p&gt;
&lt;p&gt;$${300 \choose 2} = \frac{300!}{2! \cdot 298!} = 44850$$&lt;/p&gt;
&lt;p&gt;That's more than we can check by hand, but still pretty easy for a
computer. Besides, there are actually fewer pairs than that: some
people request to be paired together explicitly, and we only pair
people of the same gender.&lt;/p&gt;
&lt;p&gt;Then, I sort them by number of unmatched days, that is, how many days
would have a single person in the hotel room if we paired them
together. Finally, I just greedily start grabbing pairs, keeping track
of the people that have been allocated rooms as I go along. As soon as
everyone is accounted for, we stop.&lt;/p&gt;
&lt;p&gt;Other than perhaps minding the edge conditions where you have an odd
number of people to pair, this isn't too tricky. The implementation
for this is on Github, in
&lt;a href="https://github.com/lvh/pairing/blob/master/src/pairing/core.clj"&gt;&lt;code&gt;lvh/pairing&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;Solution, meet reality&lt;/h4&gt;
&lt;p&gt;Before I wrote this, humans did this by hand. That took pretty long,
and the solutions were decent, but suboptimal. All the humans that
have tackled this problem seem to take the same approach: sort by
check-in date, find exact or near matches in check-out dates, rinse,
repeat.&lt;/p&gt;
&lt;p&gt;The algorithm above did quite well, coming up with a significantly
better result than the previous human allocation. It also produced
very &lt;em&gt;interesting&lt;/em&gt; solutions. Turns out that by taking a big hit on
one of the pairs (say, a pair that's 4 days mismatched four days), you
can limit the damage on a large number of other pairs, and still come
out on top. After reviewing with the person who previously had to do
this manually, we quickly agreed that a human would most likely not
have come up with this.&lt;/p&gt;
&lt;p&gt;Furthermore, a lot of the pairs have matching check-out dates but with
a mismatched check-in date; whereas humans typically only look for
solutions in the other direction. This is easy to explain in
hindsight; the algorithm has no concept of an ordering of events in
time. It just tries to minimize the number of mismatched days.&lt;/p&gt;
&lt;p&gt;I'm quite happy with the result. Any dollar I'm not devoting to a room
that isn't being fully used will instead be going into an increased
grant.&lt;/p&gt;
&lt;p&gt;Unfortunately, finding this solution isn't the end of the story. It
rarely survives the clash with reality. Many complex factors affect
it: people will drastically change their room dates, people's visas
get denied, et cetera. All sorts of unforseeable circumstances have
lead to changes to the answer the algorithm originally produced. I
don't expect that to change until PyCon is over; unfortunately, I also
don't think that's a problem I can fix in a few lines of Clojure.&lt;/p&gt;
&lt;h3&gt;Grant allocation&lt;/h3&gt;
&lt;p&gt;The second issue is a much thornier one. Given the financial aid
budget, figure out how to optimally distribute it. The budget is quite
limited, a good deal smaller than the sum of what everyone requests.&lt;/p&gt;
&lt;p&gt;There's a few reasons why this problem is complex. First of all,
"optimal" is highly subjective. As I'm sure you'll notice very soon
after thinking about it, it's very easy to verge off from math and
straight into the realm of politics.&lt;/p&gt;
&lt;h4&gt;A very simple greedy algorithm&lt;/h4&gt;
&lt;p&gt;You might say that you want to get as many people as possible to come
to PyCon, and you just greedily allocate the smallest grant requests
first. This has a few disadvantages:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It biases against the people that ostensibly need the money the
   most.&lt;/li&gt;
&lt;li&gt;It is ordering-sensitive: equivalent applications that happen to
   come later in the queue are disadvantaged.&lt;/li&gt;
&lt;li&gt;It oversimplifies how people react to grants, by making grant
   allocation binary. Someone receiving 90% of their requested grant
   amount will likely still be able to attend. Suppose you have 11
   people, all requesting 100 USD, and you have 1000 USD to spend. The
   greedy algorithm would give the first ten of them 100 USD and find
   its purse empty for the eleventh. It would almost certainly be
   better to give them all 90.91 USD instead.&lt;/li&gt;
&lt;li&gt;Game-theoretically, it makes a lot of sense for everyone to apply
   for a small grant that they will almost certainly get. (This is not
   a real issue for us, because we still have humans eyeballing all
   the applications.)&lt;/li&gt;
&lt;li&gt;The only difference between applications is the amount they're
   requesting, but there are people that we would like to bias in
   favor of. For example, we'd like to try very hard to get speakers
   or tutorial presenters to the conference, we might want to reward
   people doing open source work, et cetera.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Selecting these critera is definitely squarely in the realm of
politics, and I'd like to stick to the realm of math; so let's just
assume that we can assign scores to applicants and that those scores
are fair and just. If you feel like we shouldn't bias in favor of
anyone at all, just assume that whenever I say "the score of an
applicant" I mean "the number 1".&lt;/p&gt;
&lt;h4&gt;A slightly smarter greedy algorithm&lt;/h4&gt;
&lt;p&gt;One of the key ideas (which a lot of people seem to have when tackling
this problem) is to translate an application's score into an amount of
the budget. So, for example, let's say that the sum of all scores is
100, and your score is 10, that means you can have up to 10% of the
budget allocated to you.&lt;/p&gt;
&lt;p&gt;So, I make a pass over all the remaining applicants. If you're asking
less than your budget slice, you get your requested grant. If you're
asking for more, I save you for a future pass. Even though the budget
goes down between passes, budget slices will go up, because the total
score drops.&lt;/p&gt;
&lt;p&gt;You can't do this in one pass, increasing the budget as you go along
if people request less than their slice, because you might introduce
order dependence. For example, consider what happens when Alice and
Charlie both need more than the budget allows for (and they have the
same score and requested amount), and Bob needs less. If you process
them in the order Alice - Bob - Charlie, Charlie may get his requested
grant and Alice may not, just because Bob's in the middle making the
budget bigger for Charlie.&lt;/p&gt;
&lt;p&gt;Once everyone left is requesting more than their slice, they just get
their slice instead of their requested amount.&lt;/p&gt;
&lt;p&gt;This solution is adequate, but I'm not completely satisfied; everyone
besides the last pass will get full grant amounts. You can find my
implementation of this algorithm
&lt;a href="https://github.com/lvh/hood/blob/master/src/hood/greedy.clj"&gt;on Github&lt;/a&gt;
as well.&lt;/p&gt;
&lt;h4&gt;A better model&lt;/h4&gt;
&lt;p&gt;I think we can do better by applying some elementary probability
theory. What we really want is to maximize the total score of the
applicants that we expect to see at PyCon as a consequence of
financial aid. Probability theory has a thing called the expected
value of a random variable, which is pretty much just the integral of
the random variable with respect to the probability. In our case, that
just means that we want to maximize the sum of the probabiliies that a
given applicant will come to PyCon given a particular grant amount,
weighted by their score:&lt;/p&gt;
&lt;p&gt;$$\max \sum s_i \cdot p_i$$&lt;/p&gt;
&lt;p&gt;That just restates problems we can't solve in terms of problems we
can't solve. What on earth could the probability that someone shows up
be? We can't know the real value, since it's specific to each
individual, and dependent on a lot of random, unknowable events. We
can, however, make an educated guess. If we don't give them any money,
they probably won't come. If we give them the amount they're asking
for, they probably will.&lt;/p&gt;
&lt;p&gt;We could conjecture that the probability someone will come to the
conference is approximately the fraction of the amount they requested
that they actually received:&lt;/p&gt;
&lt;p&gt;$$p_i = \frac{g_i}{r_i}$$&lt;/p&gt;
&lt;p&gt;For example, if someone gets 90% of their
requested grant, we estimate that the odds they will attend are also
90%; if we give them only 10%, we estimate it at just 10%.&lt;/p&gt;
&lt;p&gt;Alternatively, we could conjecture that it's closer to the &lt;em&gt;square&lt;/em&gt; of
that ratio; when giving someone a value that's very close to what they
asked for, their probability of attending is still going to be very
high; but if we only give them half, the odds they will attend will be
closer to 25%, much lower than 50%. So, the expression becomes:&lt;/p&gt;
&lt;p&gt;$$p^{\prime}_i = \left(\frac{g_i}{r_i}\right)^{2}$$&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Update:&lt;/em&gt; I now realize that this is probably not the expression that
 I actually want: it falls off very quickly as soon as an applicant
 gets anything less than the full amount. I've elaborated on this in
 &lt;a href="http://www.lvh.io/blog/2014/04/06/more-on-financial-aid-grant-optimization/"&gt;a new blog post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We will see how the square model emphasizes focusing the available
funds on fewer grants, whereas the linear model will spread smaller
grants more liberally.&lt;/p&gt;
&lt;h4&gt;An attempt with constraint solvers&lt;/h4&gt;
&lt;p&gt;(I would like to thank Mark Engelberg for helping me with the stuff in
this chapter. It may not have panned out, but it was a very
educational experience nonetheless.)&lt;/p&gt;
&lt;p&gt;It'd be nice if we could just declaratively describe the problem,
throw it into a computer program, and have it magically tell us the
answer. Of course, there are programs that do exactly that, called
solvers.&lt;/p&gt;
&lt;p&gt;When I reached out on the Clojure mailing list, Mark Engelberg
helpfully reached out and immediately handed out some cool runnable
example for me to play with. Sure enough, they worked super, and with
a carefully crafted three-person example we could clearly see the
difference between the linear and quadratic models I was talking about
above: under the square model, the concentrated grants, trying harder
to give high-scoring applications the amount they requested. The
linear model spread money out more evenly. That is, with the following
applications:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;alice&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:name&lt;/span&gt; &lt;span class="s"&gt;"Alice"&lt;/span&gt;, &lt;span class="ss"&gt;:score&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;, &lt;span class="ss"&gt;:requested&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;bob&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:name&lt;/span&gt; &lt;span class="s"&gt;"Bob"&lt;/span&gt;, &lt;span class="ss"&gt;:score&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;, &lt;span class="ss"&gt;:requested&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;def &lt;/span&gt;&lt;span class="nv"&gt;carol&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:name&lt;/span&gt; &lt;span class="s"&gt;"Carol"&lt;/span&gt;, &lt;span class="ss"&gt;:score&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;, &lt;span class="ss"&gt;:requested&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;In a linear model, it comes up with:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;alice&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
 &lt;span class="nv"&gt;bob&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;
 &lt;span class="nv"&gt;carol&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;However, in the quadratic model, the optimizer rather gives Carol (who
has a lower score) a complete grant than give Bob a partial one:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="nv"&gt;alice&lt;/span&gt; &lt;span class="mi"&gt;120&lt;/span&gt;
 &lt;span class="nv"&gt;bob&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
 &lt;span class="nv"&gt;carol&lt;/span&gt; &lt;span class="mi"&gt;80&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You can find the code &lt;a href="https://github.com/lvh/hood/blob/master/src/hood/constraint.clj"&gt;on
Github&lt;/a&gt;.
The tests that confirm the difference in behavior for the linear and
quadratic models are in &lt;a href="https://github.com/lvh/hood/blob/master/test/hood/constraint_test.clj"&gt;the
tests&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;There's one issue though; it didn't scale. Not bad enough that you'd
notice on the three-person example (I thought my REPL was just being
laggy), but bad enough that any real-world problem would be completely
unsolvable. Why? Clearly constraint solvers are awesome real world
tools with real world usage, it's not like they're supposed to fall
over as soon as you throw a problem of reasonable size at it.&lt;/p&gt;
&lt;p&gt;Well, let's do some napkin math. If we have 200 financial aid
recipients that are all getting 1000 possible options (somewhere
between 0 USD and 1000 USD, in whole-dollar increments), there's
200,000 possible places to put any given dollar. If we have 100,000
USD to spend, that's:&lt;/p&gt;
&lt;p&gt;$${2 \cdot 10^{5} \choose 10^{5}} = \frac{(2 \cdot 10^{5})!}{10^{5}! \cdot 10^{5}!} \approx 10^{60203}$$&lt;/p&gt;
&lt;p&gt;That is a very big number. I needed logarithms to compute it. It is so
huge that it makes the number of atoms in the observable universe
(about \(10^{80}\)) look like rounding error.&lt;/p&gt;
&lt;p&gt;In an attempt to "fix" that problem, I tried only handing out funds in
chunks of 100 USD each. Then, we have 1000 chunks to hand out and 2000
places to put them:&lt;/p&gt;
&lt;p&gt;$${2000 \choose 1000} = \frac{2000!}{1000! \cdot 1000!} \approx 10^{600}$$&lt;/p&gt;
&lt;p&gt;I have made the problem 59,603 decimal orders of magnitude easier!
Rejoice!&lt;/p&gt;
&lt;p&gt;A constraint solver really doesn't "know" anything about the structure
of the problem you're feeding it. That's a trade-off: in return, it
grants you a lot of freedom in expressing your problem. Constraint
solvers like LoCo are very valuable, they just aren't a good fit for
this problem. They are designed for problems where the constraints
really constraining the solution space. We're clearly not in that
territory. We have many valid solutions, and we're struggling to look
for a &lt;em&gt;good&lt;/em&gt; one.&lt;/p&gt;
&lt;p&gt;There are two ways we can fix this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Compromising on the freedom of expressing the problem. By pouring
   our problem into a specific structured shape, we may be able to use
   a much faster solver, specific to that class of problems. Also, by
   allowing arbitrary real numbers instead of just integers, we can
   use much faster solvers.&lt;/li&gt;
&lt;li&gt;Compromising on finding the &lt;em&gt;optimal&lt;/em&gt; solution, instead searching
   for a &lt;em&gt;decent&lt;/em&gt; solution. You can do that with algorithms like tabu
   search or simulated annealing.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I will be elaborating on these problems in a future blog post.&lt;/p&gt;&lt;/div&gt;</description><category>mathjax</category><category>pycon</category><guid>http://www.lvh.io/posts/2014/03/optimization-problems-and-pycon-financial-aid.html</guid><pubDate>Mon, 10 Mar 2014 23:47:00 GMT</pubDate></item></channel></rss>