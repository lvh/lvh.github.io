<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>lvh (security)</title><link>http://www.lvh.io/</link><description></description><atom:link href="http://www.lvh.io/categories/security.xml" type="application/rss+xml" rel="self"></atom:link><language>en</language><lastBuildDate>Fri, 21 Aug 2015 20:13:01 GMT</lastBuildDate><generator>http://getnikola.com/</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Today's OpenSSL bug (for techies without infosec chops)</title><link>http://www.lvh.io/posts/todays-openssl-bug-for-techies-without-infosec-chops.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;h2&gt;What happened?&lt;/h2&gt;
&lt;p&gt;OpenSSL 1.0.1n+ and 1.0.2b+ had a new feature that allows finding an
alternative certificate chain when the first one fails. The logic in
that feature had a bug in it, such that it didn't properly verify if
the certificates in the alternative chain had the appropriate
permissions; specifically, it didn't check if those certificates are
certificate authorities.&lt;/p&gt;
&lt;p&gt;Specifically, this means that an attacker who has a valid certificate
for any domain, can use that certificate to produce new
certificates. Those normally wouldn't work, but the algorithm for
finding the alternative trust chain doesn't check if the valid
certificate can act as a certificate authority.&lt;/p&gt;
&lt;h2&gt;What's a certificate (chain)?&lt;/h2&gt;
&lt;p&gt;A certificate is a bit like an ID card: it has some information about
you (like your name), and is authenticated by a certificate authority
(in the case of an ID, usually your government).&lt;/p&gt;
&lt;h2&gt;What's a certificate authority?&lt;/h2&gt;
&lt;p&gt;A certificate authority is an entity that's allowed to authenticate
certificates. Your computer typically ships with the identity of those
certificate authorities, so it knows how to recognize certificates
authorized by them.&lt;/p&gt;
&lt;p&gt;In the ID analogy, your computer knows how to recognize photo IDs
issued by e.g. California.&lt;/p&gt;
&lt;p&gt;The issue here is that in some cases, OpenSSL was willing to accept
signatures authenticated by certificates that don't have certificate
authority powers. In the analogy, it would mean that it accepted
CostCo cards as valid ID, too.&lt;/p&gt;
&lt;h2&gt;Why did they say it wouldn't affect most users?&lt;/h2&gt;
&lt;p&gt;This basically means "we're assuming most users are using OpenSSL for
vanilla servers", which is probably true. Most servers do use OpenSSL,
and most clients (browsers) don't.&lt;/p&gt;
&lt;p&gt;The bug affects anyone trying to authenticate their peer. That
includes regular clients, and servers doing client
authentication. Regular servers aren't affected, because they don't
authenticate their peer.&lt;/p&gt;
&lt;p&gt;Servers doing client authentication are fairly rare. The biggest
concern is with clients. While browsers typically don't use OpenSSL, a
lot of API clients do. For those few people affected by the bug and
with clients that use OpenSSL, the bug is catastrophic.&lt;/p&gt;
&lt;h2&gt;What's client authentication?&lt;/h2&gt;
&lt;p&gt;The vast majority of TLS connections only authenticate the
server. When the client opens the connection, the server sends its
certificate. The client checks the certificate chain against the list
of certificate authorities that it knows about. The client is
typically authenticated, but over the protocol spoken inside of TLS
(usually HTTP), not at a TLS level.&lt;/p&gt;
&lt;p&gt;That isn't the only way TLS can work. TLS also supports authenticating
clients with certificates, just like it authenticates servers. This is
called mutually authenticated TLS, because both peers authenticate
each other. At Rackspace Managed Security, we use this for all
communication between internal nodes. We also operate our own
certificate authority to sign all of those certificates.&lt;/p&gt;
&lt;h2&gt;What's TLS?&lt;/h2&gt;
&lt;p&gt;TLS is what SSL has been called for way over a decade. The old name
stuck (particularly in the name "OpenSSL"), but you should probably
stop using it when you're talking about the secure protocol, since all
of the versions of the protocol that were called "SSL" have crippling
security bugs.&lt;/p&gt;
&lt;h2&gt;Why wasn't this found by automated testing?&lt;/h2&gt;
&lt;p&gt;I'm not sure. I wish automated testing this stuff was easier. Since
I'm both a user and a big fan of client authentication, which is a
pretty rare feature, I hope to spend more time in the future creating
easy-to-use automated testing tools for this kind of scenario.&lt;/p&gt;
&lt;h2&gt;How big is the window?&lt;/h2&gt;
&lt;p&gt;1.0.1n and 1.0.2b were both released on 11 Jun 2015. The fixes, 1.0.1p
and 1.0.2d, were released today, on 9 Jul 2015.&lt;/p&gt;
&lt;p&gt;The "good news" is that the bad releases are recent. Most people who
have an affected version will be updating regularly, so the number of
people affected is small.&lt;/p&gt;
&lt;p&gt;The bug affected following platforms (non-exhaustive):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It did not affect stock OS X, because they still ship
  0.9.8. However, the bug does affect a stable version shipped through
  Homebrew (1.0.2c).&lt;/li&gt;
&lt;li&gt;&lt;a href="http://people.canonical.com/~ubuntu-security/cve/2015/CVE-2015-1793.html"&gt;Ubuntu is mostly not affected&lt;/a&gt;. The only affected version
  is the unreleased 15.10 (Wily). Ubuntu has already released an
  update for it.&lt;/li&gt;
&lt;li&gt;The bug affects stable releases of Fedora. I previously mistakenly
  reported that the contrary, but that information was based on their
  package version numbers, which did not match upstream. Fedora
  backported the faulty logic to their version of 1.0.1k, which was
  available in Fedora 21 and 22. They have since released patches; see
  &lt;a href="https://bugzilla.redhat.com/show_bug.cgi?id=1241544"&gt;this ticket&lt;/a&gt; for details. Thanks to Major Hayden for the
  correction!&lt;/li&gt;
&lt;li&gt;The bug does not affect Debian stable, but it does affect
  &lt;a href="https://security-tracker.debian.org/tracker/CVE-2015-1793s=openssl"&gt;testing and unstable&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;The bug affects &lt;a href="https://www.archlinux.org/packages/?sort=-last_update"&gt;ArchLinux testing&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;In conclusion&lt;/h2&gt;
&lt;p&gt;The bug is disastrous, but affects few people. If you're running
stable versions of your operating system, you're almost certainly
safe.&lt;/p&gt;
&lt;p&gt;The biggest concern is with software developers using OS X. That
audience uses HTTPS APIs frequently, and the clients to connect to
those APIs typically use OpenSSL. OS X comes with 0.9.8zf by default
now, which is a recent revision of an ancient branch. Therefore,
people have a strong motivation to get their OpenSSL from a
third-party source. The most popular source is Homebrew, which up
until earlier this morning shipped 1.0.2c. The bug affects that
version. If you installed OpenSSL through Homebrew, you should go
update right now.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>http://www.lvh.io/posts/todays-openssl-bug-for-techies-without-infosec-chops.html</guid><pubDate>Thu, 09 Jul 2015 15:26:58 GMT</pubDate></item><item><title>They do take security seriously</title><link>http://www.lvh.io/posts/they-do-take-security-seriously.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Earlier today, I read an &lt;a href="http://www.troyhunt.com/2015/07/we-take-security-seriously-otherwise.html"&gt;article&lt;/a&gt; about the plethora of
information security breaches in recent history. Its title reads:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“We take security seriously”, otherwise known as “We didn’t take it
seriously enough”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The article then lists a number of companies informing the public that
they've been breached.&lt;/p&gt;
&lt;p&gt;I think this article doesn't just blame the victims of those attacks,
but subjects them to public ridicule. Neither helps anyone, least of
all end users.&lt;/p&gt;
&lt;p&gt;I'm surprised to hear such comments from Troy Hunt. He's certainly an
accomplished professional with extensive security experience. This is
not the first time people have expressed similar thoughts; the
&lt;a href="https://news.ycombinator.com/item?id=9834099"&gt;HN thread&lt;/a&gt; for that article is rife with them.&lt;/p&gt;
&lt;p&gt;The explicit assumption is that these companies wouldn't have gotten
in trouble if only they had taken security more seriously. In a world
where the information services store is increasingly valuable and
software increasingly complex, breaches are going to happen. The idea
that getting breached is their own darn fault is unrealistic.&lt;/p&gt;
&lt;p&gt;This idea is also counterproductive. Firstly, there's one thing all of
the victims being ostracized have in common: they disclosed the
details of the breach. That is exactly what they should have done;
punishing them creates a perverse incentive for victims to hide
breaches in the future, a decidedly worse end-user outcome.&lt;/p&gt;
&lt;p&gt;Secondly, if any breach is as bad as any other breach, there is no
incentive to proactively mitigate damage from future breaches by
hardening internal systems. Why encrypt records, invest in access
control or keep sensitive information in a separate database with
extensive audit logging? It might materially impact end-user security,
but who cares -- all anyone is going to remember is that you got
popped.&lt;/p&gt;
&lt;p&gt;Finally, there's a subtle PR issue: how can the security industry
build deep relationships with clients when we publicly ridicule them
when the inevitable happens?&lt;/p&gt;
&lt;p&gt;These commentators have presumably not been the victims of a breach
themselves. I have trouble swallowing that anyone who's been through
the terrifying experience of being breached, seeing a breach up close
or even just witnessing a hairy situation being defused could air
those thoughts.&lt;/p&gt;
&lt;p&gt;If you haven't been the victim of an attack, and feel that your
security posture is keeping you from becoming one, consider this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What's your threat model?&lt;/li&gt;
&lt;li&gt;How confident are you in your estimation of the capabilities of
   attackers?&lt;/li&gt;
&lt;li&gt;Would you still be okay if your database became three orders of
   magnitude more valuable? Most personal data's value will scale
   linearly with the number of people affected, so if you're a small
   start-up with growth prospects, you'll either fail to execute, or
   be subject to that scenario.&lt;/li&gt;
&lt;li&gt;Would you still be okay if the attacker has a few 0-days?&lt;/li&gt;
&lt;li&gt;What if the adversary is a nation-state?&lt;/li&gt;
&lt;li&gt;How do you &lt;em&gt;know&lt;/em&gt; you haven't been breached?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That brings me to my final thesis: I contest the claim that all of the
companies in the article didn't take security seriously. It is far
more probable that all of the companies cited in the article have
expended massive efforts to protect themselves, and, in doing so,
foiled many attacks. It's also possible that they haven't; but the
onus there is certainly on the accuser.&lt;/p&gt;
&lt;p&gt;Clearly, that's a weak form of disagreement, since "taking something
seriously" is entirely subjective. However, keep in mind that many
targets &lt;em&gt;actually&lt;/em&gt; haven't taken security seriously, and would not
even have the technical sophistication to detect an attack.&lt;/p&gt;
&lt;p&gt;(By the way, if you too would like to help materially improve people's
security, we're hiring. Contact me at &lt;code&gt;_@lvh.io&lt;/code&gt;.)&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>http://www.lvh.io/posts/they-do-take-security-seriously.html</guid><pubDate>Sun, 05 Jul 2015 20:17:18 GMT</pubDate></item><item><title>HTTPS requests with client certificates in Clojure</title><link>http://www.lvh.io/posts/https-requests-with-client-certificates-in-clojure.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;The vast majority of TLS connections only authenticate the
server. When the client opens the connection, the server sends its
certificate. The client checks the certificate against the list of
certificate authorities that it knows about. The client is typically
authenticated, but over the inner HTTP connection, not at a TLS level.&lt;/p&gt;
&lt;p&gt;That isn't the only way TLS can work. TLS also supports authenticating
clients with certificates, just like it authenticates servers. This is
called mutually authenticated TLS, because both peers authenticate
each other. At Rackspace Managed Security, we use this for all
communication between internal nodes. We also operate our own
certificate authority to sign all of those certificates.&lt;/p&gt;
&lt;p&gt;One major library, &lt;a href="https://github.com/http-kit/http-kit"&gt;&lt;code&gt;http-kit&lt;/code&gt;&lt;/a&gt;, makes use of Java's
&lt;code&gt;javax.net.ssl&lt;/code&gt;, notably &lt;code&gt;SSLContext&lt;/code&gt; and &lt;code&gt;SSLEngine&lt;/code&gt;. These Java APIs
are exhaustive, and very... Java. While it's easy to make fun of these
APIs, most other development environments leave you using OpenSSL,
whose APIs are patently misanthropic. While some of these APIs do
leave something to be desired, &lt;a href="https://aphyr.com/"&gt;aphyr&lt;/a&gt; has done a lot of the
hard work of making them more palatable with
&lt;a href="https://github.com/aphyr/less-awful-ssl"&gt;&lt;code&gt;less-awful-ssl&lt;/code&gt;&lt;/a&gt;. That gives you an
&lt;code&gt;SSLContext&lt;/code&gt;. Request methods in &lt;code&gt;http-kit&lt;/code&gt; have an &lt;code&gt;opts&lt;/code&gt; map that
you can pass a &lt;code&gt;:sslengine&lt;/code&gt; object to. Given an &lt;code&gt;SSLContext&lt;/code&gt;, you just
need to do &lt;code&gt;(.createSSLEngine ctx)&lt;/code&gt; to get the engine object you want.&lt;/p&gt;
&lt;p&gt;Another major library, &lt;a href="https://github.com/dakrone/clj-http"&gt;&lt;code&gt;clj-http&lt;/code&gt;&lt;/a&gt;, uses lower-level
APIs. Specifically, it requires [&lt;code&gt;KeyStore&lt;/code&gt;][keystore] instances for
its &lt;code&gt;:key-store&lt;/code&gt; and &lt;code&gt;:trust-store&lt;/code&gt; options. That requires diving deep
into Java's cryptographic APIs, which, as mentioned before, might be
something you want to avoid. While &lt;code&gt;clj-http&lt;/code&gt; is probably the most
popular library, if you want to do fancy TLS tricks, you probably want
to use &lt;code&gt;http-kit&lt;/code&gt; instead for now.&lt;/p&gt;
&lt;p&gt;My favorite HTTP library is &lt;a href="http://aleph.io/"&gt;&lt;code&gt;aleph&lt;/code&gt;&lt;/a&gt; by
&lt;a href="http://ideolalia.com/"&gt;Zach Tellman&lt;/a&gt;.  It uses Netty instead of the usual Java IO
components. Fortunately, Netty's API is at least marginally friendlier
than the one in &lt;code&gt;javax.net.ssl&lt;/code&gt;. Unfortunately, there's no
&lt;code&gt;less-awful-ssl&lt;/code&gt; for Aleph. Plus, since I'm using &lt;a href="https://github.com/ptaoussanis/sente"&gt;&lt;code&gt;sente&lt;/code&gt;&lt;/a&gt; for
asynchronous client-server communication, which doesn't have support
for &lt;code&gt;aleph&lt;/code&gt; yet. So, I'm comfortably stuck with &lt;code&gt;http-kit&lt;/code&gt; for now.&lt;/p&gt;
&lt;p&gt;In conclusion, API design &lt;em&gt;is&lt;/em&gt; UX design. The library that "won" for
us was simply the one that was easiest to use.&lt;/p&gt;
&lt;p&gt;For a deeper dive in how TLS and its building blocks work, you should
watch my talk, &lt;a href="https://www.youtube.com/watch?v=3rmCGsCYJF8"&gt;Crypto 101&lt;/a&gt;, or the matching &lt;a href="https://www.crypto101.io"&gt;book&lt;/a&gt;. It's
free! Oh, and if you're looking for information security positions
(that includes entry-level!) in an inclusive and friendly environment
that puts a heavy emphasis on teaching and personal development, you
should get in touch with me at &lt;code&gt;_@lvh.io&lt;/code&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>http://www.lvh.io/posts/https-requests-with-client-certificates-in-clojure.html</guid><pubDate>Thu, 02 Jul 2015 15:53:20 GMT</pubDate></item><item><title>Conflicting threat models</title><link>http://www.lvh.io/posts/conflicting-threat-models.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;As I mentioned &lt;a href="http://www.lvh.io/posts/were-just-getting-started.html"&gt;in my previous post&lt;/a&gt;, we have a long way to go when it comes to information security. I'll be presenting &lt;a href="https://us.pycon.org/2015/schedule/presentation/342/"&gt;a talk on building secure systems&lt;/a&gt; at PyCon 2015 next month, and I hope to blog more about interesting bits of comprehensible security.&lt;/p&gt;
&lt;p&gt;I'm a strong believer in the importance of threat models. A threat model is your idea of what you're protecting against. It may seem obvious that you can't effectively protect anything without knowing what you're protecting it from. Sadly, simply contemplating your threat model puts you ahead of the curve in today's software industry.&lt;/p&gt;
&lt;p&gt;Threat models often simply deal with how much effort you're willing to spend to prevent something from happening. In a world with finite resources, we have to make choices. Some models are unrealistic or prohibitively expensive to defend against. These questions aren't all strictly technical: perhaps some risk is adequately covered by insurance. Perhaps you have a legal or a compliance requirement to do something, even if the result is technically inferior. These questions are also not just about &lt;em&gt;how much&lt;/em&gt; you're going to do: different threat models can lead to mutually exclusive resolutions, each a clear security win.&lt;/p&gt;
&lt;p&gt;Consider your smartphone. Our phones have a lot of important, private information; it makes sense to protect them. The iPhone 6 provides two options for the lock screen: a passcode and a fingerprint sensor. Passcodes have been around for about as long as smartphones have, while fingerprint sensors are new and exciting. It's clear that either of them is more secure than not protecting your phone at all. But which one is more secure?&lt;/p&gt;
&lt;p&gt;Most people instinctively feel the fingerprint sensor is the way to go. Biometric devices feel advanced; up until recently, they only existed in Hollywood. Fingerprints have their share of issues. It's impossible to pick a new key or have separate keys for separate capabilities; you're stuck with the keys you have. A fingerprint is like a password that you involuntarily leave on everything you touch. That said, turning a fingerprint into something that will unlock your iPhone is out of reach for most attackers.&lt;/p&gt;
&lt;p&gt;Passcodes aren't perfect either. People generally pick poor codes: important dates and years are common, but typically not kept secret in other contexts. If you know someone's birthday, there's a decent chance you can unlock their phone. At least with a passcode, you have the option of picking a good one. Even if you do, a passcode provides little protection against shoulder surfing. Most people unlock their phone dozens of times per day, and spend most of that day in the presence of other people. A lot of those people could see your passcode inconspicuously.&lt;/p&gt;
&lt;p&gt;Two options. Neither is perfect. How do you pick one? To make an informed choice, you need to formalize your threat models.&lt;/p&gt;
&lt;p&gt;In the United States, under the Fifth Amendment, you don't have to divulge information that might incriminate you. I am not a lawyer, and courts have provided conflicting rulings, &lt;a href="https://en.wikipedia.org/wiki/Fifth_Amendment_to_the_United_States_Constitution#Computer_passwords"&gt;but currently it appears that this includes computer passwords.&lt;/a&gt; &lt;a href="http://hamptonroads.com/2014/10/police-can-require-cellphone-fingerprint-not-pass-code?wpisrc=nl-swbd&amp;amp;wpmm=1#"&gt;However, a court has ruled that a fingerprint doesn't count as secret information.&lt;/a&gt; If you can unlock your phone with your fingerprint, they can force you to unlock it.&lt;/p&gt;
&lt;p&gt;If your threat models include people snooping, the fingerprint sensor is superior. If your threat model includes law enforcement, the passcode is superior. So, which do you pick? It depends on your threat model.&lt;/p&gt;
&lt;p&gt;Disclaimer: this is an illustration of how threat models can conflict. It is &lt;em&gt;not&lt;/em&gt; operational security advice; in which case I would point out other options. It is not legal advice, which I am not at all qualified to dispense.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>http://www.lvh.io/posts/conflicting-threat-models.html</guid><pubDate>Sat, 07 Mar 2015 16:56:05 GMT</pubDate></item><item><title>We're just getting started</title><link>http://www.lvh.io/posts/were-just-getting-started.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Most conference talks are transactional. The speaker has a point to
make. After the presentation, it's "over"; only spoken about in
perfect tenses. You've communicated your thoughts, perhaps had a
conversation or two, but, mostly, moved on.&lt;/p&gt;
&lt;p&gt;I've given talks like these. However, about two years ago, I gave a
talk that had a deep impact on my life. That talk was Crypto 101.&lt;/p&gt;
&lt;p&gt;Right before the presentation, cryptanalytic research was released
that popped RC4. I couldn't have asked for a better setup. Turns out
it wasn't &lt;em&gt;just&lt;/em&gt; luck; eventually our systemic failure as an industry
in taking security seriously was bound to catch up with us. Since
then, the proverbial piper has been well-paid. We've seen a plethora
of serious security bugs. Huge corporations have been the victims of
attacks in the billions of dollars a pop. As I'm writing this blog
post, there's an article on a new TLS attack in my reading list.&lt;/p&gt;
&lt;p&gt;It quickly became clear that this wasn't just a one-off thing. I
started writing &lt;a href="http://crypto101.github.io"&gt;Crypto 101, the book,&lt;/a&gt; not too long after
giving the talk. We were, unwittingly, at the crest of a wave that's
still growing. Projects like PyCA and LibreSSL started fighting
tirelessly to make the software we use better. Security talks became a
mandatory part of the programming conference food pyramid. My friends
Hynek and Ying gave fantastic talks. They, too, got "lucky" with a
security bombshell: Heartbleed happened mere days before the
conference.&lt;/p&gt;
&lt;p&gt;Last week, I presented Crypto 101 again at rax.io, Rackspace's
internal conference. It was well-received, and I think I provided
value for people's time. One thing, more than anything, it
crystallized where we are. We're not done yet. There's still a huge
audience left to reach. Interest in information security has done
nothing but grow.  With a total of just over 100,000 downloads for the
book and about half as many for the recording of the presentation,
people are definitely listening. We've made real impact, and we have
people's attention, but we need to keep going.&lt;/p&gt;
&lt;p&gt;One of the two talks I'll be giving at PyCon is a more high-level
overview of how we can build secure systems. More friends of mine will
talk in about TLS there too. Within Rackspace, I'm focusing on
information security. There are awesome things brewing here, and I
hope that we can continue the great work we've been doing so far.&lt;/p&gt;
&lt;p&gt;We've accomplished a lot, but we're just getting started.&lt;/p&gt;&lt;/div&gt;</description><category>crypto</category><category>security</category><guid>http://www.lvh.io/posts/were-just-getting-started.html</guid><pubDate>Tue, 03 Mar 2015 01:06:41 GMT</pubDate></item><item><title>Securing APIs with shims</title><link>http://www.lvh.io/posts/securing-apis-with-shims.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Imagine that you had a capability URL, except instead of giving you
the ability to perform a specific &lt;em&gt;action&lt;/em&gt;, it gave you the ability to
perform a (limited) set of operations on a third party API,
e.g. OpenStack. The capability URL wouldn't just be something you
exercise or revoke; it'd be an API endpoint, mostly indistinguishable
from the real API. Incoming requests would be inspected, and based on
a set of rules, either be rejected or forwarded to the API being
shimmed.&lt;/p&gt;
&lt;h2&gt;Proof of concept&lt;/h2&gt;
&lt;p&gt;At my day job, we had a programming task that I thought logic
programming would be well-suited for. Unfortunately, logic programming
is kind of weird and esoteric. Even programmers with otherwise broad
experiences professed to not being quite sure how it worked, or what
to do with it.&lt;/p&gt;
&lt;p&gt;Therefore, I used up my hack day (a day where we get to hack on random
projects) to cook up some cool stuff using logic programming. I demoed
the usual suspects (&lt;a href="https://github.com/lvh/shimmer/blob/master/src/shimmer/monkey.clj"&gt;the monkey with the banana&lt;/a&gt;, and a
&lt;a href="https://github.com/lvh/shimmer/blob/master/src/shimmer/sudoku.clj"&gt;sudoku solver&lt;/a&gt;), illustrating the difference between the
relational nature of the logic programs and the imperative nature of
the algorithms you might otherwise write to solve the same problems.
Finally, I demoed the aforementioned proxying API shim. The proof of
concept, codenamed shimmer, is &lt;a href="https://github.com/lvh/shimmer/"&gt;up on Github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Let's take a look at the handler function, which takes incoming
requests and modifies them slightly so they can be passed on:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;build-handler&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;target-host&lt;/span&gt; &lt;span class="nv"&gt;target-port&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;fn &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;incoming-request&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;match&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;spy&lt;/span&gt; &lt;span class="nv"&gt;incoming-request&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;let &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;modified-request&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;-&amp;gt; &lt;/span&gt;&lt;span class="nv"&gt;incoming-request&lt;/span&gt;
                                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;dissoc &lt;/span&gt;&lt;span class="ss"&gt;:scheme&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;;; hack&lt;/span&gt;
                                 &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;assoc &lt;/span&gt;&lt;span class="ss"&gt;:host&lt;/span&gt; &lt;span class="nv"&gt;target-host&lt;/span&gt;
                                        &lt;span class="ss"&gt;:port&lt;/span&gt; &lt;span class="nv"&gt;target-port&lt;/span&gt;
                                        &lt;span class="ss"&gt;:throw-exceptions&lt;/span&gt; &lt;span class="nv"&gt;false&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
        &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;spy&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;request&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;spy&lt;/span&gt; &lt;span class="nv"&gt;modified-request&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
      &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:status&lt;/span&gt; &lt;span class="mi"&gt;403&lt;/span&gt; &lt;span class="c1"&gt;;; Forbidden&lt;/span&gt;
       &lt;span class="ss"&gt;:headers&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;"content-type"&lt;/span&gt; &lt;span class="s"&gt;"text/plain"&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
       &lt;span class="ss"&gt;:body&lt;/span&gt; &lt;span class="s"&gt;"Doesn't match!"&lt;/span&gt;&lt;span class="p"&gt;})))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;(Those &lt;code&gt;spy&lt;/code&gt; calls are from the excellent &lt;a href="https://github.com/ptaoussanis/timbre"&gt;&lt;code&gt;timbre&lt;/code&gt;&lt;/a&gt;
library. They make it easy to log values without cluttering up your
code; a godsend while developing with some libraries you're not
terribly familiar with.)&lt;/p&gt;
&lt;p&gt;The matching function looks like this:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="nv"&gt;match&lt;/span&gt;
  &lt;span class="s"&gt;"Checks if the request is allowed."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;req&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;not= &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;l/run&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;q&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
          &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;l/conde&lt;/span&gt;
           &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nf"&gt;l/featurec&lt;/span&gt; &lt;span class="nv"&gt;req&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:request-method&lt;/span&gt; &lt;span class="ss"&gt;:get&lt;/span&gt;&lt;span class="p"&gt;})]&lt;/span&gt;
           &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nf"&gt;l/featurec&lt;/span&gt; &lt;span class="nv"&gt;req&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:request-method&lt;/span&gt; &lt;span class="ss"&gt;:post&lt;/span&gt;
                             &lt;span class="ss"&gt;:headers&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;"x-some-header"&lt;/span&gt;
                                       &lt;span class="s"&gt;"the right header value"&lt;/span&gt;&lt;span class="p"&gt;}})]&lt;/span&gt;
           &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nf"&gt;l/featurec&lt;/span&gt; &lt;span class="nv"&gt;req&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:request-method&lt;/span&gt; &lt;span class="ss"&gt;:post&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
            &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;l/featurec&lt;/span&gt; &lt;span class="nv"&gt;req&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="ss"&gt;:headers&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s"&gt;"x-some-header"&lt;/span&gt;
                                       &lt;span class="s"&gt;"another right header value"&lt;/span&gt;&lt;span class="p"&gt;}})]))&lt;/span&gt;
        &lt;span class="o"&gt;'&lt;/span&gt;&lt;span class="p"&gt;()))&lt;/span&gt;
&lt;/pre&gt;


&lt;h2&gt;Future work&lt;/h2&gt;
&lt;p&gt;Make this thing actually vaguely correct. That means e.g. also
inspecting the body for URL references, and changing those to go
through the proxy as well.&lt;/p&gt;
&lt;p&gt;Start collecting a library of short hand notations for specific API
functionality, e.g. if you're proxying an OpenStack API, you should be
able to just say you want to allow server creation requests, without
having to figure out exactly what those requests look like.&lt;/p&gt;
&lt;p&gt;The spec is hard-coded, it should be specified at runtime. That was
trickier than I had originally anticipated: the vast majority of
&lt;code&gt;core.logic&lt;/code&gt; behavior uses macros. While some functionality is fairly
easy to port, that's probably a red herring: I don't want to port a
gazillion macros. As an example, here's &lt;code&gt;conds&lt;/code&gt;, which is just&lt;code&gt;conde&lt;/code&gt;
as a function (except without support for logical conjunction per
disjunctive set of goals):&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kd"&gt;defn &lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="ss"&gt;:private&lt;/span&gt; &lt;span class="nv"&gt;conds&lt;/span&gt;
  &lt;span class="s"&gt;"Like conde, but a function."&lt;/span&gt;
  &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="nv"&gt;goals&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="k"&gt;if &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;empty?&lt;/span&gt; &lt;span class="nv"&gt;goals&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="nv"&gt;l/fail&lt;/span&gt;
    &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;l/conde&lt;/span&gt; &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nb"&gt;first &lt;/span&gt;&lt;span class="nv"&gt;goals&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
             &lt;span class="p"&gt;[(&lt;/span&gt;&lt;span class="nf"&gt;conds&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;rest &lt;/span&gt;&lt;span class="nv"&gt;goals&lt;/span&gt;&lt;span class="p"&gt;))])))&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;That's not the worst function, but let's just say I see a lot of
&lt;code&gt;macroexpand&lt;/code&gt; in my future if I'm going to take this seriously.&lt;/p&gt;
&lt;p&gt;URLs and bodies should be parsed, so that you can write assertions
against structured data, or against URL patterns, instead of specific
URLs.&lt;/p&gt;
&lt;p&gt;If I ever end up letting any of this be a serious part of my day job,
I'm going to invest a ton of time improving the documentation for both
&lt;code&gt;core.logic&lt;/code&gt; and &lt;code&gt;core.typed&lt;/code&gt;. They're &lt;em&gt;fantastic&lt;/em&gt; projects, but
they're harder to get started with than they could be, and that's a
shame.&lt;/p&gt;&lt;/div&gt;</description><category>crypto</category><category>security</category><guid>http://www.lvh.io/posts/securing-apis-with-shims.html</guid><pubDate>Sat, 21 Feb 2015 06:24:03 GMT</pubDate></item><item><title>On discussing software security improvements</title><link>http://www.lvh.io/posts/on-discussing-software-security-improvements.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;A common criticism of information security folks is that they tend to
advise people to not do any crypto. Through projects like &lt;a class="reference external" href="https://www.crypto101.io/"&gt;Crypto
101&lt;/a&gt;, I've attempted to make a small contribution towards fixing
that.&lt;/p&gt;
&lt;p&gt;In the open source world, various people often try to improve the
security of a project. Because designing secure systems is pretty
hard, they often produce flawed proposals. The aforemetioned tendency
for infosec-conscious people to tell them to stop doing crypto is
experienced as unwelcoming, even dismissive. Typically, the only thing
that's accomplished is that a lot of feelings get hurt; it seems to
only rarely result in improved software.&lt;/p&gt;
&lt;p&gt;I think that's quite unfortunate. I think open source is great, and we
should be not just welcoming and inclusive, but aiming to produce
secure software. Furthermore, even if a flawed proposal is
unsalvageable, a clear description of &lt;em&gt;why&lt;/em&gt; it is flawed will
presumably result in fewer negative interactions. Best case scenario,
the issues with a proposal can be discussed and potentially rectified.&lt;/p&gt;
&lt;p&gt;In an effort to improve this situation, I'm documenting what I believe
to be a useful way to discuss security changes and their tradeoffs. As
Zooko has taught me:&lt;/p&gt;
&lt;blockquote&gt;
Security isn't about perfect versus imperfect or about better versus
worse, it's about &lt;em&gt;this&lt;/em&gt; attack surface versus &lt;em&gt;that&lt;/em&gt; attack
surface.&lt;/blockquote&gt;
&lt;p&gt;This document aims to be the equivalent of an &lt;a class="reference external" href="http://www.sscce.org/"&gt;SSCCE&lt;/a&gt; for generic bug
reports: a blueprint for making suggestions likely to lead to
productive discourse, as long as we can agree that we're trying to
produce more secure software, as well as provide a welcoming
development environment.&lt;/p&gt;
&lt;div class="section" id="important-points"&gt;
&lt;h2&gt;Important points&lt;/h2&gt;
&lt;p&gt;A good proposal should contain:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;A brief description of what you're suggesting.&lt;/li&gt;
&lt;li&gt;A description of the attack model you're considering, why the
current system does not address this issue, and why the suggested
system &lt;em&gt;does&lt;/em&gt; address this issue.&lt;/li&gt;
&lt;li&gt;A motivation of the attack model. Why is it important that this
issue is actually addressed?&lt;/li&gt;
&lt;li&gt;How does this change affect the attack surface (i.e. all of the
ways an attacker can attempt to attack a system)?&lt;/li&gt;
&lt;li&gt;What does the user experience for all users of the system look
like? Many cryptosystems fall over because they're simply unusable
for most users of the system.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="an-example"&gt;
&lt;h2&gt;An example&lt;/h2&gt;
&lt;p&gt;Wul (the widely underestimated language, pronounced &lt;em&gt;/wool/&lt;/em&gt;) is a
general purpose programming language. It has a package repository,
WuPI (the Wul package index, pronounced &lt;em&gt;/woopie/&lt;/em&gt;), the de facto
standard for distributing and installing Wul software.&lt;/p&gt;
&lt;p&gt;WuPI uses TLS as a secure transport. The WuF (Wul foundation,
pronounced &lt;em&gt;/woof/&lt;/em&gt;), maintains a root certificate, distributed with
Wul. Thanks to a well-managed system of intermediary CAs run by a
tireless army of volunteers, this means that both package authors and
consumers know they're talking to the real WuPI.&lt;/p&gt;
&lt;p&gt;Alice is the WuPI BDFL. Bob is a Wul programmer, and would like to
improve the security of WuPI.&lt;/p&gt;
&lt;p&gt;While consumers and authors know that they're talking to the real
WuPI, there is no protection against a malicious WuPI endpoint. (This
problem was recently made worse because WuPI introduced a CDN, greatly
increasing the number of people who could own a node.). You know that
you're talking to something with a WuF-signed certificate (presumably
WuPI, provided the WuF has done a good job managing that certificate),
but you have no idea if that thing is being honest about the packages
it serves you.&lt;/p&gt;
&lt;p&gt;Bob believes WuPI could solve this by using GPG signatures.&lt;/p&gt;
&lt;p&gt;He starts with a brief description of the suggestion:&lt;/p&gt;
&lt;blockquote&gt;
I would like to suggest that WuPI grows support for GPG signatures
of packages. These signatures would be created when a package author
uploads a package. They would optionally be verified when the user
downloads a package.&lt;/blockquote&gt;
&lt;p&gt;He continues with the attack model being considered:&lt;/p&gt;
&lt;blockquote&gt;
I believe this would secure WuPI consumers against a malicious WuPI
endpoints. A malicious WuPI endpoint (assuming it acquires an
appropriate certificate) is currently free to deliver whatever
packages it wants.&lt;/blockquote&gt;
&lt;p&gt;He explains why the current model doesn't address this:&lt;/p&gt;
&lt;blockquote&gt;
The current system assures authenticity and secrecy of the stream
(through TLS), and it ensures that the server authenticates itself
with a WuPI/WuF certificate. It does not ensure that the package is
what the author uploaded.&lt;/blockquote&gt;
&lt;p&gt;He explains why he believes his model does address this:&lt;/p&gt;
&lt;blockquote&gt;
Because the signatures are produced by the author's GPG key, a
malicious WuPI endpoint would not be able to forge them. Therefore,
a consumer is sure that a package with a valid signature is indeed
from the author.&lt;/blockquote&gt;
&lt;p&gt;He explains why this attack model is important:&lt;/p&gt;
&lt;blockquote&gt;
With the new CDN support, the number of people with access to such a
certificate has greatly increased. While I certainly trust all of
the volunteers involved, it would be nice if we didn't &lt;em&gt;have&lt;/em&gt; to.
Furthermore, the software on the servers can always be vulnerable to
attack; as a high-value target, it certainly isn't inconceivable
that an attacker would use an unknown vulnerability to take over a
WuPI endpoint.&lt;/blockquote&gt;
&lt;p&gt;He (believes to) address the attack surface:&lt;/p&gt;
&lt;blockquote&gt;
Because the signatures are optional, the attack surface remains the
same.&lt;/blockquote&gt;
&lt;p&gt;Finally, he addresses the user experience:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The weak point of this scheme is most likely the user experience,
because users historically seem to dislike using GPG.&lt;/p&gt;
&lt;p&gt;I am hopeful that this increased value of participating in the GPG
web of trust will mean that more people participate.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Alice reviews this, and notes a flaw in the proposal:&lt;/p&gt;
&lt;blockquote&gt;
This proposal aims to address a security flaw when the WuPI endpoint
is malicious by adding signatures. However, a malicious WuPI
endpoint can lie by omission, and claim a package was never signed
by the author.&lt;/blockquote&gt;
&lt;p&gt;Bob now realizes this issue, and suggests an improvement:&lt;/p&gt;
&lt;blockquote&gt;
This could be rectified if the user insists on a signature for
packages they expect to be signed.&lt;/blockquote&gt;
&lt;p&gt;As a side note, Alice notes that the attack surface does increase:&lt;/p&gt;
&lt;blockquote&gt;
This places trust in author's ability to manage private keys, which
has historically been shown to be problematic. That introduces a new
attack vector: an attacker can attempt to go after the author's
private key.&lt;/blockquote&gt;
&lt;p&gt;Regardless of the outcome of this conversation, there actually was a
conversation. I believe this to be an improvement over the overall
status quo.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>crypto</category><category>python</category><category>security</category><guid>http://www.lvh.io/posts/on-discussing-software-security-improvements.html</guid><pubDate>Tue, 29 Jul 2014 06:58:27 GMT</pubDate></item><item><title>Securing against timing attacks with Twisted</title><link>http://www.lvh.io/posts/2013/01/securing-against-timing-attacks-with-twisted.html</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;h3&gt;What are timing attacks?&lt;/h3&gt;
&lt;p&gt;Timing attacks are side-channel attacks that rely on inferring secret
information from operations by measuring how long they take to execute.&lt;/p&gt;
&lt;p&gt;A complete explanation is outside of the scope of this article, but
the &lt;a href="https://en.wikipedia.org/wiki/Timing_attack"&gt;Wikipedia article&lt;/a&gt;
might be a good starting point for the interested reader.&lt;/p&gt;
&lt;h3&gt;Why should I care about them?&lt;/h3&gt;
&lt;p&gt;Because they can creep in before you know it, and break your otherwise
fine system.&lt;/p&gt;
&lt;p&gt;A common way they're introduced are string comparisons. String
comparisons in many langauge implementations, including all
implementations of Python I know of, short-circuit. They work roughly
like this:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;strcmp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;s2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;c1&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="n"&gt;c2&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;This means that as soon as they can prove the two strings are not
equal, they return &lt;code&gt;False&lt;/code&gt; and ignore the rest of the string. This is
a very simple and effective performance optimization. And that's
precisely why, from a security point of view, it's a liability.&lt;/p&gt;
&lt;p&gt;Since it takes longer to compare "The quick brown fox jumps over the
lazy dog" to "The quick brown fox jumps over the lazy god" than it
does to compare it to "Lorem ipsum", or even a Lipsum of the same
length, an attacker can use that timing information to figure out what
the original string is that is being compared to, even when he
shouldn't.&lt;/p&gt;
&lt;h3&gt;Why did you care?&lt;/h3&gt;
&lt;p&gt;Password resets.&lt;/p&gt;
&lt;p&gt;The typically recommended way of doing them is to generate a random
number, one that's sufficiently long that an attacker can't guess it.
Then, you relay that number to the user using some alternative channel
(usually a URL in an e-mail).&lt;/p&gt;
&lt;p&gt;Bar the random number, those URLs are predictable. That means an
attacker can trivially try any number he wants. If an attacker is
allowed to do that enough, he could measure timing differences between
different numbers (introduced by string comparison functions that
short-circuit or even by the database's index) to efficiently deduce
the value of a "good" number.&lt;/p&gt;
&lt;p&gt;Also, if membership is private, an attacker may exploit timing
differences in the password reset &lt;em&gt;request&lt;/em&gt; function to farm e-mail
addresses.&lt;/p&gt;
&lt;h3&gt;How do I protect against timing attacks?&lt;/h3&gt;
&lt;p&gt;Just to be clear: timing attacks are a complicated problem, and this
article describes just one strategy I've applied to help secure
against them.&lt;/p&gt;
&lt;p&gt;The easiest way to prevent a timing attack is to make sure that the
timing your hypothetical attacker can measure is unrelated to the work
you have to do.&lt;/p&gt;
&lt;p&gt;Since I was using &lt;a href="http://twistedmatrix.com"&gt;Twisted&lt;/a&gt; and
&lt;a href="http://amp-protocol.net/"&gt;AMP&lt;/a&gt;, this was actually quite easy. I wrote
a decorator for AMP responder functions that does exactly that:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;_immediateResponder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;"""&lt;/span&gt;
&lt;span class="sd"&gt;    A decorator for responder functions that should return immediately and&lt;/span&gt;
&lt;span class="sd"&gt;    execute asynchronously, as a defense against timing attacks.&lt;/span&gt;

&lt;span class="sd"&gt;    The responder decorator should be applied after (above) this decorator::&lt;/span&gt;

&lt;span class="sd"&gt;        @SomeCommand.responder&lt;/span&gt;
&lt;span class="sd"&gt;        @_immediateResponder&lt;/span&gt;
&lt;span class="sd"&gt;        def responder(...):&lt;/span&gt;
&lt;span class="sd"&gt;            ....&lt;/span&gt;

&lt;span class="sd"&gt;    This should be timing attack resistant since it is unconditional: the&lt;/span&gt;
&lt;span class="sd"&gt;    the AMP response is returned immediately, and the real responder is&lt;/span&gt;
&lt;span class="sd"&gt;    scheduled to run at the next chance the reactor has to do so.&lt;/span&gt;

&lt;span class="sd"&gt;    This only works with AMP commands with empty responses. That's probably a&lt;/span&gt;
&lt;span class="sd"&gt;    good idea anyway: almost all information you could add to the response&lt;/span&gt;
&lt;span class="sd"&gt;    is liable to introduce a timing attack vulnerability.&lt;/span&gt;

&lt;span class="sd"&gt;    Since this precludes your ability to communicate success or failure to&lt;/span&gt;
&lt;span class="sd"&gt;    the caller, the decorated function should return quite quickly (or, if it&lt;/span&gt;
&lt;span class="sd"&gt;    can't, that should be clearly documented). Otherwise, you may end up in a&lt;/span&gt;
&lt;span class="sd"&gt;    a race condition, where the caller assumes the operation has completed,&lt;/span&gt;
&lt;span class="sd"&gt;    but it is in progress or hasn't started yet.&lt;/span&gt;

&lt;span class="sd"&gt;    The original responder function is available on the decorated function as&lt;/span&gt;
&lt;span class="sd"&gt;    the ``responderFunction`` attribute.&lt;/span&gt;
&lt;span class="sd"&gt;    """&lt;/span&gt;
    &lt;span class="nd"&gt;@functools.wraps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;wrapped&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;reactor&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;callLater&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="n"&gt;kwargs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;

    &lt;span class="n"&gt;wrapped&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;responderFunction&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;wrapped&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;When I get an incoming RPC call, the function doing the actual work is
scheduled to run at the next reactor iteration. Then, an empty
response is returned. All of this happens in amortized constant time,
and independent of any secrets. As a result, it can't really leak
much about them.&lt;/p&gt;
&lt;h3&gt;An abstraction too high&lt;/h3&gt;
&lt;p&gt;The above was an effective response to a proof-of-concept timing
attack exploit. Unfortunately, that doesn't mean you've fixed every
timing attack.&lt;/p&gt;
&lt;p&gt;In particular, this example is a few layers of abstraction removed
from the grit of real-world I/O. Just because I returned &lt;code&gt;{}&lt;/code&gt; (an
empty response) immediately, doesn't mean the underlying IO happens
immediately.&lt;/p&gt;
&lt;p&gt;In particular, the write output latency could be coerced to depend on
the computation time, because the function passed to it could be
executed before the &lt;code&gt;write&lt;/code&gt;. If that happens, and the time it takes is
dependant on some secret, delaying the write, the latency on the
attacker's side could be used to measure the work done.&lt;/p&gt;
&lt;p&gt;I have not yet been able to turn the above into a working exploit.&lt;/p&gt;
&lt;p&gt;There are a number of ways this could be mitigated. Since there's no
working exploit, it's unclear if this mitigation would render a timing
attack infeasible.&lt;/p&gt;
&lt;p&gt;One way I've considered to mitigate this is to limit the time that the
reactor is blocked. In my concrete example, this was fortunately
already the case, since one of the first things it did was defer to a
thread that released the GIL (to compute the key from the password
using &lt;code&gt;scrypt&lt;/code&gt;). Alternatively, if you're doing this for Python
code, you could write your function cooperatively.&lt;/p&gt;&lt;/div&gt;</description><category>amp</category><category>security</category><category>twisted</category><guid>http://www.lvh.io/posts/2013/01/securing-against-timing-attacks-with-twisted.html</guid><pubDate>Thu, 31 Jan 2013 02:55:00 GMT</pubDate></item></channel></rss>