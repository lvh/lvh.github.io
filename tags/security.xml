<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>lvh (Posts about security)</title><link>https://www.lvh.io/</link><description></description><atom:link href="https://www.lvh.io/tags/security.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 30 Oct 2019 16:24:09 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>How (not) to sign a JSON object</title><link>https://www.lvh.io/posts/how-not-to-sign-a-json-object/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Last year we did a blog post on interservice auth. This post is mostly about authenticating consumers to an API. That’s a related but subtly different problem: you can probably impose more requirements on your internal users than your customers. The idea is the same though: you’re trying to differentiate between a legitimate user and an attacker, usually by getting the legitimate user to prove that they know a credential that the attacker doesn’t.&lt;/p&gt;
&lt;h2&gt;You don’t really want a signature&lt;/h2&gt;
&lt;p&gt;When cryptography engineers say "signature" they tend to mean something asymmetric, like RSA or ECDSA. Developers reach for asymmetric tools too often. There are a lot of ways to screw them up. By comparison, symmetric “signing” (MACs) are easy to use and hard to screw up. HMAC is bulletproof and ubiquitous.&lt;/p&gt;
&lt;p&gt;Unless you have a good reason why you need an (asymmetric) signature, you want a MAC. If you really do want a signature, check out our Cryptographic Right Answers post to make that as safe as possible. For the rest of this blog post, "signing" means symmetrically, and in practice that means HMAC.&lt;/p&gt;
&lt;h2&gt;How to sign a JSON object&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Serialize however you want.&lt;/li&gt;
&lt;li&gt;HMAC. With SHA256? Sure, whatever. We did &lt;a href="https://latacora.singles/2018/04/03/cryptographic-right-answers.html"&gt;a blog post&lt;/a&gt; on that too.&lt;/li&gt;
&lt;li&gt;Concatenate the tag with the message, maybe with a comma in between for easy parsing or something.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Wait, isn’t that basically a HS256 JWT?&lt;/h2&gt;
&lt;p&gt;Shut up. Anyway, no, because you need to parse a header to read the JWT, so you inherit all of the problems that stem from that.&lt;/p&gt;
&lt;h2&gt;How &lt;em&gt;not&lt;/em&gt; to sign a JSON object, if you can help it&lt;/h2&gt;
&lt;p&gt;Someone asked how to sign a JSON object "in-band": where the tag is part of the object you’re signing itself. That's a niche use case, but it happens. You have a JSON object that a bunch of intermediate systems want to read and it’s important  none of them mess with its contents. You can't just send &lt;code&gt;tag || json&lt;/code&gt;: that may be the cryptographically right answer, but now it's not a JSON object anymore so third party services and middleboxes will barf. You also can't get them to reliably pass the tag around as metadata (via a HTTP header or something). You need to put the key &lt;em&gt;on the JSON object&lt;/em&gt;, somehow, to "transparently" sign it. Anyone who cares about validating the signature can, and anyone who cares that the JSON object has a particular structure doesn't break (because the blob is still JSON and it still has the data it's supposed to have in all the familiar places).&lt;/p&gt;
&lt;p&gt;This problem sort-of reminds me of format-preserving encryption. I don’t mean that in a nice way, because there’s no nice way to mean that. Format-preserving encryption means you encrypt a credit card number and the result still sorta looks like a credit card number. It’s terrible and you only do it because you have to. Same with in-band JSON signing.&lt;/p&gt;
&lt;p&gt;As stated, in-band JSON signing means modifying a JSON object (e.g. removing the HMAC tag) and validating that it’s the same thing that was signed. You do that by computing the HMAC again and validating the result. Unfortunately there are infinitely many equal JSON objects with distinct byte-level representations (for some useful definition of equality, like Python’s builtin ==).&lt;/p&gt;
&lt;p&gt;Some of those differences are trivial, while others are fiendishly complicated. You can add as many spaces as you want between some parts of the grammar, like after the colon and before the value in an object. You can reorder the keys in an object. You can escape a character using a Unicode escape sequence (\u2603) instead of using the UTF-8 representation. "UTF-8" may be a serialization format for Unicode, but it’s not a canonicalization technique. If a character has multiple diacritics, they might occur in different orders. Some characters can be written as a base character plus a diacritic, but there’s also an equivalent single character. You can’t always know what the “right” character out of context: is this the symbol for the unit of resistance (U+2126 OHM SIGN) or a Greek capital letter Omega (U+03A9)? Don’t even get me started on the different ways you can write the same floating point number!&lt;/p&gt;
&lt;p&gt;Three approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Canonicalize the JSON.&lt;/li&gt;
&lt;li&gt;Add the tag and the exact string you signed to the object, validate the signature and then validate that the JSON object is the same as the one you got.&lt;/li&gt;
&lt;li&gt;Create an alternative format with an easier canonicalization than JSON.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Canonicalization&lt;/h3&gt;
&lt;p&gt;Canonicalization means taking an object and producing a unique representation for it. Two objects that mean the same thing ("are equal") but are expressed differently canonicalize to the same representation.&lt;/p&gt;
&lt;p&gt;Canonicalization is a quagnet, which is a term of art in vulnerability research meaning quagmire and vulnerability magnet. You can tell it’s bad just by how hard it is to type ‘canonicalization’.&lt;/p&gt;
&lt;p&gt;My favorite canonicalization bug in recent memory is probably Kelby Ludwig’s SAML bug. Hold onto your butts, because this bug broke basically every SAML implementation under the sun in a masterful stroke. It used NameIds (SAML-speak for "the entity this assertion is about") that look like this:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nt"&gt;&amp;lt;NameId&amp;gt;&lt;/span&gt;barney@latacora.com&lt;span class="c"&gt;&amp;lt;!----&amp;gt;&lt;/span&gt;.evil.com&lt;span class="nt"&gt;&amp;lt;/NameId&amp;gt;&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The common canonicalization strategy ("exc-c14n") will remove comments, so that side sees “barney@latacora.com.evil.com”. The common parsing strategy (“yolo”) disagrees, and sees a text node, a comment, and another text node. Since everyone is expecting a NameId to have one text node, you grab the first one. But that says barney@latacora.com, which isn’t what the IdP signed or your XML-DSIG library validated.&lt;/p&gt;
&lt;p&gt;Not to worry: we said we were doing JSON, and JSON is not XML. It’s simpler! Right? There are at least two specs here: Canonical JSON (from OLPC) and an IETF draft (https://tools.ietf.org/id/draft-rundgren-json-canonicalization-scheme-05.html). They work? Probably? But they’re not fun to implement.&lt;/p&gt;
&lt;h3&gt;Include the exact thing you’re signing&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as "to validate a signature I need an exact byte representation of what to sign" and canonicalization is just the default mechanism for getting to an exact byte representation, you could also just attach a specific byte serialization to the object with a tag for it.&lt;/p&gt;
&lt;p&gt;You validate the tag matches the specific serialization, and then you validate that the specific serialization matches the outside object with the tag and specific serialization removed. The upside is that you don’t need to worry about canonicalization; the downside is your messages are about twice the size that they need to be. You can maybe make that a little better with compression, since the repeated data is likely to compress well.&lt;/p&gt;
&lt;h3&gt;The regex bait and switch trick&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as being about already having a perfectly fine serialization to compute a tag over, but the JSON parser/serializer roundtrip screwing it up after you compute the tag, you might try to do something to the serialized format that doesn't know it's JSON. This is a variant of the previous approach: you're just not adding a &lt;em&gt;second&lt;/em&gt; serialization to compute the tag over.&lt;/p&gt;
&lt;p&gt;The clever trick here is to add a field of the appropriate size for your tag with a well-known fake value, then HMAC, then swap the value. For example, if you know the tag is HMAC-SHA256, your tag size is 256 bits aka 32 bytes aka 64 hex chars. You add a unique key (something like &lt;code&gt;__hmac_tag&lt;/code&gt;) with a value of 64 well-known bytes, e.g. 64 ASCII zero bytes. Serialize the object and compute its HMAC. If you document some subset of JSON serialization (e.g. where CRLFs can occur or where extra spaces can occur), you know that the string &lt;code&gt;"__hmac_tag": “000...”&lt;/code&gt; will occur in the serialized byte stream. Now, you can use string replacement to shiv in the real HMAC value. Upon receipt, the decoder finds the tag, reads the HMAC value, replaces it with zeroes, computes the expected tag and compares against the previously read value.&lt;/p&gt;
&lt;p&gt;Because there’s no JSON roundtripping, the parser can’t mess up the JSON object’s specific serialization. The key needs to be unique because of course the string replacement or regular expression doesn’t know how to parse JSON.&lt;/p&gt;
&lt;p&gt;This feels weirdly gross? But at the same time probably less annoying than canonicalization. And it doesn't work if any of the middleboxes modiy the JSON through a parse/re-serialize cycle.&lt;/p&gt;
&lt;h3&gt;An alternative format&lt;/h3&gt;
&lt;p&gt;If you interpret the problem as "canonicalization is hard because JSON is more complex than what I really want to sign", you might think the answer is to reformat the data you want to sign in a format where canonicalization is easy or even automatic.  AWS Signatures do this: there’s a serialization format that’s far less flexible than JSON where you put some key parameters, and then you HMAC that. (There’s an interesting part to it where it also incorporates the hash of the exact message you’re signing -- but we’ll get to that later.)&lt;/p&gt;
&lt;p&gt;This is particularly attractive if there’s a fixed set of simple values you have to sign, or more generally if the thing you’re signing has a predictable format.&lt;/p&gt;
&lt;h2&gt;Request signing in practice&lt;/h2&gt;
&lt;p&gt;Let’s apply this model to a case study of request signing has worked through the years in some popular services. These are not examples of how to do it well, but rather cautionary tales.&lt;/p&gt;
&lt;p&gt;First off, AWS. AWS requires you to sign API requests. The current spec is "v4", which tells you that there is probably at least one interesting version that preceded it.&lt;/p&gt;
&lt;h3&gt;AWS Signing v1&lt;/h3&gt;
&lt;p&gt;Let’s say an AWS operation CreateWidget takes attribute Name which can be any ASCII string. It also takes an attribute Unsafe, which is false by default and the attacker wishes were true. V1 concatenates the key-value pairs you’re signing, so something like Operation=CreateWidget&amp;amp;Name=iddqd became OperationCreateWidgetNameiddqd. You then signed the resulting string using HMAC.&lt;/p&gt;
&lt;p&gt;The problem with this is if I can get you to sign messages for creating widgets with arbitrary names, I can get you to sign operations for arbitrary CreateWidget requests: I just put all the extra keys and values I want in the value you’re signing for me. For example, the request signature for creating a widget named &lt;code&gt;iddqdUnsafetrue&lt;/code&gt; is exactly the same as a request signature for creating a widget named &lt;code&gt;iddqd&lt;/code&gt; with Unsafe equal to true: OperationCreateWidgetNameiddqdUnsafetrue.&lt;/p&gt;
&lt;h3&gt;AWS Signing V2&lt;/h3&gt;
&lt;p&gt;Security-wise: fine.&lt;/p&gt;
&lt;p&gt;Implementation-wise: it’s limited to query-style requests (query parameters for GET, x-www-form-urlencoded for POST bodies) and didn’t support other methods, let alone non-HTTP requests. Sorting request parameters is a burden for big enough requests. Nothing for chunked requests either.&lt;/p&gt;
&lt;p&gt;(Some context: even though most AWS SDKs present you with a uniform interface, there are several different protocol styles in use within AWS. For example, EC2 and S3 are their own thing, some protocols use Query Requests (basically query params in GET queries and POST formencoded bodies), others use REST+JSON, some use REST+XML… There’s even some SOAP! But I think that’s on its way out.)&lt;/p&gt;
&lt;h3&gt;AWS Signing V3&lt;/h3&gt;
&lt;p&gt;AWS doesn’t seem to like V3 very much. The &lt;a href="https://docs.aws.amazon.com/general/latest/gr/sigv4_changes.html"&gt;"what’s new in v4 document"&lt;/a&gt; all but disavows it’s existence, and no live services appear to implement it. It had some annoying problems like distinguishing between signed and unsigned headers (leaving the service to figure it out) and devolving to effectively a bearer token when used over TLS (which is great, as long as it actually gets used over TLS).&lt;/p&gt;
&lt;p&gt;Given how AWS scrubbed it away, it’s hard to say anything with confidence. I’ve found implementations, but that’s not good enough: an implementation may only use a portion of the spec while the badness can be hiding in the rest.&lt;/p&gt;
&lt;h3&gt;AWS Signing V4&lt;/h3&gt;
&lt;p&gt;Security-wise: fine.&lt;/p&gt;
&lt;p&gt;Addressed some problems noted in V2; for example: just signs the raw body bytes and doesn’t care about parameter ordering. This is pretty close to the original recommendation: don’t do inline signing at all, just sign the exact message you’re sending and put a MAC tag on the outside. A traditional objection is that several equivalent requests would have a different representation, e.g. the same arguments but in a different order. It just turns out that in most cases that doesn’t matter, and API auth is one of those cases.&lt;/p&gt;
&lt;p&gt;Also note that all of these schemes are really outside signing, but they’re still interesting because they had a lot of the problems you see on an inline signing scheme (they were just mostly unforced errors).&lt;/p&gt;
&lt;h3&gt;AWS Signing V0&lt;/h3&gt;
&lt;p&gt;For completeness. It is even harder to find than V3: you have to spelunk some SDKs for it. I hear it might have been HMAC(k, service || operation || timestamp), so it didn’t really sign much of the request.&lt;/p&gt;
&lt;h3&gt;Flickr’s API signing&lt;/h3&gt;
&lt;p&gt;One commonality of the AWS vulnerabilities is that none of them attacked the primitive. All of them used HMAC and HMAC has always been safe. Flickr had exactly the same bug as AWS V1 signing, but also used a bad MAC. The tag you sent was MD5(secret + your_concatenated_key_value_pairs). We’ll leave the details of extension attacks for a different time, but the punchline is that if you know the value of H(secret + message) and don’t know s, you get to compute H(secret + message + glue + message2), where glue is some binary nonsense and message2 is an arbitrary attacker controlled string.&lt;/p&gt;
&lt;p&gt;A typical protocol where this gets exploited looks somewhat like query parameters. The simplest implementation will just loop over every key-value pair and assign the value into an associative array. So if you have user=lvh&amp;amp;role=user, I might be able to extend that to a valid signature for user=lvh&amp;amp;role=userSOMEBINARYGARBAGE&amp;amp;role=admin.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Just go ahead and always enforce TLS for your APIs.&lt;/li&gt;
&lt;li&gt;Maybe you don’t need request signing? A bearer token header is fine, or HMAC(k, timestamp) if you’re feeling fancy, or mTLS if you really care.&lt;/li&gt;
&lt;li&gt;Canonicalization is fiendishly difficult.&lt;/li&gt;
&lt;li&gt;Add a signature on the outside of the request body, make sure the request body is complete, and don’t worry about "signing what is said versus what is meant" -- it’s OK to sign the exact byte sequence.&lt;/li&gt;
&lt;li&gt;The corollary here is that it’s way harder to do request signing for a REST API (where stuff like headers and paths and methods matter) than it is to do signing for an RPC-like API.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/how-not-to-sign-a-json-object/</guid><pubDate>Thu, 25 Jul 2019 01:56:06 GMT</pubDate></item><item><title>The PGP problem</title><link>https://www.lvh.io/posts/the-pgp-problem/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;a href="https://blog.cryptographyengineering.com/2014/08/13/whats-matter-with-pgp/"&gt;Cryptography engineers have been tearing their hair out over PGP’s deficiencies&lt;/a&gt; for (literally) decades. When other kinds of engineers get wind of this, they’re shocked. PGP is bad? Why do people keep telling me to use PGP? The answer is that they shouldn’t be telling you that, because PGP is bad and needs to go away.&lt;/p&gt;
&lt;p&gt;There are, as you’re about to see, lots of problems with PGP. Fortunately, if you’re not morbidly curious, there’s a simple meta-problem with it: it was designed in the 1990s, before serious modern cryptography. No competent crypto engineer would design a system that looked like PGP today, nor tolerate most of its defects in any other design. Serious cryptographers have largely given up on PGP and don’t spend much time publishing on it anymore (&lt;a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-poddebniak.pdf"&gt;with a notable exception&lt;/a&gt;). Well-understood problems in PGP have gone unaddressed for over a decade because of this.&lt;/p&gt;
&lt;p&gt;Two quick notes: first, we wrote this for engineers, not lawyers and activists. Second: “PGP” can mean a bunch of things, from the &lt;a href="https://tools.ietf.org/html/rfc4880"&gt;OpenPGP standard&lt;/a&gt; to its reference implementation in GnuPG. We use the term “PGP” to cover all of these things.&lt;/p&gt;
&lt;h2&gt;The Problems&lt;/h2&gt;
&lt;h3&gt;Absurd Complexity&lt;/h3&gt;
&lt;p&gt;For reasons none of us here in the future understand, PGP has a packet-based structure. A PGP message (in a “.asc” file) is an archive of typed packets. There are &lt;a href="https://tools.ietf.org/html/rfc4880#page-13"&gt;at least 8 different ways&lt;/a&gt; of encoding the length of a packet, depending on whether you’re using “new” or “old” format packets. The “new format” packets have variable-length lengths, like BER (try to write a PGP implementation and you may wish for the sweet release of ASN.1). Packets can have subpackets. There are overlapping variants of some packets. The most recent keyserver attack happened because GnuPG &lt;a href="https://threadreaderapp.com/thread/1147162583969009664.html"&gt;accidentally went quadratic&lt;/a&gt; in parsing keys, which also follow this deranged format.&lt;/p&gt;
&lt;p&gt;That’s just the encoding. The actual system doesn’t get simpler. There are keys and subkeys. Key IDs and key servers and key signatures. Sign-only and encrypt-only. Multiple “key rings”. Revocation certificates. Three different compression formats. This is all before we get to smartcard support.&lt;/p&gt;
&lt;h3&gt;Swiss Army Knife Design&lt;/h3&gt;
&lt;p&gt;If you’re stranded in the woods and, I don’t know, need to repair your jean cuffs, it’s handy if your utility knife has a pair of scissors. But nobody who does serious work uses their multitool scissors regularly.&lt;/p&gt;
&lt;p&gt;A Swiss Army knife does a bunch of things, all of them poorly. PGP does a mediocre job of signing things, a relatively poor job of encrypting them with passwords, and a pretty bad job of encrypting them with public keys. PGP is not an especially good way to securely transfer a file. It’s a clunky way to sign packages. It’s not great at protecting backups. It’s a downright dangerous way to converse in secure messages.&lt;/p&gt;
&lt;p&gt;Back in the MC Hammer era from which PGP originates, “encryption” was its own special thing; there was one tool to send a file, or to back up a directory, and another tool to encrypt and sign a file. Modern cryptography doesn’t work like this; it’s purpose built. Secure messaging wants crypto that is different from secure backups or package signing.&lt;/p&gt;
&lt;h3&gt;Mired In Backwards Compatibility&lt;/h3&gt;
&lt;p&gt;PGP predates modern cryptography; there are Hanson albums that have aged better. If you’re lucky, your local GnuPG defaults to 2048-bit RSA, the 64-bit-block CAST5 cipher in CFB, and the OpenPGP MDC checksum (about which more later). If you encrypt with a password rather than with a public key, the OpenPGP protocol specifies PGP’s S2K password KDF. These are, to put it gently, not the primitives a cryptography engineer would select for a modern system.&lt;/p&gt;
&lt;p&gt;We’ve learned a lot since Steve  Urkel graced the airwaves during ABC’s TGIF: that you should authenticate your ciphertexts (and avoid CFB mode) would be an obvious example, but also that 64-bit block ciphers are bad, that we can do much better than RSA, that mixing compression and encryption is dangerous, and that KDFs should be both time- and memory-hard.&lt;/p&gt;
&lt;p&gt;Whatever the OpenPGP RFCs may say, you’re probably not doing any of these things if you’re using PGP, nor can you predict when you will. Take AEAD ciphers: the Rust-language Sequoia PGP defaulted to the AES-EAX AEAD mode, which is great, and nobody can read those messages because most PGP installs don’t know what EAX mode is, which is not great. Every well-known bad cryptosystem eventually sprouts an RFC extension that supports curves or AEAD, so that its proponents can claim on message boards that they support modern cryptography. RFC’s don’t matter: only the installed base does. We’ve understood authenticated encryption for 2 decades, and PGP is old enough to buy me drinks; enough excuses.&lt;/p&gt;
&lt;p&gt;You can have backwards compatibility with the 1990s or you can have sound cryptography; &lt;em&gt;you can’t have both&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Obnoxious UX&lt;/h3&gt;
&lt;p&gt;We can’t say this any better than Ted Unangst:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There was a PGP usability study conducted a few years ago where a group of technical people were placed in a room with a computer and asked to set up PGP. Two hours later, they were never seen or heard from again.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;If you’d like empirical data of your own to back this up, here’s an experiment you can run: find an immigration lawyer and talk them through the process of getting Signal working on their phone. You probably don’t suddenly smell burning toast. Now try doing that with PGP.&lt;/p&gt;
&lt;h3&gt;Long-Term Secrets&lt;/h3&gt;
&lt;p&gt;PGP begs users to keep a practically-forever root key tied to their identity. It does this by making keys annoying to generate and exchange, by encouraging “key signing parties”, and by creating a “web of trust” where keys depend on other keys.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://blog.filippo.io/giving-up-on-long-term-pgp/"&gt;Long term keys are almost never what you want&lt;/a&gt;. If you keep using a key, it eventually gets exposed. You want the blast radius of a compromise to be as small as possible, and, just as importantly, you don’t want users to hesitate even for a moment at the thought of rolling a new key if there’s any concern at all about the safety of their current key.&lt;/p&gt;
&lt;p&gt;The PGP cheering section will immediately reply “that’s why you keep keys on a Yubikey”. To a decent first approximation, nobody in the whole world uses the expensive Yubikeys that do this, and you can’t imagine a future in which that changes (we can barely get U2F rolled out, and those keys are disposable). We can’t accept bad cryptosystems just to make Unix nerds feel better about their toys.&lt;/p&gt;
&lt;h3&gt;Broken Authentication&lt;/h3&gt;
&lt;p&gt;More on PGP’s archaic primitives: way back in 2000, the OpenPGP working group realized they needed to authenticate ciphertext, and that PGP’s signatures weren’t accomplishing that. So OpenPGP invented &lt;a href="https://tools.ietf.org/html/rfc4880#section-5.14"&gt;the MDC system&lt;/a&gt;: PGP messages with MDCs attach a SHA-1 of the plaintext to the plaintext, which is then encrypted (as normal) in CFB mode.&lt;/p&gt;
&lt;p&gt;If you’re wondering how PGP gets away with this when modern systems use relatively complex AEAD modes (why can’t everyone just tack a SHA-1 to their plaintext), you’re not alone. Where to start with this Rube Goldberg contraption? The PGP MDC can be stripped off messages  it was encoded in such a way that you can simply chop off the last 22 bytes of the ciphertext to do that. To retain backwards compatibility with insecure older messages, PGP introduced a new packet type to signal that the MDC needs to be validated; if you use the wrong type, the MDC doesn’t get checked. Even if you do, the new SEIP packet format is close enough to the insecure SE format that you can potentially trick readers into downgrading; &lt;a href="https://mailarchive.ietf.org/arch/msg/openpgp/tB00vO5r-qneX9wz1xz3netpXVU"&gt;Trevor Perrin worked the SEIP out to 16 whole bits of security.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And, finally, even if everything goes right, the reference PGP implementation will (wait for it) release unauthenticated plaintext to callers, &lt;em&gt;even if the MDC doesn’t match&lt;/em&gt;.&lt;/p&gt;
&lt;h3&gt;Incoherent Identity&lt;/h3&gt;
&lt;p&gt;PGP is an application. It’s a set of integrations with other applications. It’s a file format. It’s also a social network, and a subculture.&lt;/p&gt;
&lt;p&gt;PGP pushes notion of a cryptographic identity. You generate a key, save it in your keyring, print its fingerprint on your business card, and publish it to a keyserver. You sign other people’s keys. They in turn may or may not rely on your signatures to verify other keys. Some people go out of their way to meet other PGP users in person to exchange keys and more securely attach themselves to this “web of trust”. Other people organize “key signing parties”. The image you’re conjuring in your head of that accurately explains how hard it is to PGP’s devotees to switch to newer stuff.&lt;/p&gt;
&lt;p&gt;None of this identity goop works. Not the key signing web of trust, not the keyservers, not the parties. Ordinary people will trust anything that looks like a PGP key no matter where it came from  how could they not, when even an expert would have a hard time articulating how to evaluate a key? Experts don’t trust keys they haven’t exchanged personally. Everyone else relies on centralized authorities to distribute keys. PGP’s key distribution mechanisms are theater.&lt;/p&gt;
&lt;h3&gt;Leaks Metadata&lt;/h3&gt;
&lt;p&gt;Forget the email debacle for a second (we’ll get to that later). PGP by itself leaks metadata. Messages are (in normal usage) linked directly to key identifiers, which are, throughout PGP’s cobweb of trust, linked to user identity. Further, a rather large fraction of PGP users make use of keyservers, which can themselves leak to the network the identities of which PGP users are communicating with each other.&lt;/p&gt;
&lt;h3&gt;No Forward Secrecy&lt;/h3&gt;
&lt;p&gt;A good example of that last problem: secure messaging crypto demands forward secrecy. Forward secrecy means that if you lose your key to an attacker today, they still can’t go back and read yesterday’s messages; they had to be there with the key yesterday to read them. In modern cryptography engineering, we assume our adversary is recording everything, into infinite storage. PGP’s claimed adversaries include world governments, many of whom are certainly doing exactly that. Against serious adversaries and without forward secrecy, breaches are a question of “when”, not “if”.&lt;/p&gt;
&lt;p&gt;To get forward secrecy in practice, you typically keep two secret keys: a short term session key and a longer-term trusted key. The session key is ephemeral (usually the product of a DH exchange) and the trusted key signs it, so that a man-in-the-middle can’t swap their own key in. It’s theoretically possible to achieve a facsimile of forward secrecy using the tools PGP provides. Of course, pretty much nobody does this.&lt;/p&gt;
&lt;h3&gt;Clumsy Keys&lt;/h3&gt;
&lt;p&gt;An OpenBSD signify(1) public key is a Base64 string short enough to fit in the middle of a sentence in an email; the private key, which isn’t an interchange format, is just a line or so longer. A PGP public key is a whole giant Base64 document; if you’ve used them often, you’re probably already in the habit of attaching them rather than pasting them into messages so they don’t get corrupted. Signify’s key is a state-of-the-art Ed25519 key; PGP’s is a weaker RSA key.&lt;/p&gt;
&lt;p&gt;You might think this stuff doesn’t matter, but it matters a lot; orders of magnitude more people use SSH and manage SSH keys than use PGP. SSH keys are trivial to handle; PGP’s are not.&lt;/p&gt;
&lt;h3&gt;Negotiation&lt;/h3&gt;
&lt;p&gt;PGP supports ElGamal. PGP supports RSA. PGP supports the NIST P-Curves. PGP supports Brainpool. PGP supports Curve25519. PGP supports SHA-1. PGP supports SHA-2. PGP supports RIPEMD160. PGP supports IDEA. PGP supports 3DES. PGP supports CAST5. PGP supports AES. There is no way this is a complete list of what PGP supports.&lt;/p&gt;
&lt;p&gt;If we’ve learned 3 important things about cryptography design in the last 20 years, at least 2 of them are that negotiation and compatibility are evil. The flaws in cryptosystems tend to appear in the joinery, not the lumber, and expansive crypto compatibility increases the amount of joinery. Modern protocols like TLS 1.3 are jettisoning backwards compatibility with things like RSA, not adding it. New systems support &lt;em&gt;just a single suite of primitives&lt;/em&gt;, and a simple version number. If one of those primitives fails, you bump the version and chuck the old protocol all at once.&lt;/p&gt;
&lt;p&gt;If we’re unlucky, and people are still using PGP 20 years from now, PGP will be the only reason any code anywhere includes CAST5. We can’t say this more clearly or often enough: you can have backwards compatibility with the 1990s or you can have sound cryptography; you can’t have both.&lt;/p&gt;
&lt;h3&gt;Janky Code&lt;/h3&gt;
&lt;p&gt;The de facto standard implementation of PGP is GnuPG. GnuPG is not carefully built. It’s a sprawling C-language codebase with duplicative functionality (write-ups of the most recent SKS key parsing denial of service noted that it has multiple key parsers, for instance) with a &lt;a href="https://www.cvedetails.com/vulnerability-list/vendor_id-4711/Gnupg.html"&gt;long track record of CVEs&lt;/a&gt; ranging from memory corruption to cryptographic side channels. It has at times been possible to strip authenticators off messages without GnuPG noticing. It’s been possible to feed it keys that don’t fingerprint properly without it noticing. The 2018 Efail vulnerability was a result of it releasing unauthenticated plaintext to callers. GnuPG is not good.&lt;/p&gt;
&lt;p&gt;GnuPG is also effectively the reference implementation for PGP, and also the basis for most other tools that integrate PGP cryptography. It isn’t going anywhere. To rely on PGP is to rely on GPG.&lt;/p&gt;
&lt;h2&gt;The Answers&lt;/h2&gt;
&lt;p&gt;One of the rhetorical challenges of persuading people to stop using PGP is that there’s no one thing you can replace it with, &lt;em&gt;nor should there be&lt;/em&gt;. What you should use instead depends on what you’re doing.&lt;/p&gt;
&lt;h3&gt;Talking To People&lt;/h3&gt;
&lt;p&gt;Use Signal. Or Wire, or WhatsApp, or some other Signal-protocol-based secure messenger.&lt;/p&gt;
&lt;p&gt;Modern secure messengers are purpose-built around messaging. They use privacy-preserving authentication handshakes, repudiable messages, &lt;em&gt;cryptographic ratchets&lt;/em&gt; that rekey on every message exchange, and, of course, modern encryption primitives. Messengers are trivially easy to use and there’s no fussing over keys and subkeys. If you use Signal, you get even more than that: you get a system so paranoid about keeping private metadata off servers that it tunnels Giphy searches to avoid traffic analysis attacks, and until relatively recently didn’t even support user profiles.&lt;/p&gt;
&lt;h3&gt;Encrypting Email&lt;/h3&gt;
&lt;p&gt;Don’t.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://news.ycombinator.com/item?id=16088386"&gt;Email is insecure&lt;/a&gt;. Even with PGP, it’s default-plaintext, which means that even if you do everything right, some totally reasonable person you mail, doing totally reasonable things, will invariably CC the quoted plaintext of your encrypted message to someone else (we don’t know a PGP email user who hasn’t seen this happen). PGP email is forward-insecure. Email metadata, including the subject (which is literally message content), are always plaintext.&lt;/p&gt;
&lt;p&gt;If you needed another reason, &lt;a href="https://www.usenix.org/system/files/conference/usenixsecurity18/sec18-poddebniak.pdf"&gt;read the Efail paper&lt;/a&gt;. The GnuPG community, &lt;a href="https://web.archive.org/web/20181225214730/https://flaked.sockpuppet.org/2018/05/16/a-unified-timeline.html"&gt;which mishandled the Efail disclosure&lt;/a&gt;, talks this research down a lot, but it was accepted at Usenix Security (one of the top academic software security venues) and at Black Hat USA (&lt;em&gt;the&lt;/em&gt; top industry software security venue), was one of the best cryptographic attacks of the last 5 years, and is a pretty devastating indictment of the PGP ecosystem. As you’ll see from the paper, S/MIME isn’t better.&lt;/p&gt;
&lt;p&gt;This isn’t going to get fixed. To make actually-secure email, you’d have to tunnel another protocol over email (you’d still be conceding traffic analysis attacks). At that point, why bother pretending?&lt;/p&gt;
&lt;p&gt;Encrypting email is asking for a calamity. Recommending email encryption to at-risk users is malpractice. Anyone who tells you it’s secure to communicate over PGP-encrypted email is putting their weird preferences ahead of your safety.&lt;/p&gt;
&lt;h3&gt;Sending Files&lt;/h3&gt;
&lt;p&gt;Use &lt;a href="https://github.com/warner/magic-wormhole"&gt;Magic Wormhole&lt;/a&gt;. Wormhole clients use a one-time password-authenticated key exchange (PAKE) to encrypt files to recipients. It’s easy (for nerds, at least), secure, and fun: we haven’t introduced wormhole to anyone who didn’t start gleefully wormholing things immediately just like we did.&lt;/p&gt;
&lt;p&gt;Someone stick a Windows installer on a Go or Rust implementation of Magic Wormhole right away; it’s too great for everyone not to have.&lt;/p&gt;
&lt;p&gt;If you’re working with lawyers and not with technologists, Signal does a perfectly cromulent job of securing file transfers. Put a Signal number on your security page to receive bug bounty reports, not a PGP key.&lt;/p&gt;
&lt;h3&gt;Encrypting Backups&lt;/h3&gt;
&lt;p&gt;Use Tarsnap. &lt;a href="https://www.tarsnap.com/design.html"&gt;Colin can tell you all about how Tarsnap is optimized to protect backups.&lt;/a&gt; Or really, use any other encrypted backup tool that lots of other people use; they won’t be as good as Tarsnap but they’ll all do a better job than PGP will.&lt;/p&gt;
&lt;p&gt;Need offline backups? Use encrypted disk images; they’re built into modern Windows, Linux, and macOS. &lt;a href="https://sockpuppet.org/blog/2014/04/30/you-dont-want-xts/"&gt;Full disk encryption isn’t great&lt;/a&gt;, but it works fine for this use case, and it’s easier and safer than PGP.&lt;/p&gt;
&lt;h3&gt;Signing Packages&lt;/h3&gt;
&lt;p&gt;Use Signify/Minisign. &lt;a href="https://www.openbsd.org/papers/bsdcan-signify.html"&gt;Ted Unangst will tell you all about it.&lt;/a&gt; It’s what OpenBSD uses to sign packages. It’s extremely simple and uses modern signing. &lt;a href="https://jedisct1.github.io/minisign/"&gt;Minisign&lt;/a&gt;, from Frank Denis, the libsodium guy, brings the same design to Windows and macOS; it has bindings for Go, Rust, Python, Javascript, and .NET; it’s even compatible with Signify.&lt;/p&gt;
&lt;h3&gt;Encrypting Application Data&lt;/h3&gt;
&lt;p&gt;Use  &lt;a href="https://github.com/jedisct1/libsodium"&gt;libsodium&lt;/a&gt; It builds everywhere, has interface that’s designed to be hard to misuse, and you won’t have to shell out to a binary to use it.&lt;/p&gt;
&lt;h3&gt;Encrypting Files&lt;/h3&gt;
&lt;p&gt;This really is a problem. If you’re/not/making a backup, and you’re /not/archiving something offline for long-term storage, and you’re /not/encrypting in order to securely send the file to someone else, and you’re /not/encrypting virtual drives that you mount/unmount as needed to get work done, then there’s no one good tool that does this now. Filippo Valsorda is working on “&lt;a href="https://docs.google.com/document/d/11yHom20CrsuX8KQJXBBw04s80Unjv8zCg_A7sPAX_9Y/view"&gt;age&lt;/a&gt;” for these use cases, and I'm super optimistic about it, but it's not there yet.&lt;/p&gt;
&lt;p&gt;Hopefully it’s clear that this is a pretty narrow use case. We work in software security and handle sensitive data, including bug bounty reports (another super common “we need PGP!” use case), and we almost never have to touch PGP.&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/the-pgp-problem/</guid><pubDate>Wed, 17 Jul 2019 03:14:00 GMT</pubDate></item><item><title>The default OpenSSH key encryption is worse than plaintext</title><link>https://www.lvh.io/posts/the-default-openssh-key-encryption-is-worse-than-plaintext/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;The eslint-scope npm package got compromised recently, stealing npm credentials from your home directory. We started running tabletop exercises: what else would you smash-and-grab, and how can we mitigate that risk?&lt;/p&gt;
&lt;p&gt;Most people have an RSA SSH key laying around. That SSH key has all sorts of privileges: typically logging into prod and GitHub access. Unlike an npm credential, an SSH key is encrypted, so perhaps it’s safe even if it leaks? Let’s find out!&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;user&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="nv"&gt;work&lt;/span&gt; &lt;span class="nv"&gt;/tmp&lt;/span&gt; &lt;span class="nv"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;ssh-keygen&lt;/span&gt;
&lt;span class="nv"&gt;Generating&lt;/span&gt; &lt;span class="nv"&gt;public/private&lt;/span&gt; &lt;span class="nv"&gt;rsa&lt;/span&gt; &lt;span class="nb"&gt;key &lt;/span&gt;&lt;span class="nv"&gt;pair.&lt;/span&gt;
&lt;span class="nv"&gt;Enter&lt;/span&gt; &lt;span class="nv"&gt;file&lt;/span&gt; &lt;span class="nv"&gt;in&lt;/span&gt; &lt;span class="nv"&gt;which&lt;/span&gt; &lt;span class="nv"&gt;to&lt;/span&gt; &lt;span class="nv"&gt;save&lt;/span&gt; &lt;span class="nv"&gt;the&lt;/span&gt; &lt;span class="nb"&gt;key &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nf"&gt;/home/user/.ssh/id_rsa&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="nv"&gt;mykey&lt;/span&gt;
&lt;span class="nv"&gt;...&lt;/span&gt;
&lt;span class="nv"&gt;user&lt;/span&gt;&lt;span class="o"&gt;@&lt;/span&gt;&lt;span class="nv"&gt;work&lt;/span&gt; &lt;span class="nv"&gt;/tmp&lt;/span&gt; &lt;span class="nv"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;head&lt;/span&gt; &lt;span class="nv"&gt;-n&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="nv"&gt;mykey&lt;/span&gt;
&lt;span class="nv"&gt;-----BEGIN&lt;/span&gt; &lt;span class="nv"&gt;RSA&lt;/span&gt; &lt;span class="nv"&gt;PRIVATE&lt;/span&gt; &lt;span class="nv"&gt;KEY-----&lt;/span&gt;
&lt;span class="nv"&gt;Proc-Type&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;,&lt;span class="nv"&gt;ENCRYPTED&lt;/span&gt;
&lt;span class="nv"&gt;DEK-Info&lt;/span&gt;&lt;span class="err"&gt;:&lt;/span&gt; &lt;span class="nv"&gt;AES-128-CBC&lt;/span&gt;,&lt;span class="nv"&gt;CB973D5520E952B8D5A6B86716C6223F&lt;/span&gt;

&lt;span class="nv"&gt;+5ZVNE65kl8kwZ808e4+Y7Pr8IFstgoArpZJ/bkOs7rB9eAfYrx2CLBqLATk1RT/&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;You can tell it’s encrypted because it says so right there. It also doesn’t start with &lt;code&gt;MII&lt;/code&gt; -- the base64 DER clue that an RSA key follows. And AES! That’s good, right? CBC with ostensibly a random IV, even! No MAC, but without something like a padding oracle to try modified ciphertexts on, so that might be OK?&lt;/p&gt;
&lt;p&gt;It’s tricky to find out what this DEK-Info stuff means. Searching the openssh-portable repo for the string DEK-Info only shows sample keys. The punchline is that the AES key is just MD5(password || IV[:8]). That’s not good at all: password storage best practice holds that passwords are bad (low entropy) and in order to turn them into cryptographic key material you need an expensive function like Argon2. MD5 is very cheap to compute. The only thing this design has going for it is that the salt goes after the password, so you can’t just compute the intermediate state of MD5(IV[8:]) and try passwords from there. That’s faint praise, especially in a world where I can rent a machine that tries billions of MD5 calls per second. There just aren’t that many passwords.&lt;/p&gt;
&lt;p&gt;You might ask yourself how OpenSSH ended up with this. The sad answer is the OpenSSL command line tool had it as a default, and now we’re stuck with it.&lt;/p&gt;
&lt;p&gt;That’s a fair argument to say that standard password-encrypted keys are about as good as plaintext: the encryption is ineffective. But I made a stronger statement: it’s &lt;em&gt;worse&lt;/em&gt;. The argument there is simple: an SSH key password is unlikely to be managed by a password manager: instead it’s something you remember. If you remember it, you probably reused it somewhere. Perhaps it’s even your device password. This leaked key provides an oracle: if I guess the password correctly (and that’s feasible because the KDF is bad), I know I guessed correctly because I can check against your public key.&lt;/p&gt;
&lt;p&gt;There’s nothing wrong with the RSA key pair itself: it’s just the symmetric encryption of the private key. You can’t mount this attack from just a public key.&lt;/p&gt;
&lt;p&gt;How do you fix this? OpenSSH has a new key format that you should use. “New” means 2013. This format uses bcrypt_pbkdf, which is essentially bcrypt with fixed difficulty, operated in a PBKDF2 construction. Conveniently, you always get the new format when generating Ed25519 keys, because the old SSH key format doesn’t support newer key types. That’s a weird argument: you don’t really need your key format to define how Ed25519 serialization works since Ed25519 itself already defines how serialization works. But if that’s how we get good KDFs, that’s not the pedantic hill I want to die on. Hence, one answer is ssh-keygen -t ed25519. If, for compatibility reasons, you need to stick to RSA, you can use ssh-keygen -o. That will produce the new format, even for old key types. You can upgrade existing keys with ssh-keygen -p -o -f PRIVATEKEY. If your keys live on a Yubikey or a smart card, you don't have this problem either.&lt;/p&gt;
&lt;p&gt;We want to provide a better answer to this. On the one hand, aws-vault has shown the way by moving credentials off disk and into keychains. Another parallel approach is to move development into partitioned environments. Finally, most startups should consider not having long-held SSH keys, instead using temporary credentials issued by an SSH CA, ideally gated on SSO. Unfortunately this doesn't work for GitHub.&lt;/p&gt;
&lt;p&gt;PS: It’s hard to find an authoritative source, but from my memory: the versioned parameter in the PEM-like OpenSSH private key format only affect the encryption method. That doesn’t matter in the slightest: it’s the KDF that’s broken. That’s an argument against piecemeal negotiating parts of protocols, I’m sure. We’ll get you a blog post on that later.&lt;/p&gt;
&lt;p&gt;The full key is available here, just in case you feel like running john the ripper on something today: &lt;a href="https://gist.github.com/lvh/c532c8fd46115d2857f40a433a2416fd"&gt;gist.github.com/lvh/c532c...&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/the-default-openssh-key-encryption-is-worse-than-plaintext/</guid><pubDate>Sat, 04 Aug 2018 02:00:18 GMT</pubDate></item><item><title>Factoring the Noise protocol matrix</title><link>https://www.lvh.io/posts/factoring-the-noise-protocol-matrix/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;style&gt;
    .matrix {
        position: relative;
        margin: auto;
        margin-bottom: 2em;
    }
    .matrix:before, .matrix:after {
        content: "";
        position: absolute;
        top: 0;
        border: 3px solid #000;
        width: 20px;
        height: 100%;
    }
    .matrix:before {
        left: -10px;
        border-right: 0;
    }
    .matrix:after {
        right: -10px;
        border-left: 0;
    }
    .matrix td {
        vertical-align: middle;
        min-width: 100px;
        margin-bottom: 10px;
    }
    .matrix td p {
        vertical-align: middle;
        text-align: center;
        margin: auto;
    }
&lt;/style&gt;

&lt;p&gt;The Noise protocol is one of the best things to happen to encrypted protocol
design. &lt;a href="https://www.wireguard.com"&gt;WireGuard&lt;/a&gt; inherits its elegance from Noise.
Noise is a cryptography engineer's darling spec. It's important not to get
blindsided while fawning over it and to pay attention to where implementers run
into trouble. Someone raised a concern I had run into before: Noise has a
matrix.&lt;/p&gt;
&lt;table class="matrix" style="width:100%"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;N(rs):&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN:&lt;br&gt;  → e&lt;br&gt;  ← e, ee&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN:&lt;br&gt; → s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ...&lt;br&gt; → e&lt;br&gt; ← e, ee, se&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN:&lt;br&gt;  → e&lt;br&gt;  ← e, ee&lt;br&gt;  → s, se&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, s&lt;br&gt;  ← e, ee, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;K(s, rs):&lt;br&gt;  → s&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, ss&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK:&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;br&gt;  ← e, ee&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  …&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, es, ss&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← e, ee, se&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK:&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es&lt;br&gt;  ← e, ee&lt;br&gt;  → s, se&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, s, ss&lt;br&gt;  ← e, ee, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;X(s, rs):&lt;br&gt;  ← s&lt;br&gt;  ...&lt;br&gt;  → e, es, s, ss&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX:&lt;br&gt;  → e&lt;br&gt;  ← e, ee, s, es&lt;/span&gt;&lt;/p&gt;
                &lt;p&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX:&lt;br&gt;  → s&lt;br&gt;  ...&lt;br&gt;  → e&lt;br&gt;  ← e, ee, se, s, es&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX:&lt;br&gt;  → e&lt;br&gt;  ← e, ee, s, es&lt;br&gt;  → s, se&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt; IX:&lt;/span&gt;&lt;br&gt;&lt;span&gt;  → e, s&lt;/span&gt;&lt;br&gt;&lt;span&gt;  ← e, ee, se, s, es&lt;/span&gt;&lt;br&gt;&lt;span&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To a cryptography engineer, this matrix is beautiful. These eldritch runes
describe a grammar: the number of ways you can meaningfully compose the phrases
that can make up a Noise handshake into a proper protocol. The rest of the
document describes what the trade-offs between them are: whether the protocol is
one-way or interactive, whether you get resistance against key-compromise
impersonation, what sort of privacy guarantees you get, et cetera.
(Key-compromise impersonation means that if I steal your key, I can impersonate
anyone to you.)&lt;/p&gt;
&lt;p&gt;To the layperson implementer, the matrix is terrifying. They hadn't thought
about key-compromise impersonation or the distinction between known-key,
hidden-key and exposed-key protocols or even forward secrecy. They're going to
fall back to something else: something probably less secure but at least
unambiguous on what to do. As Noise matures into a repository for protocol
templates with wider requirements, this gets worse, not better. The most recent
revision of the Noise protocol adds 23 new "deferred" variants. It's unlikely
these will be the last additions.&lt;/p&gt;
&lt;p&gt;Which Noise variant should that layperson use? Depends on the application of
course, but we can make some reasonable assumptions for most apps. Ignoring
variants, we have:&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;N&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;K&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;X&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Firstly, let's assume you need bidirectional communication, meaning
initiator and responder can send messages to each other as opposed to
just initiator to responder. That gets rid of the first column of the
matrix.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IN&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The other protocols are defined by two letters. From the spec:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The first character refers to the initiator's static key:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N = No static key for initiator&lt;/li&gt;
&lt;li&gt;K = Static key for initiator Known to responder&lt;/li&gt;
&lt;li&gt;X = Static key for initiator Xmitted ("transmitted") to responder&lt;/li&gt;
&lt;li&gt;I = Static key for initiator Immediately transmitted to responder, despite reduced or absent identity hiding&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The second character refers to the responder's static key:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N = No static key for responder&lt;/li&gt;
&lt;li&gt;K = Static key for responder Known to initiator&lt;/li&gt;
&lt;li&gt;X = Static key for responder Xmitted ("transmitted") to initiator&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;NN provides confidentiality against a passive attacker but neither party
has any idea who you're talking to because no static (long-term) keys
are involved. For most applications none of the *N suites make a ton of
sense: they imply the initiator does not care who they're connecting to.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;NX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For most applications the client (initiator) ought to have a fixed
static key so we have a convenient cryptographic identity for clients
over time. So really, if you wanted something with an N in it, you'd
know.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;KX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The responder usually doesn't know what the key is for any initiator that
happens to show up. This mostly makes sense if you have one central initiator
that reaches out to a lot of responders: something like an MDM or sensor data
collection perhaps. In practice, you often end up doing egress from those
devices anyway for reasons that have nothing to do with Noise. So, K* is out.&lt;/p&gt;
&lt;table style="text-align: center" class="matrix"&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;N&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;XN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;IN&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;K&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KK&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IK&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;X&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;NX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;&lt;s&gt;KX&lt;/s&gt;&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;XX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td colspan="1" rowspan="1"&gt;
                &lt;p&gt;&lt;span&gt;IX&lt;/span&gt;&lt;/p&gt;
            &lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;These remaining suites generally trade privacy (how easily can you
identify participants) for latency (how many round trips are needed).&lt;/p&gt;
&lt;p&gt;IX doesn't provide privacy for the initiator at all, but that's the side you
usually care about. It still has the roundtrip downside, making it a niche
variant. XX and XK require an extra round trip before they send over the
initiator's static key. Flip side: they have the strongest possible
privacy protection for the initiator, whose identity is only sent to the
responder after they've been authenticated and forward secrecy has been
established.&lt;/p&gt;
&lt;p&gt;IK provides a reasonable tradeoff: no extra round trip and the
initiator's key is encrypted to the responder's static key. That means
that the initiator's key is only disclosed if the responder's key is
compromised. You probably don't care about that. It does require the
initiator to know the static key of the responder ahead of time but
that's probably true anyway: you want to check that key against a
trusted value. You can also try private keys for the responder offline
but that doesn't matter unless you gratuitously messed up key
generation. In conclusion, you probably want IK.&lt;/p&gt;
&lt;p&gt;This breakdown only works if you're writing a client-server application
that plausibly might've used mTLS instead. WireGuard, for example, is
built on Noise_IK. The other variants aren't pointless: they're just
good at different things. If you care more about protecting your
initiator's privacy than you do about handshake latency, you want
Noise_XK. If you're doing a peer-to-peer IoT system where device
privacy matters, you might end up with Noise_XX. (It's no accident
that IK, XK and XX are in the last set of protocols standing.)&lt;/p&gt;
&lt;h3&gt;Protocol variants&lt;/h3&gt;
&lt;p&gt;Ignore deferred variants for now. If you needed them you'd
know. PSK is an interesting quantum computer hedge. We'll talk more about
quantum key exchanges in a different post, but briefly: a shared PSK among
several participants protects against a passive adversary that records
everything and acquires a quantum computer some time in the future, while
retaining the convenient key distribution of public keys.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;It's incredible how much has happened in the last few years
to make protocols safer, between secure protocol templates like Noise,
new proof systems like Tamarin, and ubiquitous libraries of safer
primitives like libsodium. So far, the right answer for a safe transport
has almost always been TLS, perhaps mutually authenticated. That's not
going to change right away, but if you control both sides of the network
and you need properties hard to get out of TLS, Noise is definitely The
Right Answer. Just don't stare at the eldritch rune matrix too long. You
probably want Noise_IK. Or, you know, ask your security person :)&lt;/p&gt;
&lt;p&gt;Thanks to Katriel Cohn-Gordon for reviewing this blog post.&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/factoring-the-noise-protocol-matrix/</guid><pubDate>Wed, 18 Jul 2018 17:59:00 GMT</pubDate></item><item><title>Self-compressing pickles</title><link>https://www.lvh.io/posts/self-compressing-pickles/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;I’ve been working on some pickle security stuff. This is a teaser.&lt;/p&gt;
&lt;p&gt;Python pickles are extremely flexible: they can run essentially whatever code they want. That means you can create a pickle that contains a compressed pickle. The consumer doesn’t know if an incoming pickle will be compressed or not: the Pickle VM takes care of the details.&lt;/p&gt;
&lt;p&gt;To do this, we define a useful little helper class:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;PickleCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;object&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
     &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;args&lt;/span&gt;
     &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;__reduce__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
         &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;args&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;PickleCall is nothing but a convenience function for us to encode the function f being called with some args into a pickle. If you’ve used pickle before and you know that it normally encodes classes by name, you might expect that the &lt;s&gt;victi&lt;/s&gt;consumer of the pickle also needs to define PickleCall, but that’s not the case. This class accomplishes that by explicitly implementing part of the pickle protocol with the __reduce__ method: it tells pickle how to encode it, and PickleCall isn't involved anymore. Of course, the “obvious” thing to use PickleCall with is “os.system” and something involving /dev/tcp.&lt;/p&gt;
&lt;p&gt;Once you have PickleCall, writing the function that dumps an object to a string but with embedded zlib compression is straightforward:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;pickle&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dumps&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;zlib&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;compress&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;decompress&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;zdumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;zpickle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;compress&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;obj&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;level&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;9&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;unz_call&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PickleCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;decompress&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;zpickle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;loads_call&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;PickleCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;unz_call&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;loads_call&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;We can check that it works:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;zpickle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;zdumps&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="ss"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;pickle&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;dumps&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="ss"&gt;"a"&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zpickle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;True&lt;/span&gt;
&lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;zpickle&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;pickle&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="o"&gt;#&lt;/span&gt; &lt;span class="o"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;82&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;214&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Internally, the structure for this looks as follows:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;   &lt;span class="mi"&gt;0&lt;/span&gt;: \&lt;span class="nv"&gt;x80&lt;/span&gt; &lt;span class="nv"&gt;PROTO&lt;/span&gt;      &lt;span class="mi"&gt;3&lt;/span&gt;
   &lt;span class="mi"&gt;2&lt;/span&gt;: &lt;span class="nv"&gt;c&lt;/span&gt;    &lt;span class="nv"&gt;GLOBAL&lt;/span&gt;     &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="s"&gt;_pickle loads&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;
   &lt;span class="mi"&gt;17&lt;/span&gt;: &lt;span class="nv"&gt;c&lt;/span&gt;    &lt;span class="nv"&gt;GLOBAL&lt;/span&gt;     &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="s"&gt;zlib decompress&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;
   &lt;span class="mi"&gt;34&lt;/span&gt;: &lt;span class="nv"&gt;C&lt;/span&gt;    &lt;span class="nv"&gt;SHORT_BINBYTES&lt;/span&gt; &lt;span class="nv"&gt;b&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="s"&gt;x\xdak`\x8e-d\xd0\x88`d``H,d\xcc\x18\x160U\x0f\x00W\xb6+\xd4&lt;/span&gt;&lt;span class="s1"&gt;'&lt;/span&gt;     &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="nv"&gt;this&lt;/span&gt; &lt;span class="nv"&gt;is&lt;/span&gt; &lt;span class="nv"&gt;zlib&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="nv"&gt;compressed&lt;/span&gt; &lt;span class="nv"&gt;pickle&lt;/span&gt;
   &lt;span class="mi"&gt;63&lt;/span&gt;: \&lt;span class="nv"&gt;x85&lt;/span&gt; &lt;span class="nv"&gt;TUPLE1&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="nv"&gt;set&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;arguments&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;zlib&lt;/span&gt; &lt;span class="nv"&gt;decompress&lt;/span&gt;
   &lt;span class="mi"&gt;64&lt;/span&gt;: &lt;span class="nv"&gt;R&lt;/span&gt;    &lt;span class="nv"&gt;REDUCE&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="nl"&gt;zlib&lt;/span&gt; &lt;span class="nv"&gt;decompress&lt;/span&gt;
   &lt;span class="mi"&gt;65&lt;/span&gt;: \&lt;span class="nv"&gt;x85&lt;/span&gt; &lt;span class="nv"&gt;TUPLE1&lt;/span&gt;   &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="nv"&gt;set&lt;/span&gt; &lt;span class="nv"&gt;up&lt;/span&gt; &lt;span class="nv"&gt;arguments&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="nv"&gt;pickle&lt;/span&gt; &lt;span class="nv"&gt;load&lt;/span&gt;
   &lt;span class="mi"&gt;66&lt;/span&gt;: &lt;span class="nv"&gt;R&lt;/span&gt;    &lt;span class="nv"&gt;REDUCE&lt;/span&gt;    &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;  &lt;span class="k"&gt;call&lt;/span&gt; &lt;span class="nl"&gt;pickle&lt;/span&gt; &lt;span class="nv"&gt;load&lt;/span&gt;
   &lt;span class="mi"&gt;67&lt;/span&gt;: .    &lt;span class="nv"&gt;STOP&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;If you're trying to protect pickles the punchline here is that you probably need to whitelist because there are too many ways to hide things inside a pickle. (We're working on it.)&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>pickle</category><category>python</category><category>security</category><guid>https://www.lvh.io/posts/self-compressing-pickles/</guid><pubDate>Thu, 05 Jul 2018 14:59:00 GMT</pubDate></item><item><title>A child's garden of inter-service authentication schemes</title><link>https://www.lvh.io/posts/a-childs-garden-of-inter-service-authentication-schemes/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Modern applications tend to be composed from relationships between smaller applications. Secure modern applications thus need a way to express and enforce security policies that span multiple services. This is the “server-to-server” (S2S) authentication and authorization problem (for simplicity, I’ll mash both concepts into the term “auth” for most of this post).&lt;/p&gt;
&lt;p&gt;Designers today have a lot of options for S2S auth, but there isn’t much clarity about what the options are or why you’d select any of them. Bad decisions sometimes result. What follows is a stab at clearing the question up.&lt;/p&gt;
&lt;h3&gt;Cast Of Characters&lt;/h3&gt;
&lt;p&gt;Alice and Bob are services on a production VPC. Alice wants to make a request of Bob. How can we design a system that allows this to happen?&lt;/p&gt;
&lt;p&gt;Here’s, I think, a pretty comprehensive overview of available S2S schemes. I’ve done my best to describe the “what’s” and minimize the “why’s”, beyond just explaining the motivation for each scheme. Importantly, these are all things that reasonable teams use for S2S auth.&lt;/p&gt;
&lt;h4&gt;Nothing At All&lt;/h4&gt;
&lt;p&gt;Far and away the most popular S2S scheme is “no auth at all”. Internet users can’t reach internal services. There’s little perceived need to protect a service whose only clients are already trusted.&lt;/p&gt;
&lt;h4&gt;Bearer Token&lt;/h4&gt;
&lt;p&gt;Bearer tokens rule everything around us. Give Alice a small blob of data, such that when Bob sees that data presented, he assumes he’s talking to Alice. Cookies are bearer tokens. Most API keys are bearer tokens. OAuth is an elaborate scheme for generating and relaying bearer tokens. SAML assertions are delivered in bearer tokens.&lt;/p&gt;
&lt;p&gt;The canonical bearer token is a random string, generated from a secure RNG, that is at least 16 bytes long (that is: we generally consider 128 bits a reasonable common security denominator). But part of the point of a bearer token is that the holder doesn’t care what it is, so Alice’s bearer token could also encode data that Bob could recover. This is common in client-server designs and less common in S2S designs.&lt;/p&gt;
&lt;h5&gt;A few words about passwords&lt;/h5&gt;
&lt;p&gt;S2S passwords are disappointingly common. You see them in a lot of over-the-Internet APIs (ie, for S2S relationships that span companies). A password is basically a bearer token that you can memorize and quickly type. Computers are, in 2018, actually pretty good at memorizing and typing, and so you should use real secrets, rather than passwords, in S2S applications.&lt;/p&gt;
&lt;h4&gt;HMAC(timestamp)&lt;/h4&gt;
&lt;p&gt;The problem with bearer tokens is that anybody who has them can use them. And they’re routinely transmitted. They could get captured off the wire, or logged by a proxy. This keeps smart ops people up at night, and motivates a lot of “innovation”.&lt;/p&gt;
&lt;p&gt;You can keep the simplicity of bearer tokens while avoiding the capture-in-flight problem by exchanging the tokens with secrets, and using the secrets to authenticate a timestamp. A valid HMAC proves ownership of the shared secret without revealing it. You’d then proceed as with bearer tokens.&lt;/p&gt;
&lt;h5&gt;A few words about TOTP&lt;/h5&gt;
&lt;p&gt;TOTP is basically HMAC(timestamp) stripped down to make it easy for humans to briefly memorize and type. As with passwords, you shouldn’t see TOTP in S2S applications.&lt;/p&gt;
&lt;h5&gt;A few words about PAKEs&lt;/h5&gt;
&lt;p&gt;PAKEs are a sort of inexplicably popular cryptographic construction for securely proving knowledge of a password and, from that proof, deriving an ephemeral shared secret. SRP is a PAKE. People go out of their way to find applications for PAKEs. The thing to understand about them is that they’re fundamentally a way to extract cryptographic strength from passwords. Since this isn’t a problem computers have, PAKEs don’t make sense for S2S auth.&lt;/p&gt;
&lt;h4&gt;Encrypted Tokens&lt;/h4&gt;
&lt;p&gt;HMAC(timestamp) is stateful; it works because there’s pairwise knowledge of secrets and the metadata associated with them.  Usually, this is fine. But sometimes it’s hard to get all the parties to share metadata.&lt;/p&gt;
&lt;p&gt;Instead of making that metadata implicit to the protocol, you can store it directly in the credential: include it alongside the timestamp and HMAC or encrypt it. This is how Rails cookie storage works; it’s also the dominant use case for JWTs. AWS-style request “signing” is another example (using HMAC and forgoing encryption).&lt;/p&gt;
&lt;p&gt;By themselves, encrypted tokens make more sense in client-server settings than they do for S2S. Unlike client-server, where a server can just use the same secret for all the clients, S2S tokens still require some kind of pairwise state-keeping.&lt;/p&gt;
&lt;h4&gt;Macaroons&lt;/h4&gt;
&lt;p&gt;You can’t easily design a system where Alice takes her encrypted token, reduces its security scope (for instance, from read-write to read-only), and then passes it to Dave to use on her behalf. No matter how “sophisticated” we make the encoding and transmission mechanisms, encrypted tokens still basically express bearer logic.&lt;/p&gt;
&lt;p&gt;Macaroons are an interesting (and criminally underused) construction that directly provides both &lt;em&gt;delegation&lt;/em&gt; and &lt;em&gt;attenuation&lt;/em&gt;. They’re a kind of token from which you can derive more restricted tokens (that’s the “attenuation”), and, if you want, pass that token to someone else to use without them being able to exceed the authorization you gave them. Macaroons accomplish this by chaining HMAC; the HMAC of a macaroon is the HMAC secret for its derived attenuated macaroons.&lt;/p&gt;
&lt;p&gt;By adding encryption along with HMAC, Macaroons also express “third-party” conditions. Alice can get Charles to attest that Alice is a member of the super-awesome-best-friends-club, and include that in the Macaroon she delivers to Bob. If Bob also trusts Charles, Bob can safely learn whether Alice is in the club. Macaroons can flexibly express whole trees of these kinds of relationships, capturing identity, revocation, and… actually, revocation and identity are the only two big wins I can think of for this feature.&lt;/p&gt;
&lt;h4&gt;Asymmetric Tokens&lt;/h4&gt;
&lt;p&gt;You can swap the symmetric constructions used in tokens for asymmetric tokens and get some additional properties.&lt;/p&gt;
&lt;p&gt;Using signatures instead of HMACs, you get non-repudiability: Bob can verify Alice’s token, but can’t necessarily mint a new Alice token himself.&lt;/p&gt;
&lt;p&gt;More importantly, you can eliminate pairwise configuration. Bob and Alice can trust Charles, who doesn’t even need to be online all the time, and from that trust derive mutual authentication.&lt;/p&gt;
&lt;p&gt;The trade-offs for these capabilities are speed and complexity. Asymmetric cryptography is much slower and much more error-prone than symmetric cryptography.&lt;/p&gt;
&lt;h4&gt;Mutual TLS&lt;/h4&gt;
&lt;p&gt;Rather than designing a new asymmetric token format, every service can have a certificate. When Alice connects to Bob, Bob can check a whitelist of valid certificate fingerprints, and whether Alice’s name on her client certificate is allowed. Or, you could set up a simple CA, and Bob could trust any certificate signed by the CA. Things can get more complex; you might take advantage of X.509 and directly encode claims in certs (beyond just names).&lt;/p&gt;
&lt;h5&gt;A few words about SPIFFE&lt;/h5&gt;
&lt;p&gt;If you’re a Kubernetes person this scheme is also sometimes called SPIFFE.&lt;/p&gt;
&lt;h5&gt;A few words about Tokbind&lt;/h5&gt;
&lt;p&gt;If you’re a participant in the IETF TLS Working Group, you can combine bearer tokens and MTLS using tokbind. Think of tokbind as a sort of “TLS cookie”. It’s derived from the client and server certificate and survives multiple TLS connections. You can use a tokbind secret to sign a bearer token, resulting in a bearer token that is confined to a particular MTLS relationship that can’t be used in any other context.&lt;/p&gt;
&lt;h4&gt;Magic Headers&lt;/h4&gt;
&lt;p&gt;Instead of building an explicit application-layer S2S scheme, you can punt the problem to your infrastructure. Ensure all requests are routed through one or more trusted, stateful proxies. Have the proxies set headers on the forwarded requests. Have the services trust the headers.&lt;/p&gt;
&lt;p&gt;This accomplishes the same things a complicated Mutual TLS scheme does without requiring slow, error-prone public-key encryption. The trade-off is that your policy is directly coupled to your network infrastructure.&lt;/p&gt;
&lt;h4&gt;Kerberos&lt;/h4&gt;
&lt;p&gt;You can try to get the benefits of magic headers and encrypted tokens at the same time using something like Kerberos, where there’s a magic server trusted by all parties, but bound by cryptography rather than network configuration. Services need to be introduced to the Kerberos server, but not to each other; mutual trust of the Kerberos server, and authorization logic that lives on that Kerberos server, resolves all auth questions. Notably, no asymmetric cryptography is needed to make this work.&lt;/p&gt;
&lt;h3&gt;Themes&lt;/h3&gt;
&lt;p&gt;What are the things we might want to achieve from an S2S scheme? Here’s a list. It’s incomplete. Understand that it’s probably not reasonable to expect &lt;em&gt;all of these things&lt;/em&gt; from a single scheme.&lt;/p&gt;
&lt;h4&gt;Minimalism&lt;/h4&gt;
&lt;p&gt;This goal is less obvious than it seems. People adopt complicated auth schemes without clear rationales. It’s easy to lose security by doing this; every feature you add to an application  especially security features  adds attack surface. From an application security perspective, “do the simplest thing you can get away with” has a lot of merit. If you understand and keep careful track of your threat model, “nothing at all” can be a security-maximizing option. Certainly, minimalism motivates a lot of bearer token deployments.&lt;/p&gt;
&lt;p&gt;The opposite of minimalism is complexity. A reasonable way to think about the tradeoffs in S2S design is to think of complexity as a currency you have to spend. If you introduce new complexity, what are you getting for it?&lt;/p&gt;
&lt;h4&gt;Claims&lt;/h4&gt;
&lt;p&gt;Authentication and authorization are two different things: who are you, and what are you allowed to do? Of the two problems, authorization is the harder one. An auth scheme can handle authorization, or assist authorization, or punt on it altogether.&lt;/p&gt;
&lt;p&gt;Opaque bearer token schemes usually just convey identity. An encrypted token, on the other hand, might bind &lt;em&gt;claims&lt;/em&gt;: statements that limit the scope of what the token enables, or metadata about the identity of the requestor.&lt;/p&gt;
&lt;p&gt;Schemes that don’t bind claims can make sense if authorization logic between services is straightforward, or if there’s already a trusted system (for instance, a service discovery layer) that expresses authorization. Schemes that do bind claims can be problematic if the claims carried in an credential can be abused, or targeted by application flaws. On the other hand, an S2S scheme that supports claims can do useful things like propagating on-behalf-of requestor identities or supporting distributed tracing.&lt;/p&gt;
&lt;h4&gt;Confinement&lt;/h4&gt;
&lt;p&gt;The big problem with HTTP cookies is that once they’ve captured one, an attacker can abuse it however they see fit. You can do better than that by adding mitigations or caveats to credentials. They might be valid only for a short period of time, or valid only for a specific IP address (especially powerful when combined with short expiry),  or, as in the case of Tokbind, valid only on a particular MTLS relationship.&lt;/p&gt;
&lt;h4&gt;Statelessness&lt;/h4&gt;
&lt;p&gt;Statelessness means Bob doesn’t have to remember much (or, ideally, anything) about Alice. This is an immensely popular motivator for some S2S schemes. It’s perceived as eliminating a potential performance bottleneck, and as simplifying deployment.&lt;/p&gt;
&lt;p&gt;The tricky thing about statelessness is that it often doesn’t make sense to minimize state, only to eliminate it. If pairwise statefulness creeps back into the application for some other reason (for instance, Bob has to remember anything at all about Alice), stateless S2S auth can spend a lot of complexity for no real gain.&lt;/p&gt;
&lt;h4&gt;Pairwise Configuration&lt;/h4&gt;
&lt;p&gt;Pairwise configuration is the bête noire of S2S operational requirements. An application secret that has to be generated once for each of several peers and that &lt;em&gt;anybody might ever store in code&lt;/em&gt; is part of a scheme in which secrets are never, ever rotated. In a relatively common set of circumstances, pairwise config means that new services can only be introduced during maintenance windows.&lt;/p&gt;
&lt;p&gt;Still, if you have a relatively small and stable set of services (or if all instances of a particular service might simply share a credential), it can make sense to move complexity out of the application design and into the operational requirements.  Also it makes sense if you have an ops team and you never have to drink with them.&lt;/p&gt;
&lt;p&gt;I kid, really, because if you can get away with it, not spending complexity to eliminate pairwise configuration can make sense. Also, many of the ways S2S schemes manage to eliminate pairwise configurations involve &lt;em&gt;introducing yet another service&lt;/em&gt;, which has a sort of constant factor cost that can swamp the variable cost.&lt;/p&gt;
&lt;h4&gt;Delegation and Attenuation&lt;/h4&gt;
&lt;p&gt;People deploy a lot of pointless delegation. Application providers might use OAuth for their client-server login, for instance, even though no third-party applications exist.  The flip side of this is that if you actually need delegation, you really want to have it expressed carefully in your protocol. The thing you don’t want to do is ever share a bearer token.&lt;/p&gt;
&lt;p&gt;Delegation can show up in internal S2S designs as a building block. For instance, a Macaroon design might have a central identity issuance server that grants all-powerful tokens to systems that in turn filter them for specific requestors.&lt;/p&gt;
&lt;p&gt;Some delegation schemes have implied or out-of-band attenuation. For instance, you might not be able to look at an OAuth token and know what it’s restrictions are. These systems are rough in practice; from an operational security perspective, your starting point probably needs to be that any lost token is game-over for its owner.&lt;/p&gt;
&lt;p&gt;A problem with writing about attenuation is that Macaroons express it so well that it’s hard to write about its value without lapsing into the case for Macaroons.&lt;/p&gt;
&lt;h4&gt;Flexibility&lt;/h4&gt;
&lt;p&gt;If use JSON as your credential format, and you later build a feature that allows a credential to express not just Alice’s name but also whether she’s an admin, you can add that feature without changing the credential format. Later, attackers can add the feature where they turn any user into an admin, and you can then add the feature that breaks that attack. JSON is just features all the way down.&lt;/p&gt;
&lt;p&gt;I’m only mostly serious. If you’re doing something more complicated than a bearer token, you’re going to choose an extensible mechanism. If not, I already made the case for minimalism.&lt;/p&gt;
&lt;h4&gt;Coupling&lt;/h4&gt;
&lt;p&gt;All things being equal, coupling is bad. If your S2S scheme is expressed by network controls and unprotected headers, it’s tightly coupled to the network deployment, which can’t change without updating the security scheme. But if your network configuration doesn’t change often, that limitation might save you a lot of complexity.&lt;/p&gt;
&lt;h4&gt;Revocation&lt;/h4&gt;
&lt;p&gt;People talk about this problem a lot. Stateless schemes have revocation problems: the whole point of a stateless scheme is for Bob not to have to remember anything about Alice (other than perhaps some configuration that says Alice is allowed to make requests, but not Dave, and this gets complicated really quickly and can quickly call into question the value of statelessness but let’s not go there). At any rate: a stateless bearer token will eventually be compromised, and you can’t just let it get used over and over again to steal data.&lt;/p&gt;
&lt;p&gt;The two mainstream answers to this problem are short expiry and revocation lists.&lt;/p&gt;
&lt;p&gt;Short expiry addresses revocation if: (a) you have a dedicated auth server and the channel to that server is somehow more secure than the channel between Alice and Bob.; (b) the auth server relies on a long-lived secret that never appears on the less-secure channel, and (c) issues an access secret that is transmitted on the less-secure channel, but lives only for a few minutes. These schemes are called “refresh tokens”. Refresh tends to find its way into a lot of designs where this fact pattern doesn’t hold. Security design is full of wooden headphones and coconut phones.&lt;/p&gt;
&lt;p&gt;Revocation lists (and, usually, some attendant revocation service) are a sort of all-purpose solution to this problem; you just blacklist revoked tokens, for at least as long as the lifetime of the token. This obviously introduces state, but it’s a specific kind of state that doesn’t (you hope) grow as quickly as your service does. If it’s the only state you have to keep, it’s nice to have the flexibility of putting it wherever you want.&lt;/p&gt;
&lt;h4&gt;Rigidity&lt;/h4&gt;
&lt;p&gt;It is hard to screw up a random bearer token. Alice stores the token and supply it on requests. Bob uses the token to look up an entry in a database. There aren’t a lot of questions.&lt;/p&gt;
&lt;p&gt;It is extraordinarily easy to screw up JWT. JWT is a JSON format where you have to parse and interpret a JSON document to figure out how to decrypt and authenticate a JSON document. It has revived bugs we thought long dead, like “repurposing asymmetric public keys as symmetric private keys”.&lt;/p&gt;
&lt;p&gt;Problems with rigidity creep up a lot in distributed security. The first draft of this post said that MTLS was rigid; you’re either speaking TLS with a client cert or you’re not. But that ignores how hard X.509 validation is. If you’re not careful, an attacker can just ask Comodo for a free email certificate and use it to access your services. Worse still, MTLS can “fail open” in a way that TLS sort of doesn’t: if a service forgets to check for client certificates, TLS will still get negotiated, and you might not notice until an attacker does.&lt;/p&gt;
&lt;p&gt;Long story short: bearer tokens are rigid. JWT is a kind of evil pudding. Don’t use JWT.&lt;/p&gt;
&lt;h4&gt;Universality&lt;/h4&gt;
&lt;p&gt;A nice attribute of widely deployed MTLS is that it can mitigate SSRF bugs (the very bad bug where an attacker coerces one of your service to make an arbitrary HTTP request, probably targeting your internal services, on their behalf). If the normal HTTP-request-generating code doesn’t add a client certificate, and every internal service needs to see one to honor a request, you’ve limited the SSRF attackers options a lot.&lt;/p&gt;
&lt;p&gt;On the other hand, we forget that a lot of our internal services consist of code that we didn’t write. The best example of this is Redis, which for years proudly waved the banner of “if you can talk to it, you already own the whole application”.&lt;/p&gt;
&lt;p&gt;It’s helpful if we can reasonably expect an auth control to span all the systems we use, from Postgres to our custom revocation server. That might be a realistic goal with Kerberos, or with network controls and magic headers; with tunnels or proxies, it’s even something you can do with MTLS  this is a reason MTLS is such a big deal for Kubernetes, where it’s reasonable for the infrastructure to provide every container with an MTLS-enabled Envoy proxy.  On the other hand it’s unlikely to be something you can achieve with Macaroons or evil puddings.&lt;/p&gt;
&lt;h4&gt;Performance and Complexity&lt;/h4&gt;
&lt;p&gt;If you want performance and simplicity, you probably avoid asymmetric crypto, unless your request frequency is (and will remain) quite low. Similarly, you’d probably want to avoid dedicated auth servers, especially if Bob needs to be in constant contact with them for Alice to make requests to him; this is a reason people tend to migrate away from Kerberos.&lt;/p&gt;
&lt;h3&gt;Our Thoughts&lt;/h3&gt;
&lt;p&gt;Do the simplest thing that makes sense for your application right now. A true fact we can relate from something like a decade of consulting work on these problems: intricate S2S auth schemes are not the norm; if there’s a norm, it’s “nothing at all except for ELBs”.  If you need something, but you have to ask whether that something oughtn’t just be bearer tokens, then just use bearer tokens.&lt;/p&gt;
&lt;p&gt;Unfortunately, if there’s a second norm, it’s adopting complicated auth mechanisms independently or, worse, in combination, and then succumbing to vulnerabilities.&lt;/p&gt;
&lt;p&gt;Macaroons are inexplicably underused. They’re the Velvet Underground of authentication mechanisms, hugely influential but with little radio airplay. Unlike the Velvets, Macaroons aren’t overrated. They work well for client-server auth and for s2s auth. They’re very flexible but have reassuring format rigidity, and they elegantly take advantage of just a couple simple crypto operations. There are libraries for all the mainstream languages. You will have a hard time coming up with a scenario where we’d try to talk you out of using them.&lt;/p&gt;
&lt;p&gt;JWT is a standard that tries to do too much and ends up doing everything haphazardly.  Our loathing of JWT motivated this post, but this post isn’t about JWT; we’ll write more about it in the future.&lt;/p&gt;
&lt;p&gt;If your inter-service auth problem really decomposes to inter-container (or, without containers, inter-instance) auth, MTLS starts to make sense. The container-container MTLS story usually involves containers including a proxy, like Envoy, that mediates access. If you’re not connecting containers, or have ad-hoc components, MTLS can really start to take on a CORBA feel: random sidecar processes (here stunnel, there Envoy, and this one app that tries to do everything itself). It can be a pain to configure properly, and this is a place you need to get configurations right.&lt;/p&gt;
&lt;p&gt;If you can do MTLS in such a way that there is exactly one way all your applications use it (probably: a single proxy that all your applications install), consider MTLS. Otherwise, be cautious about it.&lt;/p&gt;
&lt;p&gt;Beyond that, we don’t want to be too much more prescriptive. Rather, we’d just urge you to think about what you’re actually getting from an S2S auth scheme before adopting it.&lt;/p&gt;
&lt;p&gt;(But really, you should just use Macaroons.)&lt;/p&gt;
&lt;p&gt;(This post was syndicated on the Latacora blog.)&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/a-childs-garden-of-inter-service-authentication-schemes/</guid><pubDate>Tue, 12 Jun 2018 22:27:00 GMT</pubDate></item><item><title>Gripes with Google Groups</title><link>https://www.lvh.io/posts/gripes-with-google-groups/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;If you’re like me, you think of Google Groups as the Usenet client turned
mailing list manager. If you’re a GCP user or maybe one of a handful of SAML
users you probably know Google Groups as an access control mechanism. The bad
news is we’re both right.&lt;/p&gt;
&lt;p&gt;This can blow up if permissions on those groups aren't set right. Your groups
were probably originally created by a sleep-deprived founder way before anyone
was worried about access control. It's been lovingly handcrafted and never
audited ever since. Let’s say their configuration is, uh, “inconsistent”. If an
administrator adds people to the right groups as part of their on-boarding, it’s
not obvious when group membership is secretly self-service. Even if someone
can't &lt;em&gt;join&lt;/em&gt; a group, they might still be able to read it.&lt;/p&gt;
&lt;p&gt;You don’t even need something using group membership as access control for this
to go south. The simplest way is a password reset email. (Having a list of all
of your vendors feels like a dorky compliance requirement, but it's underrated.
Being able to audit which ones have multi-factor authentication is awesome.)&lt;/p&gt;
&lt;p&gt;Some example scenarios:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scenario 1&lt;/em&gt; You get your first few customers and start seeing fraud. You create
a mailing list with the few folks who want to talk about that topic. Nobody
imagined that dinky mailing list would grow out to a full-fledged team, let alone
one with permissions to a third party analytics suite that has access to all
your raw data.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scenario 2&lt;/em&gt; Engineering team treats their mailing list as open access for the
entire company. Ops deals with ongoing incidents candidly and has had bad
experiences with nosy managers looking for scapegoats. That’s great until
someone in ops extends an access control check in some custom software
that gates on ops@ to also include engineering@.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Scenario 3&lt;/em&gt; board@ gets a new investor who insists on using their existing
email address. An administrator confuses the Google Groups setting for allowing out-of-domain
addresses with allowing out-of-domain registration. Everyone on the Internet can
read the cap table for your next funding round.&lt;/p&gt;
&lt;p&gt;This is a mess. It bites teams that otherwise have their ducks in a row.
Cleaning it up gets way worse down the line. Get in front of it now and you
probably won’t have to worry about it until someone makes you audit it, which is
probably 2-3 years from now.&lt;/p&gt;
&lt;p&gt;Google Groups has some default configurations for new groups these days:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Public (Anyone in ${DOMAIN} can join, post messages, view the members list,
  and read the archives.)&lt;/li&gt;
&lt;li&gt;Team (Only managers can invite new members, but anyone in ${DOMAIN} can
  post messages, view the members list, and read the archives.)&lt;/li&gt;
&lt;li&gt;Announcement-only (Only managers can post messages and view the members list,
  but anyone in ${DOMAIN} can join and read the archives.)&lt;/li&gt;
&lt;li&gt;Restricted (Only managers can invite new members. Only members can post
  messages, view the members list, and read the archives. Messages to the group
  do not appear in search results.)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is good but doesn't mean you're out of the woods:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;These are just defaults for access control settings. Once a group is created,
  you get to deal with the combinatorial explosion of options. Most of them
  don't really make sense. You probably don't know when someone messes with the
  group, though.&lt;/li&gt;
&lt;li&gt;People rarely document intent in the group description (or anywhere for that
  matter). When a group deviates, you have no idea if it was supposed to.&lt;/li&gt;
&lt;li&gt;"Team" lets anyone in the domain read. That doesn't cover "nosy manager" or
  "password  reset" scenarios.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Auditing this is kind of a pain. The UI is slow and relevant controls are
spread across multiple pages. Even smallish companies end up with dozens of
groups. The only way we've found to make this not suck is by using the GSuite
Admin SDK and that's a liberal definition of "not suck".&lt;/p&gt;
&lt;p&gt;You should have a few archetypes of groups. Put the name in the group itself,
because that way the expected audience and access control is obvious to users
and auditors alike. Here are some archetypes we've found:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Team mailing lists, should be called xyzzy-team@${DOMAIN}. Only has team
  members, no external members, no self-service membership.&lt;/li&gt;
&lt;li&gt;Internal-facing mailing lists, should be called xyzzy-corp@${DOMAIN}. Public
  self-serve access for employees, no external members, limit posting to domain
  members or mailing list members. These are often associated with a team, but
  unlike -team mailing lists anyone can join them.&lt;/li&gt;
&lt;li&gt;External-facing lists. Example: contracts-inbound@${DOMAIN}. No self-serve
  access, no external members, but anyone can post.&lt;/li&gt;
&lt;li&gt;External member lists (e.g. boards, investors): board-ext@${DOMAIN}. No
  self-serve access, external members allowed, members and either members or
  anyone at the domain can post.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PS: Groups can let some users post as the group. I haven't ran a phishing
exercise that way, but I'm guessing an email appearing to legitimately come from
board@company.com is going to be pretty effective.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/gripes-with-google-groups/</guid><pubDate>Tue, 29 May 2018 23:14:00 GMT</pubDate></item><item><title>Nonce misuse resistance 101</title><link>https://www.lvh.io/posts/nonce-misuse-resistance-101/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;&lt;em&gt;This post is an introduction to nonce-misused resistant cryptosystems and why
I think they matter. The first part of this post is about nonce-based
authenticated encryption schemes: how they work, and how they fail. If you're
already familiar with them, you can skip to the section on
&lt;a href="https://www.lvh.io/posts/nonce-misuse-resistance-101/#proto"&gt;protocol design&lt;/a&gt;. If you're completely new to cryptography, you might
like my free introductory course to cryptography, &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;. In a
future blog post, I'll talk about some nonce-misuse resistant schemes I've
implemented using libsodium.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Many stream ciphers and stream cipher-like constructions such as CTR,
GCM, (X)Salsa20... take a nonce. You can think of it as a pointer that lets
you jump to a particular point in the keystream. This makes these ciphers
"seekable", meaning that you can decrypt a small part of a big ciphertext,
instead of having to decrypt everything up to that point first. (That ends up
being trickier than it seems, because you still want to authenticate that
small chunk of ciphertext, but that's a topic for another time.)&lt;/p&gt;
&lt;p&gt;The critical security property of a nonce is that it's never repeated under
the same key. You can remember this by the mnemonic that a &lt;em&gt;nonce&lt;/em&gt; is a
"number used once". If you were to repeat the nonce, the keystream would also
repeat. That means that an attacker can take the two ciphertexts and XOR them
to compute the XOR of the plaintexts. If &lt;code&gt;C_n&lt;/code&gt; are ciphertexts, &lt;code&gt;P_n&lt;/code&gt;
plaintexts, &lt;code&gt;K_n&lt;/code&gt; keystreams, and &lt;code&gt;^&lt;/code&gt; is bitwise exclusive or:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt;
&lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_2&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The attacker just XORs &lt;code&gt;C_1&lt;/code&gt; and &lt;code&gt;C_2&lt;/code&gt; together:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;K_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;K_2&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;Since XOR is commutative (you can rearrange the order), &lt;code&gt;K_1 = K_2&lt;/code&gt;, and
XOR'ing two equal values cancels them out:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;C_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;C_2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;P_1&lt;/span&gt; &lt;span class="o"&gt;^&lt;/span&gt; &lt;span class="n"&gt;P_2&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;That tells an attacker a lot about the plaintext, especially if some of one of
the plaintexts is predictable. If the attacker has access to an encryption
oracle, meaning that they can get encryptions for plaintexts of their
choosing, they can even get perfect decryptions. That is not an unrealistic
scenario. For example, if you're encrypting session cookies that contain the
user name and e-mail, I can register using a name and e-mail address that has
a lot of &lt;code&gt;Z&lt;/code&gt; characters, and then I know that just XORing with &lt;code&gt;Z&lt;/code&gt; will reveal
most of the plaintext. For an idea of the state of the art in attacking
two-time pads (the usual term for two ciphertexts with a reused keystream),
see &lt;a href="https://www.cs.jhu.edu/~jason/papers/mason+al.ccs06.pdf"&gt;Mason06&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a id="proto"&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Protocol design&lt;/h3&gt;
&lt;p&gt;For many on-line protocols like TLS, the explicit nonce provides a convenient
way to securely send many messages under a per-session key. Because the
critical security property for a nonce is that it is never repeated with the
same key, it's safe to use a counter. In protocols where both peers send
messages to each other, you can just have one peer use odd nonces and have the
other use even ones. There are some caveats here: for example, if the nonce
size is sufficiently small, an attacker might try to make that counter
overflow, resulting in a repeated nonce.&lt;/p&gt;
&lt;p&gt;For off-line (or at-rest) protocols, it's a little trickier. You don't have a
live communication channel to negotiate a new ephemeral key over, so you're
stuck with longer-term keys or keys derived from them. If multiple systems are
participating, you need to decide ahead of time which systems own which
nonces. Even then, systems need to keep track of which nonces they've
used. That doesn't work well, especially not in a distributed system where
nodes and connections can fail at any time. This is why some cryptosystems
like &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt; provide an API that doesn't require you to specify
anything besides a key and a message.&lt;/p&gt;
&lt;p&gt;One solution is to use randomized nonces. Since nonces can't repeat, random
nonces should be large: if they're too small, you might randomly select the
same nonce twice, per the birthday bound. That is the only difference between
Salsa20 and XSalsa20: Salsa20 has a 64 bit nonce, whereas XSalsa20 has a 192
bit nonce. That change exists explicitly to make random nonces secure.&lt;/p&gt;
&lt;p&gt;Picking a random nonce and just prepending it to the secretbox ciphertext is
secure, but there are a few problems with this approach. It's not clear to
practitioners that that's a secure construct. Doing this may seem obvious to a
cryptographer, but not to someone who just wants to encrypt a
message. Prepending a nonce doesn't feel much different from e.g. appending a
MAC. A somewhat knowledgeable practitioner knows that there's plenty of ways
to use MACs that are insecure, and they don't immediately see that the
prefix-nonce construction is secure. Not wanting to design your own
cryptosystems is a good reflex which we should be encouraging.&lt;/p&gt;
&lt;p&gt;Random nonces also mean that any system sending messages needs access to
high-quality random number generators while they're sending a message. That's
often, but not always true. Bugs around random number generation, especially
userspace CSPRNGs, &lt;a href="http://sockpuppet.org/blog/2014/02/25/safely-generate-random-numbers/"&gt;keep popping up&lt;/a&gt;. This is often a consequence of
poor programming practice, but it can also be a consequence of
poorly-configured VMs or limitations of embedded hardware.&lt;/p&gt;
&lt;h3&gt;Nonce-misuse resistant systems&lt;/h3&gt;
&lt;p&gt;To recap, not all protocols have the luxury of an obvious nonce choice, and
through circumstances or poor practices, nonces might repeat
anyway. Regardless of how cryptographers feel about how important nonce misuse
is, we can anecdotally and empirically verify that such issues are real and
common. This is true even for systems like TLS where there is an "obvious"
nonce available (&lt;a href="https://eprint.iacr.org/2016/475.pdf"&gt;Böck et al, 2016&lt;/a&gt;). It's easy to point fingers, but
it's better to produce cryptosystems that fail gracefully.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://web.cs.ucdavis.edu/~rogaway/papers/keywrap.pdf"&gt;Rogaway and Shrimpton (2006)&lt;/a&gt; defined a new model called nonce-misuse
resistance. Informally, nonce-misuse resistance schemes ensure that a repeated
random nonce doesn't result in plaintext compromise. In the case of a broken
system where the attacker can cause repeated nonces, an attacker will only be
able to discern if a particular message repeated, but they will not be able
to decrypt the message.&lt;/p&gt;
&lt;p&gt;Rogaway and Shrimpton also later developed a mode of operation called SIV
(synthetic IV), which Gueron and Lindell are refined to GCM-SIV, a SIV-like
that takes advantage of fast GCM hardware implementations. Those two authors
are currently working with Adam Langley to standardize the AES-GCM-SIV
construction through CFRG. AEZ and HS1-SIV, two entries in the CAESAR
competition, also feature nonce-misuse resistance. CAESAR is an ongoing
competition, and GCM-SIV is not officially finished yet, so this is clearly
a field that is still evolving.&lt;/p&gt;
&lt;p&gt;There are parallels between nonce-misuse resistance and length extension
attacks. Both address issues that arguably only affected systems that were
doing it wrong to begin with. (Note, however, in the embedded case above, it
might not be a software design flaw but a hardware limitation.) Fortunately,
the SHA-3 competition showed that you can have increased performance and
still be immune to a class of problems. I'm hopeful that CAESAR will consider
nonce-misuse resistance an important property of an authenticated encryption
standard.&lt;/p&gt;
&lt;h3&gt;Repeated messages&lt;/h3&gt;
&lt;p&gt;Repeated messages are suboptimal, and in some protocols they might be
unacceptable. However, they're a fail-safe failure mode for nonce
misuse. You're not choosing to have a repeated ciphertext, you're just getting
a repeated ciphertext instead of a plaintext disclosure (where the attacker
would also know that you repeated a message). In the case of a secure random
nonce, a nonce-misuse resistant scheme is just as secure, at the cost of a
performance hit.&lt;/p&gt;
&lt;p&gt;In a context where attackers can see individual messages to detect repeated
ciphertexts, it makes sense to also consider a model where attackers can
replay messages. If replaying messages (which presumably have side effects) is
a problem, a common approach is to add a validity timestamp. This is a feature
of &lt;a href="https://cryptography.io/en/latest/fernet/"&gt;Fernet&lt;/a&gt;, for example. A device that doesn't have access to
sufficient entropy will still typically have access to a reasonably
high-resolution clock, which is still more than good enough to make sure the
synthetic IVs don't repeat either.&lt;/p&gt;
&lt;h3&gt;OK, but how does it work?&lt;/h3&gt;
&lt;p&gt;Being able to trade plaintext disclosure for attackers being able to detect
repeated messages sounds like magic, but it makes sense once you realize how
they work. As demonstrated in the start of this post, nonce re-use normally
allows an attacker to have two keystreams cancel out. That only makes sense if
two &lt;em&gt;distinct&lt;/em&gt; messages are encrypted using the same (key, nonce) pair. NMR
solves this by making the nonce also depend on the message itself. Informally,
it means that a nonce should never repeat for two distinct
messages. Therefore, an attacker can't cancel out the keystreams without
cancelling out the messages themselves as well.&lt;/p&gt;
&lt;p&gt;This model does imply off-line operation, in that the entire message has to be
scanned before the nonce can be computed. For some protocols, that may not be
acceptable, although plenty of protocols work around this assumption by simply
making individual messages sufficiently small.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Thanks to Aaron Zauner and Kurt Griffiths for proofreading this post.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/nonce-misuse-resistance-101/</guid><pubDate>Thu, 19 May 2016 19:25:44 GMT</pubDate></item><item><title>Supersingular isogeny Diffie-Hellman 101</title><link>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;Craig Costello, Patrick Longa and Michael Naehrig, three cryptographers at
Microsoft Research, recently published a &lt;a href="https://eprint.iacr.org/2016/413"&gt;paper&lt;/a&gt; on supersingular
isogeny Diffie-Hellman. This paper garnered a lot of interest in the security
community and even made it to the front page of Hacker News. Most of the
discussion around it seemed to be how no one understands isogenies, even
within cryptography-literate communities. This article aims to give you a
high-level understanding of what this cryptosystem is and why it works.&lt;/p&gt;
&lt;p&gt;This post assumes that you already know how Diffie-Hellman works in the
abstract, and that you know elliptic curves are a mathematical construct that
you can use to perform Diffie-Hellman operations, just like you can with the
integers &lt;em&gt;mod p&lt;/em&gt; (that would be "regular" Diffie-Hellman). If that was
gibberish to you and you'd like to know more, check out &lt;a href="https://www.crypto101.io"&gt;Crypto 101&lt;/a&gt;, my
free introductory book on cryptography. You don't need a math background to
understand those concepts at a high level. The main difference is that Crypto
101 sticks to production cryptography, while this is still experimental.&lt;/p&gt;
&lt;p&gt;It's not surprising that isogeny-based cryptography is so confusing. Up until
recently, it was unambiguously in the realm of research, not even close to
being practically applicable. Its mathematical underpinnings are much more
complex than regular elliptic curves, let alone integers &lt;em&gt;mod p&lt;/em&gt;. It also
looks superficially similar to elliptic curve Diffie-Hellman, which only adds
to the confusion.&lt;/p&gt;
&lt;p&gt;With that, let's begin!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is this paper about?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Supersingular isogeny Diffie-Hellman (SIDH) is one of a handful of
"post-quantum" cryptosystems. Those are cryptosystems that will remain secure
even if the attacker has access to a large quantum computer. This has nothing
to do with quantum cryptography (for example, quantum key distribution)
beyond their shared quantum mechanical underpinning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why should I care about quantum computers?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;General quantum computers are not useful as general-purpose computing devices,
but they can solve some problems much faster than classical
computers. Classical computers can emulate quantum computers, but only with
exponential slowdown. A sufficiently large quantum computer could break most
production cryptography, including cryptosystems based on the difficulty of
factoring large numbers (like RSA), taking discrete logs over the integers
&lt;em&gt;mod p&lt;/em&gt; (like regular DH), or taking discrete logs over elliptic curves (like
ECDH and ECDSA). To quantify that, consider the following table:&lt;/p&gt;
&lt;p&gt;&lt;img alt="quantum computer attack cost versus classical" src="https://www.lvh.io/img/post-quantum/quantum-computer-relative-cost.png"&gt;&lt;/p&gt;
&lt;p&gt;In this table, n refers to the modulus size for RSA, and the field size for
ECC. Look at the rightmost column, which represents time taken by the
classical algorithm, and compare it to the "time" columns, which represent how
much a quantum computer would take. As &lt;em&gt;n&lt;/em&gt; increases, the amount of time the
quantum computer would take stays in the same ballpark, whereas, for a
classical computer, it increases (almost) exponentially. Therefore, increasing
n is an effective strategy for keeping up with ever-faster classical
computers, but it is ineffective at increasing the run time for a quantum
computer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aah! Why isn't everyone panicking about this?!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The good news is that these large quantum computers don't exist yet.&lt;/p&gt;
&lt;p&gt;If you look at the qubits column, you'll see that these attacks require large
universal quantum computers. The state of the art in those only has a handful
of qubits. In 2011, IBM successfully factored 143 using a 4-qubit quantum
computer. Scaling the number of qubits up is troublesome. In that light,
larger key sizes may prove effective after all; we simply don't know yet how
hard it is to build quantum computers that big.&lt;/p&gt;
&lt;p&gt;D-wave, a quantum computing company, has produced computers with 128 and 512
qubits and even &amp;gt;1000 qubits. While there is some discussion if D-waves
provide quantum speedup or are even real quantum computers at all; there is no
discussion that they are not &lt;em&gt;universal&lt;/em&gt; quantum computers. Specifically, they
only claim to solve one particular problem called quantum annealing. The 1000
qubit D-Wave 2X cannot factor RSA moduli of ~512 bits or solve discrete logs
on curves of ~120 bits.&lt;/p&gt;
&lt;p&gt;The systems at risk implement asymmetric encryption, signatures, and
Diffie-Hellman key exchanges. That's no accident: all post-quantum
alternatives are asymmetric algorithms. Post-quantum secure symmetric
cryptography is easier: we can just use bigger key sizes, which are still
small enough to be practical and result in fast primitives. Quantum computers
simply halve the security level, so all we need to do to maintain a 128 bit
security level is to use ciphers with 256 bit keys, like Salsa20.&lt;/p&gt;
&lt;p&gt;Quantum computers also have an advantage against SIDH, but both are still
exponential in the field size. The SIDH scheme in the new paper has 192 bits
of security against a classical attacker, but still has 128 bits of security
against a quantum attacker. That's in the same ballpark as most symmetric
cryptography, and better than the 2048-bit RSA certificates that underpin the
security of the Internet.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What makes this paper special?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Post-quantum cryptography has been firmly in the realm of academic research
and experiments. This paper makes significant advancements in how practically
applicable SIDH is.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Being future-proof sounds good. If this makes it practical, why don't we
start using it right now?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;SIDH is a young cryptosystem in a young field, and hasn't had the same level
of scrutiny as some of the other post-quantum cryptosystems, let alone the
"regular" cryptosystems we use daily. Attacks only get better, they never get
worse. It's possible that SIDH is insecure, and we just don't know how to
break it yet. It does have a good argument for why quantum algorithms wouldn't
be able to crack it (more on that later), but that's a hypothesis, not a
proof.&lt;/p&gt;
&lt;p&gt;The new performance figures from this paper are impressive, but this system is
still much slower than the ones we use today. Key generation and key exchange
take a good 50 million cycles or so each. That's about a thousand times slower
than Curve25519, a curve designed about 10 years ago. Key sizes are also much
larger: SIDH public keys are 751 bytes, whereas Curve25519 keys are only 32
bytes. For on-line protocols like HTTPS operating over TCP, that's a
significant cost.&lt;/p&gt;
&lt;p&gt;Finally, there are issues with implementing SIDH safely. Systems like
Diffie-Hellman over integers &lt;em&gt;mod p&lt;/em&gt; are much less complex than elliptic curve
Diffie-Hellman (ECDH), let alone SIDH. With ECDH and ECC in general, we've
seen new implementation difficulties, especially with early curves. Point
addition formulas would work, unless you were adding a point to itself. You
have to check that input points are on the curve, or leak the secret key
modulo some small order. These are real implementation problems, even though
we know how to solve them.&lt;/p&gt;
&lt;p&gt;This is nothing compared to the difficulties implementing SIDH. Currently,
SIDH security arguments rely on honest peers. A peer that gives you a
pathological input can utterly break the security of the scheme. To make
matters worse, while we understand how to verify inputs for elliptic curve
Diffie-Hellman, we don't have a way to verify inputs for isogeny-based
cryptography at all. We don't have much research to fall back on here
either. This isn't a SIDH-specific problem; post-quantum cryptography isn't
mature enough yet to have implementation issues like these nailed down
yet. (For an example from lattice-based cryptography, see the recent paper by
&lt;a href="https://eprint.iacr.org/2016/415"&gt;Bindel et al&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;I don't want to diminish the importance of this paper in any way!  Just
because it's not something that your browser is going to be doing tomorrow
doesn't mean it's not an impressive accomplishment. It's just a step on the
path that might lead to production crypto one day.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, fine. Why is this so different from elliptic curve Diffie-Hellman?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While SIDH and ECDH both use elliptic curves, they're different beasts. SIDH
generates new curves to perform a DH exchange, whereas ECDH uses points on one
fixed curve. These supersingular curves also have different properties from
regular curves. Using a supersingular curve for regular elliptic curve
operations would be horribly insecure. If you have some background in elliptic
curves: supersingular curves have a tiny embedding degree, meaning that
solving the ECDLP over &lt;code&gt;F(p)&lt;/code&gt; can easily be transformed into solving the DLP
over &lt;code&gt;F(p^n)&lt;/code&gt; where &lt;code&gt;n&lt;/code&gt; is that small embedding degree. Most curves have large
embedding degrees, meaning that solving the ECDLP directly is easier than
translating it into a DLP and then solving that.  You generally have to go out
of your way to find a curve with a small embedding degree. That is only done
in specialized systems, like for pairing-based cryptography, or, as in this
case, supersingular isogeny-based Diffie-Hellman.&lt;/p&gt;
&lt;p&gt;Let's recap ECDH. Public keys are points on a curve, and secret keys are
numbers. Alice and Bob agree on the parameters of the exchange ahead of time,
such as the curve &lt;em&gt;E&lt;/em&gt; and a generator point &lt;em&gt;P&lt;/em&gt; on that curve. Alice picks a
secret integer &lt;em&gt;a&lt;/em&gt; and computes her public key &lt;em&gt;aP&lt;/em&gt;. Bob picks a secret
integer &lt;em&gt;b&lt;/em&gt; and computes his public key &lt;em&gt;bP&lt;/em&gt;. Alice and Bob send each other
their public keys, and multiply their secret key by the other peer's public
key. Since &lt;em&gt;abP = baP&lt;/em&gt;, they compute the same secret. Since an attacker has
neither secret key, they can't compute the shared secret.&lt;/p&gt;
&lt;p&gt;SIDH is different. Secret keys are isogenies...&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Whoa whoa whoa. What the heck are isogenies?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;An isogeny between elliptic curves is a function from one elliptic curve to
another that preserves base points. That means it takes points on one curve
and returns points on the other curve. Every point on the input curve will map
to a point on the output curve; but multiple points may map to the same
point. Formally speaking, the isogeny is surjective. An isogeny is also a
homomorphism. That is, it preserves the structure of the curve. For any two
points P and Q, &lt;code&gt;phi(P + Q) = phi(P) + phi(Q)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;We have a bunch of formulas for generating isogenies from a curve and a
point. You might remember that the set of values a function takes is its
"domain", and the set of values it returns is called its "codomain". The
domain of such an isogeny is the curve you give it; its codomain might be the
same curve, or it might be a different one. In general, for SIDH, we care
about the case where it produces a new curve.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, so explain how SIDH works again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Roughly speaking, a secret key is an isogeny, and a public key is an elliptic
curve. By "mixing" their isogeny with the peer's public curve, each peer
generates a secret curve. The two peers will generally generate different
curves, but those curves will have the same j-invariant.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Wait, what's a j-invariant?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The j-invariant is a number you can compute for a particular curve. Perhaps
the best analogy would be the discriminant for quadratic equation you might
remember from high school math; it's a single number that tells you something
interesting about the underlying curve. There are different formulas for
curves in different forms. For example, for a curve in short Weierstrass form
&lt;code&gt;y^2 = x^3 + ax + b&lt;/code&gt;, the j-invariant is:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1728&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;27&lt;/span&gt;&lt;span class="n"&gt;b&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;The j-invariant has a few cool properties. For example, while this is the
formula for the short Weierstrass form, the value of j doesn't change if you
put the same curve in a different form. Also, all curves with the same
j-invariant are isomorphic. However, for SIDH you don't really care about
these properties; you just care that the j-invariant is a number you can
compute, and it'll be the same for the two secret curves that are generated by
the DH exchange.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OK, try explaining SIDH again.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The protocol fixes a supersingular curve E and four points on that
curve: P_A, Q_A, P_B, Q_B.&lt;/p&gt;
&lt;p&gt;Alice picks two random integers, m_A and n_A. She takes a linear combination
of those two integers with P_A and Q_A to produce a random point R_A, so:&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;R_A&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;n_A&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;P_A&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;m_A&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;Q_A&lt;/span&gt;
&lt;/pre&gt;


&lt;p&gt;That random point defines Alice's secret isogeny through the isogeny formulas
I talked about above. The codomain of that isogeny forms Alice's public
curve. Alice transforms points P_B and Q_B with the isogeny. She sends Bob her
public curve and the two transformed points.&lt;/p&gt;
&lt;p&gt;Bob does the same thing, except with A and B swapped.&lt;/p&gt;
&lt;p&gt;Once Alice gets Bob's public key, she applies m_A and n_A again to the
corresponding transformed points she got from Bob. She generates a new isogeny
phiBA from the resulting point just like she did before to generate her
private key. That isogeny's codomain will be an elliptic curve E_BA.&lt;/p&gt;
&lt;p&gt;When Bob performs his side of the exchange, he'll produce a different isogeny
and a different elliptic curve E_AB; but it will have the same j-invariant as
the curve Alice computed.  That j-invariant is the shared key.&lt;/p&gt;
&lt;p&gt;I've compiled a &lt;a href="https://www.lvh.io/sage/Supersingular%20Isogeny%20Elliptic%20Curve%20Cryptography%20--%20Sage.pdf"&gt;transcript&lt;/a&gt; of a Diffie-Hellman exchange using
Sage so you can see a (toy!) demo in action.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I know a little about elliptic curves. I thought they were always
non-singular. What's a supersingular elliptic curve but a contradiction in
terms?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You're right! Supersingular elliptic curves are somewhat confusingly
named. Supersingular elliptic curves are still elliptic curves, and they are
non-singular just like all other elliptic curves. The "supersingular" refers
to the singular values of the j-invariant. Equivalently, the Hasse invariant
will be 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;So, why does it matter that the curve is supersingular?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Firstly, computing the isogeny is much easier on supersingular curves than on
ordinary (not supersingular) elliptic curves. Secondly, if the curve is
ordinary, the scheme can be broken in subexponential time by a quantum
attacker.&lt;/p&gt;
&lt;p&gt;Isogeny-based cryptography using ordinary curves was considered as a
post-quantum secure cryptosystem before SIDH. However, Childs et al. showed a
subexponential quantum algorithm in 2010. This paper appeared to have ended
isogeny-based cryptography: it was already slower than other post-quantum
systems, and now it was shown that it wasn't even post-quantum secure.&lt;/p&gt;
&lt;p&gt;Because supersingular curves are rare, they had not previously been considered
for isogeny-based cryptography. However, the paper itself suggested that
supersingular curves might be worth examining, so it ended up pushing research
in a new direction rather than ending it.&lt;/p&gt;
&lt;p&gt;Explaining why the supersingular curve makes the problem quantum-hard is
tricky without being thoroughly familiar with isogenies and quantum
computing. If you're really interested, &lt;a href="https://arxiv.org/pdf/1012.4019v2.pdf"&gt;the Childs paper&lt;/a&gt; explains
how the quantum attack in the ordinary case works. Informally, in the ordinary
case, there is a group action (the &lt;em&gt;isogeny star operator&lt;/em&gt;) of the ideal class
group onto the set of isomorphism classes of isogenous curves with the same
endomorphism ring. That can be shown to be a special case of the abelian group
hidden shift problem, which can be solved quickly on a quantum computer. In
the supersingular case, there is no such group action to exploit. (If you're
trying to solve for this at home; this is why SIDH needs to define the 4
points P_A, P_B, Q_A, Q_B.)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;I would like to thank Thomas Ptacek for reviewing this blog post and bearing
with me as I struggle through trying to come up with human-readable
explanations for all of this stuff; Sean Devlin for reminding me that Sage is
an excellent educational tool; and Watson Ladd for pointing out a correction
w.r.t the Hasse invariant (the Hasse-Witt matrix is undefined, not
singular.). Finally, I'd like to thank all the people who reviewed drafts of
this post, including (in no particular order) Bryan Geraghty, Shane Wilton,
Sean Devlin, Thomas Ptacek, Tanner Prynn, Glyph Lefkowitz and Chris Wolfe.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</description><category>cryptography</category><category>security</category><guid>https://www.lvh.io/posts/supersingular-isogeny-diffie-hellman-101/</guid><pubDate>Sat, 30 Apr 2016 16:00:28 GMT</pubDate></item><item><title>Introducing Teleport</title><link>https://www.lvh.io/posts/introducing-teleport/</link><dc:creator>lvh</dc:creator><description>&lt;div&gt;&lt;p&gt;I'm happy to introduce &lt;a href="https://github.com/gravitational/teleport"&gt;Teleport&lt;/a&gt;, a new open source platform for
managing SSH infrastructure. Teleport is built by &lt;a href="http://www.gravitational.com/"&gt;Gravitational&lt;/a&gt;, a Y
Combinator company that ships SaaS on any platform. While I'm not a part of
Gravitational, I have been advising them on the Teleport project.&lt;/p&gt;
&lt;p&gt;Most teams don't have a great authentication story. Some rely on passing
passwords around haphazardly, while others rely on copying everyone's
&lt;code&gt;~/.ssh/id_rsa.pub&lt;/code&gt; to every new box. More complex homegrown systems quickly
become unwieldy. These methods are problematic both operationally and from a
security perspective: when security and usability are at odds, security tends
to lose out. For a lot of teams, a single compromised key off of a developer
machine spells disaster, on-boarding new team members is painful, and key
rotation doesn't happen.&lt;/p&gt;
&lt;p&gt;In the last few years, strong multi-factor authentication has become the
norm. Tokens are only valid for a brief period of time, use challenge-response
protocols, or both. Teleport helps bring the same level of sophistication to
infrastructure. It helps system administrators leverage the security benefits
of short-lived certificates, while keeping the operational benefits of
decoupling server authentication from user authentication. It lets you run
isolated clusters, so that a compromise of staging credentials doesn't lead to
a compromise in production. It automatically maintains clear audit logs: who
logged in, when and where they logged in, and what they did once they got
there.&lt;/p&gt;
&lt;p&gt;Teleport comes with a beautiful, usable UI, making it easy to visualize
different clusters and the available machines within them. The UI is optional:
many system administrators will prefer to use their existing SSH client, and
Teleport supports that natively.  Because it implements the &lt;code&gt;SSH_AUTH_SOCK&lt;/code&gt;
protocol, integrating your current CLI workflow is a simple matter of setting
a single environment variable.&lt;/p&gt;
&lt;p&gt;As someone with an open-source background, I'm glad to see this software
released and developed out in the open. A decent SSH key management story
should be available to everyone, and that's what Teleport does. I believe
making this technology more accessible is good for everyone, including
commercial vendors. Democratizing a decent DIY story helps turn their product
into the battle-hardened and commercially supported version of industry best
practice; and as such, I hope this helps grow that market. As a principal
engineer at &lt;a href="https://www.rackspace.com/security/"&gt;Rackspace Managed Security&lt;/a&gt;, I'm excited to start working
towards better authentication stories, both internally and for our customers,
with Teleport as the new baseline.&lt;/p&gt;
&lt;p&gt;Releasing early and often is also an important part of open source
culture. That can be at odds with doing due diligence when releasing
security-critical systems like Teleport, especially when those systems have
non-trivial cryptographic components. We feel Teleport is ready to show to the
public now. To make sure we act as responsibly as possible, I've helped the
Teleport team to join forces with a competent independent third-party
auditor. We're not recommending that you bet the farm on Teleport by running
it in production as your only authentication method just yet, but we do think
it's ready for motivated individuals to start experimenting with it.&lt;/p&gt;
&lt;p&gt;Some people might feel that a better SSH story means you're solving the wrong
problem. It seems at odds with the ideas behind immutable infrastructure and
treating servers as &lt;a href="https://blog.engineyard.com/2014/pets-vs-cattle"&gt;cattle, not pets&lt;/a&gt;. I don't think that's
true. Firstly, even with immutable infrastructure, being able to SSH into a
box to debug and monitor is still incredibly important. Being able to rapidly
deploy a bunch of fixed images quickly may be good, but you still have to know
what to fix first. Secondly, existing systems don't always work that way. It
may not be possible, let alone economically rational, to "port" them
effectively. It's easy to think of existing systems as legacy eyesores that
only exist until you can eradicate them, but they do exist, they're typically
here to stay, and they need a real security story, too.&lt;/p&gt;
&lt;p&gt;Teleport is still in its early stages. It's usable today, and I'm convinced it
has a bright future ahead of it. It's written in a beautiful, hackable Go
codebase, and &lt;a href="https://github.com/gravitational/teleport"&gt;available on Github&lt;/a&gt; starting today.&lt;/p&gt;&lt;/div&gt;</description><category>security</category><guid>https://www.lvh.io/posts/introducing-teleport/</guid><pubDate>Sat, 12 Mar 2016 17:35:56 GMT</pubDate></item></channel></rss>