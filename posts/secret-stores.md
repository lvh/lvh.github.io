<!--
.. title: Secret stores
.. slug: secret-stores
.. date: 2017-01-18 13:15:16 UTC-08:00
.. tags: private, security, crypto
.. category:
.. link:
.. description:
.. type: text
-->

Applications need secrets. TLS certificates, credentials for your database or
cloud provider: there are plenty of things your application may need access to
that you don't want anyone else to have access to.

Most companies don't have a particularly comprehensive strategy for managing
secrets. They're often committed to version control, kept on one person's
machine, accidentally leaked via environment variables, et cetera. Sometimes
secrets get added to build artifacts like Docker images. There's rarely any kind
of comprehensive story for key rotation or audit logs. Most sets of secrets
don't have the principle of least authority applied to them; applications get
access secrets by default, not by exception, and there's no mechanism in place
for limiting that.

These practices are generally understood to be awful and there are a lot of
homegrown mechanisms for improving on them. For example, the credentials in
source control might be encrypted; moving the trusted actors from "everyone with
the source code" to "the one trusted deployment machine".

This post is not about password managers. Password managers have many similar
design constraints, but are still fundamentally different beasts with completely
different users. Secret stores (as defined in this post) are primarily consumed
by computers. The secrets are typically short and high entropy (a human wouldn't
be able to remember them), and generated by a third party. By comparison, a
password manager is used by humans, accessed with a low entropy passphrase, and
is often responsible for generating the secrets to begin with. This post is also
not about cold storage, like the physical vault where you keep your AWS master
password.

This post is intended to be an overview of how we can do better. First, I'll
argue that we can do better at all. If you're already convinced secret stores
are a great idea, you can jump ahead to the [contenders](#contenders). Or, maybe
you just care about the [conclusion](#conclusion).

# Chicken versus egg

At first sight, secret stores might sound like a fool's errand. Clearly, access
to secrets is a sensitive operation that you want to properly authenticate.
Machines authenticate themselves to other machines with high entropy secrets.
So, you still need to give the machine a secret anyway—why not just give it all
of them?

There are plenty of useful features a secret store might get you:

* It knows how to encrypt and store secrets securely. Having one specialized
  application have an opinion on how to do that is much better than having a
  hundred ones that do it incidentally. The central one will be audited and
  monitored. The hundreds will invariably mess it up. As the adage goes:
  defenders have to be right all the time, attackers only have to be right once.

* It tracks who accessed a secret and when. This is critical information for
  remediation and ongoing scope reduction. Knowing who accessed what and when
  probably gives you the context for why; all three tell you how to further
  reduce the authority that application has, or reconstruct a detailed audit
  trail.

* It can generate "minimal" credentials on-demand. Minimal means you get a key
  that only lets you access what you need and for a limited amount of time. For
  example, if you need to access specific AWS resources, you'd only be able to
  access those. On-demand means that they key can be created when you ask for
  it, and isn't shared with anyone else. (This is something dear to my heart;
  while [icecap][icecap] is anything but production software, it's essentially
  this idea turned up to eleven.)

* It can encrypt things on behalf of the requester, such that the requester
  never sees the key. That is good, because it can be one-way. It is also good
  because if a service is compromised, the compromise may be detected and
  remediated (access revoked) before all data is dumped and compromised. Having
  the secret store lets you do e.g. rate limiting and centralized monitoring,
  for example.

* Secret stores can know how secrets are linked; making it easier to do
  revocation, and easier to determine the impact of a breach or misuse incident.

* Once secrets are managed in a centralized place, it becomes feasible to have a
  coherent rotation strategy.

This concept of a secret store just kicking the can down the road is important
to consider because some schemes do not have these features, so the rationale
applies.

# Bootstrapping

This problem of needing some identity or secret to start from is called
*bootstrapping*.

One traditional strategy is to have an administrator deploy secrets to where
they need to go, via a configuration management tool like Chef or Ansible. Hosts
are long-living and their identity is either trusted on first use or verified
out of band. Identity might be something provided by a provider, like an
instance identifier, but more commonly is something like an SSH host key. You
can also tie host identities to capabilities directly. This is particularly
convenient on AWS, where EC2 instances get IAM roles and hence access to e.g.
KMS and S3.

This model is challenging to port to container-centric tools like Kubernetes,
Mesos, AWS ECS... where instances are containers, considered ephemeral and
immutable. In these models, it's more reasonable to think of the immutable
artifact being authenticated (signed) rather than the host it might incidentally
run on. That comes with metadata about what sort of capabilities the application
should be able to access. Just like an application on your phone asks to be able
to use the webcam, the application should ask the host for what it has access
to.

One way to do that in Docker is via [Docker Notary][notary]. It is an
implementation of <abbr title="The Update Framework">[TUF][tuf]</abbr>. It can
be used to audit provenance of container images via code signing rooted in a PKI
that you manage yourself. CloudFlare's Nick Sullivan gave a [talk][pal] at
B-Sides LV 2016 on PAL, their implementation of this idea. It's important to
note that this is not another secret management tool. It's a container identity
bootstrapping tool that bridges the bootstrapping gap. PAL is not open source
yet, but CloudFlare has indicated their intent to change that.

# Criteria

Measuring quality based on purely objective criteria is tempting, but many tools
make trade-offs or have interesting design choices that are difficult to compare
objectively. I try not to pick favorites between programming languages.
Deployment concerns are real, and things like having a single binary are nice,
hence projects implement in languages like Go or Rust have an advantage.

Generally speaking, open source is better than closed source. I assume that
major cloud platform providers, like Google's GCP and Amazon's AWS, are already
fundamentally trusted; although less required trust is better. Having had
professional audits is a big plus, but being amenable to informal inspection is
too (hence open source). Even though the primary consumers of these systems are
machines, at some point humans are still contributing secrets to it. It'd be
nice if we can securely link those transactions to specific individuals.

How the secrets should be handed to the application is a hotly contested topic.
Some approaches require client libraries. Some expose secrets via a real or
virtual file system. A particularly controversial option is environment
variables, which at the same time has been praised as best practice by the 12
Factor app, and deprecated by security and systems experts. QQQQ: cite diogo,
noah

It's important to distinguish between different meanings of the term
"environment variable" in different contexts. They refer to the same concept,
but in different places and at different stages of their life cycle.
Traditionally, environment variable is used in the POSIX sense of "something I
can `getenv` or `putenv` and read (at least on Linux) at `/proc/{pid}/environ`".
Docker also has its own related concept of environment variables passed on to
the process in the container. Some systems, like [Convox][convox-secrets]
actively recommend putting secrets in an environment file (e.g. `.env`) that's
unencrypted, maintained next to your code, but kept out of source control.

As usual, the answer is to formalize your threat model and your resources. Does
it involve a malicious employee? Do you think you can keep a soft key from
leaking? What will your employees put up with, and how much does it cost to
implement?

<a name="contenders">

# Implementations

Oh boy. There are a few. This is by no means intended to be a complete overview,
although it's reasonably comprehensive.

# Encrypted bags or pre-encryption

Many implementations follow an encrypted bag model, also known as a
pre-encryption scheme. The secrets are still managed in source control, although
the tool encrypts them first, and the repository might be separate from the one
used to store the source code. Examples include Chef [data bags][cdb] and
Ansible [Vault][av].

Some implementations provide incremental improvements on this model.

[Chef Vault][chef-vault] layers asymmetric RSA encryption on top of Chef's
encrypted data bags. This effectively builds a key distribution system. QQQ

[Citadel][citadel] is a response to the limitations of Chef encrypted data bags
and Vault. In the author's own words, it is a usage pattern with a bit of DSL
sugar. QQQ

[EJSON][ejson] by Shopify uses public-key crypto instead of a shared symmetric
key or password. At some point in the middle of 2016, they decided to rewrite
it from Ruby to Go. I'm reviewing the current Go version, which comes shipped as
a Ruby gem for backwards compatibility reasons.

[SOPS][sops] was at some point implemented in Python, but then got reimplemented
in Go. This review only deals with the latter since the former is deprecated.
Unfortunately the new version comes with some regressions. The old Python
version just ran the `gpg` binary, whereas the new Go version uses Go's built-in
OpenPGP implementation. This is convenient, because it no longer depends on
having GPG installed and you can just use a single binary. Unfortunately, that
also means the former supported hard tokens like a Yubikey,
and [the current version does not][sops-yk]. SOPS has a feature that makes it
stand out feature: it can encrypt using both GPG and KMS. Just like GPG
internally works by encrypting a session key to different public keys, SOPS
encrypts a session key via several mechanisms. This means that a secret in SOPS
can be written by GPG keys tightly linked to human identities, and then consumed
by KMS keys tightly linked to machine identities.

These solutions miss the features mentioned earlier. Because the ciphertext is
statically available to the operator and the key is a shared password, there is
no audit trail for accesses. Fortunately, because the secrets are managed in
source control, these systems automatically keep a historical record. Rotation
is considered orthogonal to these tools, so still needs to be handled out of
band.

These systems are typically tied to a particular deployment model; either
they're a part of a configuration management tool, or that tool is unspecified
(like EJSON). This is fine if you have an operator-centric deployment model with
long-living hosts. Conversely, it is cumbersome to use for large deployments of
ephemeral, immutable infrastructure. In that context, they leave you with a
self-referential problem to solve: you get a secret to access the secrets, but
how do you safely distribute that secret without buying into the deployment
model? This last criticism doesn't apply to SOPS, since it also supports KMS;
although you're in the same boat if you encrypt a secret with GPG—plus, you lose
the strong audit guarantees.

Asymmetric solutions try to solve this problem, but typically run into problems
where they have to encrypt for many servers: you either re-use keys, or have a
large key management problem on your hands.

# Configuration storage systems and cluster operating systems

Cluster operating systems like [Kubernetes][k8s] and [Docker Swarm][swarm] take
a similar approach to each other. Some people store secrets in configuration
management systems like etcd or Zookeeper. This works similarly to the secrets
storage mechanisms mentioned above, because they're really the same thing.
Kubernetes, for example, just manages its secrets in etcd just like everything
else. Typically, these secrets are also unencrypted; if not, you run into the
bootstrapping problem again.

Kubernetes secrets are [not encrypted][k8s-enc]. I suppose it is still
advantageous to use over storing them in etcd directly, because at least
kubernetes semantically knows they're secrets, so it has the option of allowing
something more clever in the future.

Mesos, surprisingly, has no answer for secrets management. The closest things I
found is Mesosphere's Enterprise DC/OS. The documentation seemed pretty
reasonable as a tutorial, but it didn't help me much to audit the system; either
way, it's proprietary.

Docker Swarm's [secrets][swarm-secrets] are brand new in 1.13. Disclaimer: I
reviewed some of the cryptography, and the implementation and threat model have
changed over the course of the feature's development.


```
[15:05:12]  <mhashemi>	(for bystanders, coderanger gave a great talk about secret storages not long back: https://www.youtube.com/watch?v=unFMJlKGh98 )
[15:06:40]  <coderanger>	Or for a more stable URL (with slides) https://coderanger.net/talks/secrets/
```

# Trusted third party systems

It's clear that some features, like audit logging, can only be provided by
controlling access to the keys. Plenty of secret stores take this alternative
approach, both with symmetric and asymmetric keys. Those keys can live in
software or in dedicated hardware devices like HSMs, often provided by cloud
providers, as with Amazon's KMS. Generally (although not intrinsically), this
means that the third party system you're talking to is fully trusted to see the
plaintexts credentials; either permanently or at least at decryption time.

## Vault

Hashicorp's [Vault][vault] is a relatively new and very popular contender.
Unlike some of the other alternatives, key management is done entirely in
memory; there is currently no option to use keys managed in an HSM or KMS. This
option appears [to be dismissed][vault-no-kms] on the issue tracker.

QQQ read vault's TODO docs/tickets

## (Building on) hosted platforms

[sneaker][sneaker] and [credstash][credstash] both fundamentally rely on
Amazon's KMS; the principal difference is that sneaker uses S3, and credstash
uses DynamoDB. Relying on these tools is convenient, because it implies not
having to run servers. Furthermore, routing access control through AWS IAM while
keeping the key safely locked away in KMS helps prevent accidental key
disclosure. [biscuit][biscuit] by `dcoker` (not a typosquat) also uses KMS, but
relies on local file storage of secrets instead. It also conveniently comes with
a HA, multi-region deployment model by default. Confidant similarly relies on
KMS and DynamoDB, but is additionally versioned and comes with a nice GUI.
Unlike the other three solutions, it requires running a server.

<!--
Confidant contests the HA/multi-region claim: https://github.com/dcoker/biscuit/pull/1
I've asked them to back it up: https://github.com/lyft/confidant/issues/110
-->

SOPS deserves an honorable mention here as well, since it's the only tool I
found that does both KMS and OpenPGP. Of course, once you have a PGP encrypted
version you might have access without an audit trail.

# Other systems

## [Red October][red-october]

Red October is the secret store that CloudFlare uses with PAL. It can be used
separately: PAL is there to bootstrap, Red October is there to do something with
the bootstrapped secret. Red October is notable for being able to implement
two-person rules: i.e. a secret can be accessed but only if several people or
sets of people co-operate. This prevents compromise when one individual actors
is compromised; be it under duress, or because they go rogue.

The n-person rule is implemented with traditional encrypted keys and layered
symmetric encryption. This has the benefit that it's simple and requires no
exotic cryptography. The mechanisms are well-understood and the implementations
are top-notch. A minor limitation is that you have to keep your number of groups
small. Because of the layered encryption strategy, if you you any *k* out of *n*
to be able to decrypt something, you need *n* choose *k* encrypted keys; with
something like Shamir Secret Sharing, you'd only need *n*. For any 2 out of 3,
this is 3 choose 2 = 3, the same as with secret sharing. For any 2 out of 100,
this nearly 5000.

## [secretary][secretary]

# Honorable mentions

* Barbican: an OpenStack project, now mostly pining for the fjords. Not a lot of
  production deployments, especially not outside of an OpenStack context.
* Conjur, Torus: proprietary or partially proprietary, so not considered.
* Ithos: While it is by its own admission not yet ready for prime-time, it gets
  an honorable mention for being built on an append-only cryptographically
  verifiable log, a la Certificate Transparency. This has interesting security
  properties from an audit chain perspective, not dissimilar from managing
  secrets in source control.

<a name="conclusion">

# Conclusions

There are too many secret stores. It took a while to do this research. This is
ostensibly nobody's fault. Many of these tools were developed in-house when no
great alternatives were publicly available. Furthermore, they are too niche for
any clear victor to emerge. There are a few fundamentally different approaches,
but they're not well-understood, so it's difficult for people who "just want to
protect secrets" to pick a solution judiciously.

When it comes to hosted key management, AWS clearly dominates the space. I was
unable to find anything that supports Cloud Key Management Service, GCP's
equivalent to KMS. In fairness, it's quite new, and officially still in beta.
Because of their similarities, adding support to any of the AWS KMS-powered
solutions would not be particularly complex.

Interestingly, several projects were rewritten from languages like Python and
Ruby to Go. While I think our industry generally does that kind of thing too
often, it's hard to fault anyone here. Go is genuinely great at shipping
easy-to-use binaries with strong cryptography.

# Recommendations

Think about your threat model.

Bootstrapping is a good place to start thinking. I hope CloudFlare open sources
PAL. I know it's on their roadmap and I don't want to voluntell them to do
things, but it's awesome and I wish I could start putting it in production.

If your threat model includes insider threats and you want to enforce two-person
policies, Red October seems to be the obvious choice.

biscuit seems like one of the more convenient KMS-based solutions, especially if
you're committed to the image attestation model. Because it uses local files, it
is presumably easier to pair with PAL's container image attestation model, as
well as easier to port to GCP.

# Fin

In no particular order, I'd like to thank Jeremy Rauch, Noah Kantrowitz, Julien
Vehent, Adrian Utrilla, Nick Sullivan.

Questions? Comments? Corrections? Updates? I'm [lvh][twitter] on Twitter and you
can e-mail me at [lvh@latacora.com](mailto:lvh@latacora.com).

[chef-vault]:
[red-october]: https://github.com/cloudflare/redoctober
[notary]: https://github.com/docker/notary
[tuf]: https://theupdateframework.github.io/
[cdb]: https://docs.chef.io/data_bags.html#encrypt-a-data-bag-item
[av]: http://docs.ansible.com/ansible/playbooks_vault.html
[icecap]: https://github.com/lvh/icecap
[ejson]: https://github.com/Shopify/ejson
[ejson-install]: https://github.com/Shopify/ejson/issues/36
[sneaker]: https://github.com/codahale/sneaker
[credstash]: https://github.com/fugue/credstash
[citadel]: https://github.com/poise/citadel
[secretary]: https://github.com/meltwater/secretary
[vault]: https://github.com/hashicorp/vault
[vault-no-kns]:
[pal]: https://www.youtube.com/watch?v=G_JXv059UY0
[biscuit]: https://github.com/dcoker/biscuit
[sops]: https://github.com/mozilla/sops
[torus]: https://www.torus.sh/
[ithos]: https://github.com/cryptosphere/ithos
[k8s]: https://github.com/kubernetes/kubernetes
[swarm]: https://www.docker.com/products/docker-swarm
[swarm-secrets]: https://docs.docker.com/engine/swarm/secrets/
[k8s-enc]: https://github.com/kubernetes/kubernetes/issues/12742
[convox-secrets]: https://convox.com/docs/environment/
